From 991ddf422f18336be772dd6bd5d5373570009466 Mon Sep 17 00:00:00 2001
From: Vamsi Attunuru <vattunuru@marvell.com>
Date: Wed, 12 Jul 2023 23:11:54 -0700
Subject: [PATCH 528/955] dma/cnxk: sync with 23.03

sync with 23.03-devel driver

Signed-off-by: Vamsi Attunuru <vattunuru@marvell.com>
Change-Id: I7459aea0e0b81d16d0bdc6f2f7bec7d3a745c87e
Reviewed-on: https://sj1git1.cavium.com/c/IP/SW/dataplane/dpdk/+/107453
Base-Builds: sa_ip-toolkits-Jenkins <sa_ip-toolkits-jenkins@marvell.com>
Base-Tests: sa_ip-toolkits-Jenkins <sa_ip-toolkits-jenkins@marvell.com>
Tested-by: sa_ip-toolkits-Jenkins <sa_ip-toolkits-jenkins@marvell.com>
Reviewed-by: Jerin Jacob Kollanukkaran <jerinj@marvell.com>
---
 drivers/dma/cnxk/cnxk_dmadev.c | 563 ++++++++++++++++++++++-----------
 drivers/dma/cnxk/cnxk_dmadev.h |  34 +-
 2 files changed, 401 insertions(+), 196 deletions(-)

diff --git a/drivers/dma/cnxk/cnxk_dmadev.c b/drivers/dma/cnxk/cnxk_dmadev.c
index aa83018174cff..166c8983026c9 100644
--- a/drivers/dma/cnxk/cnxk_dmadev.c
+++ b/drivers/dma/cnxk/cnxk_dmadev.c
@@ -7,66 +7,107 @@
 
 #include <bus_pci_driver.h>
 #include <rte_common.h>
+#include <rte_dmadev.h>
+#include <rte_dmadev_pmd.h>
 #include <rte_eal.h>
 #include <rte_lcore.h>
 #include <rte_mempool.h>
 #include <rte_pci.h>
-#include <rte_dmadev.h>
-#include <rte_dmadev_pmd.h>
 
-#include <roc_api.h>
 #include <cnxk_dmadev.h>
 
 static int
-cnxk_dmadev_info_get(const struct rte_dma_dev *dev,
-		     struct rte_dma_info *dev_info, uint32_t size)
+cnxk_dmadev_info_get(const struct rte_dma_dev *dev, struct rte_dma_info *dev_info, uint32_t size)
 {
-	RTE_SET_USED(dev);
+	struct cnxk_dpi_vf_s *dpivf = dev->fp_obj->dev_private;
 	RTE_SET_USED(size);
 
 	dev_info->max_vchans = MAX_VCHANS_PER_QUEUE;
-	dev_info->nb_vchans = MAX_VCHANS_PER_QUEUE;
+	dev_info->nb_vchans = dpivf->num_vchans;
 	dev_info->dev_capa = RTE_DMA_CAPA_MEM_TO_MEM | RTE_DMA_CAPA_MEM_TO_DEV |
 			     RTE_DMA_CAPA_DEV_TO_MEM | RTE_DMA_CAPA_DEV_TO_DEV |
 			     RTE_DMA_CAPA_OPS_COPY | RTE_DMA_CAPA_OPS_COPY_SG;
 	dev_info->max_desc = DPI_MAX_DESC;
-	dev_info->min_desc = 1;
+	dev_info->min_desc = DPI_MIN_DESC;
 	dev_info->max_sges = DPI_MAX_POINTER;
 
 	return 0;
 }
 
 static int
-cnxk_dmadev_configure(struct rte_dma_dev *dev,
-		      const struct rte_dma_conf *conf, uint32_t conf_sz)
+cnxk_dmadev_vchan_free(struct cnxk_dpi_vf_s *dpivf)
+{
+	struct cnxk_dpi_conf *dpi_conf;
+	uint16_t num_vchans;
+	uint16_t max_desc;
+	int i, j;
+
+	num_vchans = dpivf->num_vchans;
+	for (i = 0; i < num_vchans; i++) {
+		dpi_conf = &dpivf->conf[i];
+		max_desc = dpi_conf->c_desc.max_cnt;
+		if (dpi_conf->c_desc.compl_ptr) {
+			for (j = 0; j < max_desc; j++)
+				rte_free(dpi_conf->c_desc.compl_ptr[j]);
+		}
+
+		rte_free(dpi_conf->c_desc.compl_ptr);
+		dpi_conf->c_desc.compl_ptr = NULL;
+	}
+
+	return 0;
+}
+
+static int
+cnxk_dmadev_configure(struct rte_dma_dev *dev, const struct rte_dma_conf *conf, uint32_t conf_sz)
 {
 	struct cnxk_dpi_vf_s *dpivf = NULL;
 	int rc = 0;
 
-	RTE_SET_USED(conf);
-	RTE_SET_USED(conf);
-	RTE_SET_USED(conf_sz);
 	RTE_SET_USED(conf_sz);
+
 	dpivf = dev->fp_obj->dev_private;
+
+	/* Accept only number of vchans as config from application. */
+	if (!(dpivf->flag & CNXK_DPI_DEV_START)) {
+		/* After config function, vchan setup function has to be called.
+		 * Free up vchan memory if any, before configuring num_vchans.
+		 */
+		cnxk_dmadev_vchan_free(dpivf);
+		dpivf->num_vchans = conf->nb_vchans;
+	}
+
+	if (dpivf->flag & CNXK_DPI_DEV_CONFIG)
+		return rc;
+
 	rc = roc_dpi_configure(&dpivf->rdpi);
-	if (rc < 0)
+	if (rc < 0) {
 		plt_err("DMA configure failed err = %d", rc);
+		goto done;
+	}
 
+	dpivf->flag |= CNXK_DPI_DEV_CONFIG;
+
+done:
 	return rc;
 }
 
 static int
 cnxk_dmadev_vchan_setup(struct rte_dma_dev *dev, uint16_t vchan,
-			const struct rte_dma_vchan_conf *conf,
-			uint32_t conf_sz)
+			const struct rte_dma_vchan_conf *conf, uint32_t conf_sz)
 {
 	struct cnxk_dpi_vf_s *dpivf = dev->fp_obj->dev_private;
-	struct cnxk_dpi_compl_s *comp_data;
-	union dpi_instr_hdr_s *header = &dpivf->conf[vchan].hdr;
+	struct cnxk_dpi_conf *dpi_conf = &dpivf->conf[vchan];
+	union dpi_instr_hdr_s *header = &dpi_conf->hdr;
+	uint16_t max_desc;
+	uint32_t size;
 	int i;
 
 	RTE_SET_USED(conf_sz);
 
+	if (dpivf->flag & CNXK_DPI_DEV_START)
+		return 0;
+
 	header->cn9k.pt = DPI_HDR_PT_ZBW_CA;
 
 	switch (conf->direction) {
@@ -103,34 +144,61 @@ cnxk_dmadev_vchan_setup(struct rte_dma_dev *dev, uint16_t vchan,
 		header->cn9k.pvfe = 0;
 	};
 
-	for (i = 0; i < conf->nb_desc; i++) {
-		comp_data = rte_zmalloc(NULL, sizeof(*comp_data), 0);
-		if (comp_data == NULL) {
-			plt_err("Failed to allocate for comp_data");
+	/* Free up descriptor memory before allocating. */
+	cnxk_dmadev_vchan_free(dpivf);
+
+	max_desc = conf->nb_desc;
+	if (!rte_is_power_of_2(max_desc))
+		max_desc = rte_align32pow2(max_desc);
+
+	if (max_desc > DPI_MAX_DESC)
+		max_desc = DPI_MAX_DESC;
+
+	size = (max_desc * sizeof(struct cnxk_dpi_compl_s *));
+	dpi_conf->c_desc.compl_ptr = rte_zmalloc(NULL, size, 0);
+
+	if (dpi_conf->c_desc.compl_ptr == NULL) {
+		plt_err("Failed to allocate for comp_data");
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < max_desc; i++) {
+		dpi_conf->c_desc.compl_ptr[i] =
+			rte_zmalloc(NULL, sizeof(struct cnxk_dpi_compl_s), 0);
+		if (!dpi_conf->c_desc.compl_ptr[i]) {
+			plt_err("Failed to allocate for descriptor memory");
 			return -ENOMEM;
 		}
-		comp_data->cdata = DPI_REQ_CDATA;
-		dpivf->conf[vchan].c_desc.compl_ptr[i] = comp_data;
-	};
-	dpivf->conf[vchan].c_desc.max_cnt = DPI_MAX_DESC;
-	dpivf->conf[vchan].c_desc.head = 0;
-	dpivf->conf[vchan].c_desc.tail = 0;
+
+		dpi_conf->c_desc.compl_ptr[i]->cdata = DPI_REQ_CDATA;
+	}
+
+	dpi_conf->c_desc.max_cnt = (max_desc - 1);
+	dpi_conf->c_desc.head = 0;
+	dpi_conf->c_desc.tail = 0;
+	dpi_conf->pnum_words = 0;
+	dpi_conf->pending = 0;
+	dpi_conf->desc_idx = 0;
 
 	return 0;
 }
 
 static int
 cn10k_dmadev_vchan_setup(struct rte_dma_dev *dev, uint16_t vchan,
-			 const struct rte_dma_vchan_conf *conf,
-			 uint32_t conf_sz)
+			 const struct rte_dma_vchan_conf *conf, uint32_t conf_sz)
 {
 	struct cnxk_dpi_vf_s *dpivf = dev->fp_obj->dev_private;
-	struct cnxk_dpi_compl_s *comp_data;
-	union dpi_instr_hdr_s *header = &dpivf->conf[vchan].hdr;
+	struct cnxk_dpi_conf *dpi_conf = &dpivf->conf[vchan];
+	union dpi_instr_hdr_s *header = &dpi_conf->hdr;
+	uint16_t max_desc;
+	uint32_t size;
 	int i;
 
 	RTE_SET_USED(conf_sz);
 
+	if (dpivf->flag & CNXK_DPI_DEV_START)
+		return 0;
+
 	header->cn10k.pt = DPI_HDR_PT_ZBW_CA;
 
 	switch (conf->direction) {
@@ -167,18 +235,40 @@ cn10k_dmadev_vchan_setup(struct rte_dma_dev *dev, uint16_t vchan,
 		header->cn10k.pvfe = 0;
 	};
 
-	for (i = 0; i < conf->nb_desc; i++) {
-		comp_data = rte_zmalloc(NULL, sizeof(*comp_data), 0);
-		if (comp_data == NULL) {
-			plt_err("Failed to allocate for comp_data");
+	/* Free up descriptor memory before allocating. */
+	cnxk_dmadev_vchan_free(dpivf);
+
+	max_desc = conf->nb_desc;
+	if (!rte_is_power_of_2(max_desc))
+		max_desc = rte_align32pow2(max_desc);
+
+	if (max_desc > DPI_MAX_DESC)
+		max_desc = DPI_MAX_DESC;
+
+	size = (max_desc * sizeof(struct cnxk_dpi_compl_s *));
+	dpi_conf->c_desc.compl_ptr = rte_zmalloc(NULL, size, 0);
+
+	if (dpi_conf->c_desc.compl_ptr == NULL) {
+		plt_err("Failed to allocate for comp_data");
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < max_desc; i++) {
+		dpi_conf->c_desc.compl_ptr[i] =
+			rte_zmalloc(NULL, sizeof(struct cnxk_dpi_compl_s), 0);
+		if (!dpi_conf->c_desc.compl_ptr[i]) {
+			plt_err("Failed to allocate for descriptor memory");
 			return -ENOMEM;
 		}
-		comp_data->cdata = DPI_REQ_CDATA;
-		dpivf->conf[vchan].c_desc.compl_ptr[i] = comp_data;
-	};
-	dpivf->conf[vchan].c_desc.max_cnt = DPI_MAX_DESC;
-	dpivf->conf[vchan].c_desc.head = 0;
-	dpivf->conf[vchan].c_desc.tail = 0;
+		dpi_conf->c_desc.compl_ptr[i]->cdata = DPI_REQ_CDATA;
+	}
+
+	dpi_conf->c_desc.max_cnt = (max_desc - 1);
+	dpi_conf->c_desc.head = 0;
+	dpi_conf->c_desc.tail = 0;
+	dpi_conf->pnum_words = 0;
+	dpi_conf->pending = 0;
+	dpi_conf->desc_idx = 0;
 
 	return 0;
 }
@@ -187,11 +277,29 @@ static int
 cnxk_dmadev_start(struct rte_dma_dev *dev)
 {
 	struct cnxk_dpi_vf_s *dpivf = dev->fp_obj->dev_private;
+	struct cnxk_dpi_conf *dpi_conf;
+	int i, j;
+
+	if (dpivf->flag & CNXK_DPI_DEV_START)
+		return 0;
 
-	dpivf->desc_idx = 0;
-	dpivf->num_words = 0;
 	roc_dpi_enable(&dpivf->rdpi);
 
+	for (i = 0; i < dpivf->num_vchans; i++) {
+		dpi_conf = &dpivf->conf[i];
+		dpi_conf->c_desc.head = 0;
+		dpi_conf->c_desc.tail = 0;
+		dpi_conf->pnum_words = 0;
+		dpi_conf->pending = 0;
+		dpi_conf->desc_idx = 0;
+		for (j = 0; j < dpi_conf->c_desc.max_cnt; j++) {
+			if (dpi_conf->c_desc.compl_ptr[j])
+				dpi_conf->c_desc.compl_ptr[j]->cdata = DPI_REQ_CDATA;
+		}
+	}
+
+	dpivf->flag |= CNXK_DPI_DEV_START;
+
 	return 0;
 }
 
@@ -201,6 +309,7 @@ cnxk_dmadev_stop(struct rte_dma_dev *dev)
 	struct cnxk_dpi_vf_s *dpivf = dev->fp_obj->dev_private;
 
 	roc_dpi_disable(&dpivf->rdpi);
+	dpivf->flag &= ~CNXK_DPI_DEV_START;
 
 	return 0;
 }
@@ -211,8 +320,12 @@ cnxk_dmadev_close(struct rte_dma_dev *dev)
 	struct cnxk_dpi_vf_s *dpivf = dev->fp_obj->dev_private;
 
 	roc_dpi_disable(&dpivf->rdpi);
+	cnxk_dmadev_vchan_free(dpivf);
 	roc_dpi_dev_fini(&dpivf->rdpi);
 
+	/* Clear all flags as we close the device. */
+	dpivf->flag = 0;
+
 	return 0;
 }
 
@@ -221,8 +334,7 @@ __dpi_queue_write(struct roc_dpi *dpi, uint64_t *cmds, int cmd_count)
 {
 	uint64_t *ptr = dpi->chunk_base;
 
-	if ((cmd_count < DPI_MIN_CMD_SIZE) || (cmd_count > DPI_MAX_CMD_SIZE) ||
-	    cmds == NULL)
+	if ((cmd_count < DPI_MIN_CMD_SIZE) || (cmd_count > DPI_MAX_CMD_SIZE) || cmds == NULL)
 		return -EINVAL;
 
 	/*
@@ -238,11 +350,15 @@ __dpi_queue_write(struct roc_dpi *dpi, uint64_t *cmds, int cmd_count)
 		int count;
 		uint64_t *new_buff = dpi->chunk_next;
 
-		dpi->chunk_next =
-			(void *)roc_npa_aura_op_alloc(dpi->aura_handle, 0);
+		dpi->chunk_next = (void *)roc_npa_aura_op_alloc(dpi->aura_handle, 0);
 		if (!dpi->chunk_next) {
-			plt_err("Failed to alloc next buffer from NPA");
-			return -ENOMEM;
+			plt_dp_dbg("Failed to alloc next buffer from NPA");
+
+			/* NPA failed to allocate a buffer. Restoring chunk_next
+			 * to its original address.
+			 */
+			dpi->chunk_next = new_buff;
+			return -ENOSPC;
 		}
 
 		/*
@@ -276,13 +392,17 @@ __dpi_queue_write(struct roc_dpi *dpi, uint64_t *cmds, int cmd_count)
 		/* queue index may be greater than pool size */
 		if (dpi->chunk_head >= dpi->pool_size_m1) {
 			new_buff = dpi->chunk_next;
-			dpi->chunk_next =
-				(void *)roc_npa_aura_op_alloc(dpi->aura_handle,
-							      0);
+			dpi->chunk_next = (void *)roc_npa_aura_op_alloc(dpi->aura_handle, 0);
 			if (!dpi->chunk_next) {
-				plt_err("Failed to alloc next buffer from NPA");
-				return -ENOMEM;
+				plt_dp_dbg("Failed to alloc next buffer from NPA");
+
+				/* NPA failed to allocate a buffer. Restoring chunk_next
+				 * to its original address.
+				 */
+				dpi->chunk_next = new_buff;
+				return -ENOSPC;
 			}
+
 			/* Write next buffer address */
 			*ptr = (uint64_t)new_buff;
 			dpi->chunk_base = new_buff;
@@ -299,16 +419,16 @@ cnxk_dmadev_copy(void *dev_private, uint16_t vchan, rte_iova_t src, rte_iova_t d
 {
 	struct cnxk_dpi_vf_s *dpivf = dev_private;
 	struct cnxk_dpi_conf *dpi_conf = &dpivf->conf[vchan];
-	union dpi_instr_hdr_s *header = &dpivf->conf[vchan].hdr;
+	union dpi_instr_hdr_s *header = &dpi_conf->hdr;
 	struct cnxk_dpi_compl_s *comp_ptr;
+	uint64_t cmd[DPI_MAX_CMD_SIZE];
 	rte_iova_t fptr, lptr;
 	int num_words = 0;
 	int rc;
 
 	comp_ptr = dpi_conf->c_desc.compl_ptr[dpi_conf->c_desc.tail];
-	comp_ptr->cdata = DPI_REQ_CDATA;
 	header->cn9k.ptr = (uint64_t)comp_ptr;
-	STRM_INC(dpi_conf->c_desc);
+	STRM_INC(dpi_conf->c_desc, tail);
 
 	header->cn9k.nfst = 1;
 	header->cn9k.nlst = 1;
@@ -325,28 +445,32 @@ cnxk_dmadev_copy(void *dev_private, uint16_t vchan, rte_iova_t src, rte_iova_t d
 		lptr = dst;
 	}
 
-	dpivf->cmd[0] = header->u[0];
-	dpivf->cmd[1] = header->u[1];
-	dpivf->cmd[2] = header->u[2];
+	cmd[0] = header->u[0];
+	cmd[1] = header->u[1];
+	cmd[2] = header->u[2];
 	/* word3 is always 0 */
 	num_words += 4;
-	dpivf->cmd[num_words++] = length;
-	dpivf->cmd[num_words++] = fptr;
-	dpivf->cmd[num_words++] = length;
-	dpivf->cmd[num_words++] = lptr;
-
-	rc = __dpi_queue_write(&dpivf->rdpi, dpivf->cmd, num_words);
-	if (!rc) {
-		if (flags & RTE_DMA_OP_FLAG_SUBMIT) {
-			rte_wmb();
-			plt_write64(num_words,
-				    dpivf->rdpi.rbase + DPI_VDMA_DBELL);
-			dpivf->stats.submitted++;
-		}
-		dpivf->num_words += num_words;
+	cmd[num_words++] = length;
+	cmd[num_words++] = fptr;
+	cmd[num_words++] = length;
+	cmd[num_words++] = lptr;
+
+	rc = __dpi_queue_write(&dpivf->rdpi, cmd, num_words);
+	if (unlikely(rc)) {
+		STRM_DEC(dpi_conf->c_desc, tail);
+		return rc;
+	}
+
+	rte_wmb();
+	if (flags & RTE_DMA_OP_FLAG_SUBMIT) {
+		plt_write64(num_words, dpivf->rdpi.rbase + DPI_VDMA_DBELL);
+		dpi_conf->stats.submitted++;
+	} else {
+		dpi_conf->pnum_words += num_words;
+		dpi_conf->pending++;
 	}
 
-	return dpivf->desc_idx++;
+	return (dpi_conf->desc_idx++);
 }
 
 static int
@@ -355,61 +479,65 @@ cnxk_dmadev_copy_sg(void *dev_private, uint16_t vchan, const struct rte_dma_sge
 {
 	struct cnxk_dpi_vf_s *dpivf = dev_private;
 	struct cnxk_dpi_conf *dpi_conf = &dpivf->conf[vchan];
-	union dpi_instr_hdr_s *header = &dpivf->conf[vchan].hdr;
+	union dpi_instr_hdr_s *header = &dpi_conf->hdr;
 	const struct rte_dma_sge *fptr, *lptr;
 	struct cnxk_dpi_compl_s *comp_ptr;
+	uint64_t cmd[DPI_MAX_CMD_SIZE];
 	int num_words = 0;
 	int i, rc;
 
 	comp_ptr = dpi_conf->c_desc.compl_ptr[dpi_conf->c_desc.tail];
-	comp_ptr->cdata = DPI_REQ_CDATA;
 	header->cn9k.ptr = (uint64_t)comp_ptr;
-	STRM_INC(dpi_conf->c_desc);
+	STRM_INC(dpi_conf->c_desc, tail);
 
 	/*
 	 * For inbound case, src pointers are last pointers.
 	 * For all other cases, src pointers are first pointers.
 	 */
 	if (header->cn9k.xtype == DPI_XTYPE_INBOUND) {
-		header->cn9k.nfst = nb_dst & 0xf;
-		header->cn9k.nlst = nb_src & 0xf;
+		header->cn9k.nfst = nb_dst & DPI_MAX_POINTER;
+		header->cn9k.nlst = nb_src & DPI_MAX_POINTER;
 		fptr = &dst[0];
 		lptr = &src[0];
 	} else {
-		header->cn9k.nfst = nb_src & 0xf;
-		header->cn9k.nlst = nb_dst & 0xf;
+		header->cn9k.nfst = nb_src & DPI_MAX_POINTER;
+		header->cn9k.nlst = nb_dst & DPI_MAX_POINTER;
 		fptr = &src[0];
 		lptr = &dst[0];
 	}
 
-	dpivf->cmd[0] = header->u[0];
-	dpivf->cmd[1] = header->u[1];
-	dpivf->cmd[2] = header->u[2];
+	cmd[0] = header->u[0];
+	cmd[1] = header->u[1];
+	cmd[2] = header->u[2];
 	num_words += 4;
 	for (i = 0; i < header->cn9k.nfst; i++) {
-		dpivf->cmd[num_words++] = (uint64_t)fptr->length;
-		dpivf->cmd[num_words++] = fptr->addr;
+		cmd[num_words++] = (uint64_t)fptr->length;
+		cmd[num_words++] = fptr->addr;
 		fptr++;
 	}
 
 	for (i = 0; i < header->cn9k.nlst; i++) {
-		dpivf->cmd[num_words++] = (uint64_t)lptr->length;
-		dpivf->cmd[num_words++] = lptr->addr;
+		cmd[num_words++] = (uint64_t)lptr->length;
+		cmd[num_words++] = lptr->addr;
 		lptr++;
 	}
 
-	rc = __dpi_queue_write(&dpivf->rdpi, dpivf->cmd, num_words);
-	if (!rc) {
-		if (flags & RTE_DMA_OP_FLAG_SUBMIT) {
-			rte_wmb();
-			plt_write64(num_words,
-				    dpivf->rdpi.rbase + DPI_VDMA_DBELL);
-			dpivf->stats.submitted += nb_src;
-		}
-		dpivf->num_words += num_words;
+	rc = __dpi_queue_write(&dpivf->rdpi, cmd, num_words);
+	if (unlikely(rc)) {
+		STRM_DEC(dpi_conf->c_desc, tail);
+		return rc;
+	}
+
+	if (flags & RTE_DMA_OP_FLAG_SUBMIT) {
+		rte_wmb();
+		plt_write64(num_words, dpivf->rdpi.rbase + DPI_VDMA_DBELL);
+		dpi_conf->stats.submitted += nb_src;
+	} else {
+		dpi_conf->pnum_words += num_words;
+		dpi_conf->pending++;
 	}
 
-	return (rc < 0) ? rc : dpivf->desc_idx++;
+	return (dpi_conf->desc_idx++);
 }
 
 static int
@@ -418,16 +546,16 @@ cn10k_dmadev_copy(void *dev_private, uint16_t vchan, rte_iova_t src, rte_iova_t
 {
 	struct cnxk_dpi_vf_s *dpivf = dev_private;
 	struct cnxk_dpi_conf *dpi_conf = &dpivf->conf[vchan];
-	union dpi_instr_hdr_s *header = &dpivf->conf[vchan].hdr;
+	union dpi_instr_hdr_s *header = &dpi_conf->hdr;
 	struct cnxk_dpi_compl_s *comp_ptr;
+	uint64_t cmd[DPI_MAX_CMD_SIZE];
 	rte_iova_t fptr, lptr;
 	int num_words = 0;
 	int rc;
 
 	comp_ptr = dpi_conf->c_desc.compl_ptr[dpi_conf->c_desc.tail];
-	comp_ptr->cdata = DPI_REQ_CDATA;
 	header->cn10k.ptr = (uint64_t)comp_ptr;
-	STRM_INC(dpi_conf->c_desc);
+	STRM_INC(dpi_conf->c_desc, tail);
 
 	header->cn10k.nfst = 1;
 	header->cn10k.nlst = 1;
@@ -435,28 +563,32 @@ cn10k_dmadev_copy(void *dev_private, uint16_t vchan, rte_iova_t src, rte_iova_t
 	fptr = src;
 	lptr = dst;
 
-	dpivf->cmd[0] = header->u[0];
-	dpivf->cmd[1] = header->u[1];
-	dpivf->cmd[2] = header->u[2];
+	cmd[0] = header->u[0];
+	cmd[1] = header->u[1];
+	cmd[2] = header->u[2];
 	/* word3 is always 0 */
 	num_words += 4;
-	dpivf->cmd[num_words++] = length;
-	dpivf->cmd[num_words++] = fptr;
-	dpivf->cmd[num_words++] = length;
-	dpivf->cmd[num_words++] = lptr;
-
-	rc = __dpi_queue_write(&dpivf->rdpi, dpivf->cmd, num_words);
-	if (!rc) {
-		if (flags & RTE_DMA_OP_FLAG_SUBMIT) {
-			rte_wmb();
-			plt_write64(num_words,
-				    dpivf->rdpi.rbase + DPI_VDMA_DBELL);
-			dpivf->stats.submitted++;
-		}
-		dpivf->num_words += num_words;
+	cmd[num_words++] = length;
+	cmd[num_words++] = fptr;
+	cmd[num_words++] = length;
+	cmd[num_words++] = lptr;
+
+	rc = __dpi_queue_write(&dpivf->rdpi, cmd, num_words);
+	if (unlikely(rc)) {
+		STRM_DEC(dpi_conf->c_desc, tail);
+		return rc;
 	}
 
-	return dpivf->desc_idx++;
+	if (flags & RTE_DMA_OP_FLAG_SUBMIT) {
+		rte_wmb();
+		plt_write64(num_words, dpivf->rdpi.rbase + DPI_VDMA_DBELL);
+		dpi_conf->stats.submitted++;
+	} else {
+		dpi_conf->pnum_words += num_words;
+		dpi_conf->pending++;
+	}
+
+	return dpi_conf->desc_idx++;
 }
 
 static int
@@ -466,145 +598,212 @@ cn10k_dmadev_copy_sg(void *dev_private, uint16_t vchan, const struct rte_dma_sge
 {
 	struct cnxk_dpi_vf_s *dpivf = dev_private;
 	struct cnxk_dpi_conf *dpi_conf = &dpivf->conf[vchan];
-	union dpi_instr_hdr_s *header = &dpivf->conf[vchan].hdr;
+	union dpi_instr_hdr_s *header = &dpi_conf->hdr;
 	const struct rte_dma_sge *fptr, *lptr;
 	struct cnxk_dpi_compl_s *comp_ptr;
+	uint64_t cmd[DPI_MAX_CMD_SIZE];
 	int num_words = 0;
 	int i, rc;
 
 	comp_ptr = dpi_conf->c_desc.compl_ptr[dpi_conf->c_desc.tail];
-	comp_ptr->cdata = DPI_REQ_CDATA;
 	header->cn10k.ptr = (uint64_t)comp_ptr;
-	STRM_INC(dpi_conf->c_desc);
+	STRM_INC(dpi_conf->c_desc, tail);
 
-	header->cn10k.nfst = nb_src & 0xf;
-	header->cn10k.nlst = nb_dst & 0xf;
+	header->cn10k.nfst = nb_src & DPI_MAX_POINTER;
+	header->cn10k.nlst = nb_dst & DPI_MAX_POINTER;
 	fptr = &src[0];
 	lptr = &dst[0];
 
-	dpivf->cmd[0] = header->u[0];
-	dpivf->cmd[1] = header->u[1];
-	dpivf->cmd[2] = header->u[2];
+	cmd[0] = header->u[0];
+	cmd[1] = header->u[1];
+	cmd[2] = header->u[2];
 	num_words += 4;
 
 	for (i = 0; i < header->cn10k.nfst; i++) {
-		dpivf->cmd[num_words++] = (uint64_t)fptr->length;
-		dpivf->cmd[num_words++] = fptr->addr;
+		cmd[num_words++] = (uint64_t)fptr->length;
+		cmd[num_words++] = fptr->addr;
 		fptr++;
 	}
 
 	for (i = 0; i < header->cn10k.nlst; i++) {
-		dpivf->cmd[num_words++] = (uint64_t)lptr->length;
-		dpivf->cmd[num_words++] = lptr->addr;
+		cmd[num_words++] = (uint64_t)lptr->length;
+		cmd[num_words++] = lptr->addr;
 		lptr++;
 	}
 
-	rc = __dpi_queue_write(&dpivf->rdpi, dpivf->cmd, num_words);
-	if (!rc) {
-		if (flags & RTE_DMA_OP_FLAG_SUBMIT) {
-			rte_wmb();
-			plt_write64(num_words,
-				    dpivf->rdpi.rbase + DPI_VDMA_DBELL);
-			dpivf->stats.submitted += nb_src;
-		}
-		dpivf->num_words += num_words;
+	rc = __dpi_queue_write(&dpivf->rdpi, cmd, num_words);
+	if (unlikely(rc)) {
+		STRM_DEC(dpi_conf->c_desc, tail);
+		return rc;
+	}
+
+	if (flags & RTE_DMA_OP_FLAG_SUBMIT) {
+		rte_wmb();
+		plt_write64(num_words, dpivf->rdpi.rbase + DPI_VDMA_DBELL);
+		dpi_conf->stats.submitted += nb_src;
+	} else {
+		dpi_conf->pnum_words += num_words;
+		dpi_conf->pending++;
 	}
 
-	return (rc < 0) ? rc : dpivf->desc_idx++;
+	return (dpi_conf->desc_idx++);
 }
 
 static uint16_t
-cnxk_dmadev_completed(void *dev_private, uint16_t vchan, const uint16_t nb_cpls,
-		      uint16_t *last_idx, bool *has_error)
+cnxk_dmadev_completed(void *dev_private, uint16_t vchan, const uint16_t nb_cpls, uint16_t *last_idx,
+		      bool *has_error)
 {
 	struct cnxk_dpi_vf_s *dpivf = dev_private;
+	struct cnxk_dpi_conf *dpi_conf = &dpivf->conf[vchan];
+	struct cnxk_dpi_cdesc_data_s *c_desc = &dpi_conf->c_desc;
+	struct cnxk_dpi_compl_s *comp_ptr;
 	int cnt;
 
-	if (dpivf->stats.submitted == dpivf->stats.completed)
-		return 0;
-
 	for (cnt = 0; cnt < nb_cpls; cnt++) {
-		struct cnxk_dpi_compl_s *comp_ptr = dpivf->conf[vchan].c_desc.compl_ptr[cnt];
+		comp_ptr = c_desc->compl_ptr[c_desc->head];
 
 		if (comp_ptr->cdata) {
 			if (comp_ptr->cdata == DPI_REQ_CDATA)
 				break;
 			*has_error = 1;
-			dpivf->stats.errors++;
+			dpi_conf->stats.errors++;
+			STRM_INC(*c_desc, head);
 			break;
 		}
+
+		comp_ptr->cdata = DPI_REQ_CDATA;
+		STRM_INC(*c_desc, head);
 	}
 
-	*last_idx = cnt - 1;
-	dpivf->conf[vchan].c_desc.tail = cnt;
-	dpivf->stats.completed += cnt;
+	dpi_conf->stats.completed += cnt;
+	*last_idx = dpi_conf->stats.completed - 1;
 
 	return cnt;
 }
 
 static uint16_t
-cnxk_dmadev_completed_status(void *dev_private, uint16_t vchan,
-			     const uint16_t nb_cpls, uint16_t *last_idx,
-			     enum rte_dma_status_code *status)
+cnxk_dmadev_completed_status(void *dev_private, uint16_t vchan, const uint16_t nb_cpls,
+			     uint16_t *last_idx, enum rte_dma_status_code *status)
 {
 	struct cnxk_dpi_vf_s *dpivf = dev_private;
+	struct cnxk_dpi_conf *dpi_conf = &dpivf->conf[vchan];
+	struct cnxk_dpi_cdesc_data_s *c_desc = &dpi_conf->c_desc;
+	struct cnxk_dpi_compl_s *comp_ptr;
 	int cnt;
 
 	RTE_SET_USED(last_idx);
+
 	for (cnt = 0; cnt < nb_cpls; cnt++) {
-		struct cnxk_dpi_compl_s *comp_ptr = dpivf->conf[vchan].c_desc.compl_ptr[cnt];
+		comp_ptr = c_desc->compl_ptr[c_desc->head];
 		status[cnt] = comp_ptr->cdata;
 		if (status[cnt]) {
 			if (status[cnt] == DPI_REQ_CDATA)
 				break;
 
-			dpivf->stats.errors++;
+			dpi_conf->stats.errors++;
 		}
+		comp_ptr->cdata = DPI_REQ_CDATA;
+		STRM_INC(*c_desc, head);
 	}
 
-	*last_idx = cnt - 1;
-	dpivf->conf[vchan].c_desc.tail = 0;
-	dpivf->stats.completed += cnt;
+	dpi_conf->stats.completed += cnt;
+	*last_idx = dpi_conf->stats.completed - 1;
 
 	return cnt;
 }
 
+static uint16_t
+cnxk_damdev_burst_capacity(const void *dev_private, uint16_t vchan)
+{
+	const struct cnxk_dpi_vf_s *dpivf = (const struct cnxk_dpi_vf_s *)dev_private;
+	const struct cnxk_dpi_conf *dpi_conf = &dpivf->conf[vchan];
+	uint16_t burst_cap;
+
+	burst_cap = dpi_conf->c_desc.max_cnt -
+		    ((dpi_conf->stats.submitted - dpi_conf->stats.completed) + dpi_conf->pending) +
+		    1;
+
+	return burst_cap;
+}
+
 static int
-cnxk_dmadev_submit(void *dev_private, uint16_t vchan __rte_unused)
+cnxk_dmadev_submit(void *dev_private, uint16_t vchan)
 {
 	struct cnxk_dpi_vf_s *dpivf = dev_private;
+	struct cnxk_dpi_conf *dpi_conf = &dpivf->conf[vchan];
+	uint32_t num_words = dpi_conf->pnum_words;
+
+	if (!dpi_conf->pnum_words)
+		return 0;
 
 	rte_wmb();
-	plt_write64(dpivf->num_words, dpivf->rdpi.rbase + DPI_VDMA_DBELL);
-	dpivf->stats.submitted++;
+	plt_write64(num_words, dpivf->rdpi.rbase + DPI_VDMA_DBELL);
+
+	dpi_conf->stats.submitted += dpi_conf->pending;
+	dpi_conf->pnum_words = 0;
+	dpi_conf->pending = 0;
 
 	return 0;
 }
 
 static int
-cnxk_stats_get(const struct rte_dma_dev *dev, uint16_t vchan,
-	       struct rte_dma_stats *rte_stats, uint32_t size)
+cnxk_stats_get(const struct rte_dma_dev *dev, uint16_t vchan, struct rte_dma_stats *rte_stats,
+	       uint32_t size)
 {
 	struct cnxk_dpi_vf_s *dpivf = dev->fp_obj->dev_private;
-	struct rte_dma_stats *stats = &dpivf->stats;
-
-	RTE_SET_USED(vchan);
+	struct cnxk_dpi_conf *dpi_conf;
+	int i;
 
 	if (size < sizeof(rte_stats))
 		return -EINVAL;
 	if (rte_stats == NULL)
 		return -EINVAL;
 
-	*rte_stats = *stats;
+	/* Stats of all vchans requested. */
+	if (vchan == RTE_DMA_ALL_VCHAN) {
+		for (i = 0; i < dpivf->num_vchans; i++) {
+			dpi_conf = &dpivf->conf[i];
+			rte_stats->submitted += dpi_conf->stats.submitted;
+			rte_stats->completed += dpi_conf->stats.completed;
+			rte_stats->errors += dpi_conf->stats.errors;
+		}
+
+		goto done;
+	}
+
+	if (vchan >= MAX_VCHANS_PER_QUEUE)
+		return -EINVAL;
+
+	dpi_conf = &dpivf->conf[vchan];
+	*rte_stats = dpi_conf->stats;
+
+done:
 	return 0;
 }
 
 static int
-cnxk_stats_reset(struct rte_dma_dev *dev, uint16_t vchan __rte_unused)
+cnxk_stats_reset(struct rte_dma_dev *dev, uint16_t vchan)
 {
 	struct cnxk_dpi_vf_s *dpivf = dev->fp_obj->dev_private;
+	struct cnxk_dpi_conf *dpi_conf;
+	int i;
+
+	/* clear stats of all vchans. */
+	if (vchan == RTE_DMA_ALL_VCHAN) {
+		for (i = 0; i < dpivf->num_vchans; i++) {
+			dpi_conf = &dpivf->conf[i];
+			dpi_conf->stats = (struct rte_dma_stats){0};
+		}
+
+		return 0;
+	}
+
+	if (vchan >= MAX_VCHANS_PER_QUEUE)
+		return -EINVAL;
+
+	dpi_conf = &dpivf->conf[vchan];
+	dpi_conf->stats = (struct rte_dma_stats){0};
 
-	dpivf->stats = (struct rte_dma_stats){0};
 	return 0;
 }
 
@@ -631,8 +830,7 @@ static const struct rte_dma_dev_ops cnxk_dmadev_ops = {
 };
 
 static int
-cnxk_dmadev_probe(struct rte_pci_driver *pci_drv __rte_unused,
-		  struct rte_pci_device *pci_dev)
+cnxk_dmadev_probe(struct rte_pci_driver *pci_drv __rte_unused, struct rte_pci_device *pci_dev)
 {
 	struct cnxk_dpi_vf_s *dpivf = NULL;
 	char name[RTE_DEV_NAME_MAX_LEN];
@@ -651,8 +849,7 @@ cnxk_dmadev_probe(struct rte_pci_driver *pci_drv __rte_unused,
 	memset(name, 0, sizeof(name));
 	rte_pci_device_name(&pci_dev->addr, name, sizeof(name));
 
-	dmadev = rte_dma_pmd_allocate(name, pci_dev->device.numa_node,
-				      sizeof(*dpivf));
+	dmadev = rte_dma_pmd_allocate(name, pci_dev->device.numa_node, sizeof(*dpivf));
 	if (dmadev == NULL) {
 		plt_err("dma device allocation failed for %s", name);
 		return -ENOMEM;
@@ -669,6 +866,7 @@ cnxk_dmadev_probe(struct rte_pci_driver *pci_drv __rte_unused,
 	dmadev->fp_obj->submit = cnxk_dmadev_submit;
 	dmadev->fp_obj->completed = cnxk_dmadev_completed;
 	dmadev->fp_obj->completed_status = cnxk_dmadev_completed_status;
+	dmadev->fp_obj->burst_capacity = cnxk_damdev_burst_capacity;
 
 	if (pci_dev->id.subsystem_device_id == PCI_SUBSYSTEM_DEVID_CN10KA ||
 	    pci_dev->id.subsystem_device_id == PCI_SUBSYSTEM_DEVID_CN10KAS ||
@@ -687,6 +885,8 @@ cnxk_dmadev_probe(struct rte_pci_driver *pci_drv __rte_unused,
 	if (rc < 0)
 		goto err_out_free;
 
+	dmadev->state = RTE_DMA_DEV_READY;
+
 	return 0;
 
 err_out_free:
@@ -708,20 +908,17 @@ cnxk_dmadev_remove(struct rte_pci_device *pci_dev)
 }
 
 static const struct rte_pci_id cnxk_dma_pci_map[] = {
-	{
-		RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM,
-			       PCI_DEVID_CNXK_DPI_VF)
-	},
+	{RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_CNXK_DPI_VF)},
 	{
 		.vendor_id = 0,
 	},
 };
 
 static struct rte_pci_driver cnxk_dmadev = {
-	.id_table  = cnxk_dma_pci_map,
+	.id_table = cnxk_dma_pci_map,
 	.drv_flags = RTE_PCI_DRV_NEED_MAPPING | RTE_PCI_DRV_NEED_IOVA_AS_VA,
-	.probe     = cnxk_dmadev_probe,
-	.remove    = cnxk_dmadev_remove,
+	.probe = cnxk_dmadev_probe,
+	.remove = cnxk_dmadev_remove,
 };
 
 RTE_PMD_REGISTER_PCI(cnxk_dmadev_pci_driver, cnxk_dmadev);
diff --git a/drivers/dma/cnxk/cnxk_dmadev.h b/drivers/dma/cnxk/cnxk_dmadev.h
index 3483b30c27574..f375143b16639 100644
--- a/drivers/dma/cnxk/cnxk_dmadev.h
+++ b/drivers/dma/cnxk/cnxk_dmadev.h
@@ -4,17 +4,22 @@
 #ifndef CNXK_DMADEV_H
 #define CNXK_DMADEV_H
 
-#define DPI_MAX_POINTER		15
-#define DPI_QUEUE_STOP		0x0
-#define DPI_QUEUE_START		0x1
-#define STRM_INC(s)		((s).tail = ((s).tail + 1) % (s).max_cnt)
-#define DPI_MAX_DESC		1024
-#define MAX_VCHANS_PER_QUEUE	4
+#include <roc_api.h>
+
+#define DPI_MAX_POINTER	     15
+#define STRM_INC(s, var)     ((s).var = ((s).var + 1) & (s).max_cnt)
+#define STRM_DEC(s, var)     ((s).var = ((s).var - 1) == -1 ? (s).max_cnt : ((s).var - 1))
+#define DPI_MAX_DESC	     1024
+#define DPI_MIN_DESC	     2
+#define MAX_VCHANS_PER_QUEUE 4
 
 /* Set Completion data to 0xFF when request submitted,
  * upon successful request completion engine reset to completion status
  */
-#define DPI_REQ_CDATA		0xFF
+#define DPI_REQ_CDATA 0xFF
+
+#define CNXK_DPI_DEV_CONFIG (1ULL << 0)
+#define CNXK_DPI_DEV_START  (1ULL << 1)
 
 struct cnxk_dpi_compl_s {
 	uint64_t cdata;
@@ -22,7 +27,7 @@ struct cnxk_dpi_compl_s {
 };
 
 struct cnxk_dpi_cdesc_data_s {
-	struct cnxk_dpi_compl_s *compl_ptr[DPI_MAX_DESC];
+	struct cnxk_dpi_compl_s **compl_ptr;
 	uint16_t max_cnt;
 	uint16_t head;
 	uint16_t tail;
@@ -31,15 +36,18 @@ struct cnxk_dpi_cdesc_data_s {
 struct cnxk_dpi_conf {
 	union dpi_instr_hdr_s hdr;
 	struct cnxk_dpi_cdesc_data_s c_desc;
+	uint16_t pnum_words;
+	uint16_t pending;
+	uint16_t desc_idx;
+	uint16_t pad0;
+	struct rte_dma_stats stats;
 };
 
 struct cnxk_dpi_vf_s {
 	struct roc_dpi rdpi;
 	struct cnxk_dpi_conf conf[MAX_VCHANS_PER_QUEUE];
-	struct rte_dma_stats stats;
-	uint64_t cmd[DPI_MAX_CMD_SIZE];
-	uint32_t num_words;
-	uint16_t desc_idx;
-};
+	uint16_t num_vchans;
+	uint16_t flag;
+} __plt_cache_aligned;
 
 #endif
-- 
2.25.1

