From 8b723ab96b0175e0e7cb5de8b2793daec4a9fa37 Mon Sep 17 00:00:00 2001
From: Nithin Dabilpuram <ndabilpuram@marvell.com>
Date: Mon, 8 May 2023 17:34:54 +0530
Subject: [PATCH 471/955] net/cnxk: add support for reassembly of multi-seg
 pkts

Add support for HW reassembly of multi-seg pkts.
Also optimize the code for normal reassembly path.

Change-Id: I1ea3d04e4734eacc395a6f61560fc400882c0afc
Signed-off-by: Nithin Dabilpuram <ndabilpuram@marvell.com>
Reviewed-on: https://sj1git1.cavium.com/c/IP/SW/dataplane/dpdk/+/103263
Reviewed-by: Rahul Bhansali <rbhansali@marvell.com>
Reviewed-by: Jerin Jacob Kollanukkaran <jerinj@marvell.com>
Base-Builds: sa_ip-toolkits-Jenkins <sa_ip-toolkits-jenkins@marvell.com>
Tested-by: sa_ip-toolkits-Jenkins <sa_ip-toolkits-jenkins@marvell.com>
---
 drivers/event/cnxk/cn10k_worker.h |  11 +-
 drivers/net/cnxk/cn10k_rx.h       | 720 +++++++++++++++---------------
 2 files changed, 378 insertions(+), 353 deletions(-)

diff --git a/drivers/event/cnxk/cn10k_worker.h b/drivers/event/cnxk/cn10k_worker.h
index 5efcafd76ab51..18bc82694de08 100644
--- a/drivers/event/cnxk/cn10k_worker.h
+++ b/drivers/event/cnxk/cn10k_worker.h
@@ -18,7 +18,7 @@
 static __rte_always_inline void
 cn10k_wqe_to_mbuf(uint64_t wqe, const uint64_t __mbuf, uint8_t port_id,
 		  const uint32_t tag, const uint32_t flags,
-		  const void *const lookup_mem, uintptr_t cpth)
+		  const void *const lookup_mem, uintptr_t cpth, uintptr_t sa_base)
 {
 	const uint64_t mbuf_init = 0x100010000ULL | RTE_PKTMBUF_HEADROOM |
 				   (flags & NIX_RX_OFFLOAD_TSTAMP_F ? 8 : 0);
@@ -26,7 +26,7 @@ cn10k_wqe_to_mbuf(uint64_t wqe, const uint64_t __mbuf, uint8_t port_id,
 
 	cn10k_nix_cqe_to_mbuf((struct nix_cqe_hdr_s *)wqe, tag,
 			      (struct rte_mbuf *)mbuf, lookup_mem,
-			      mbuf_init | ((uint64_t)port_id) << 48, cpth, flags);
+			      mbuf_init | ((uint64_t)port_id) << 48, cpth, sa_base, flags);
 }
 
 static void
@@ -138,7 +138,7 @@ cn10k_process_vwqe(uintptr_t vwqe, uint16_t port_id, const uint32_t flags, struc
 		}
 
 		cn10k_nix_cqe_to_mbuf(cqe, cqe->tag, mbuf, lookup_mem,
-				      mbuf_init, cpth, flags);
+				      mbuf_init, cpth, sa_base, flags);
 
 		if (flags & NIX_RX_OFFLOAD_TSTAMP_F)
 			cn10k_sso_process_tstamp((uint64_t)wqe[0],
@@ -161,6 +161,8 @@ cn10k_sso_hws_post_process(struct cn10k_sso_hws *ws, uint64_t *u64,
 {
 	u64[0] = (u64[0] & (0x3ull << 32)) << 6 |
 		 (u64[0] & (0x3FFull << 36)) << 4 | (u64[0] & 0xffffffff);
+	uintptr_t sa_base = 0;
+
 	if (CNXK_EVENT_TYPE_FROM_TAG(u64[0]) == RTE_EVENT_TYPE_CRYPTODEV) {
 		u64[1] = cn10k_cpt_crypto_adapter_dequeue(u64[1]);
 	} else if (CNXK_EVENT_TYPE_FROM_TAG(u64[0]) == RTE_EVENT_TYPE_CRYPTODEV_VECTOR) {
@@ -185,7 +187,6 @@ cn10k_sso_hws_post_process(struct cn10k_sso_hws *ws, uint64_t *u64,
 				0x100010000ULL | RTE_PKTMBUF_HEADROOM |
 				(flags & NIX_RX_OFFLOAD_TSTAMP_F ? 8 : 0);
 			struct rte_mbuf *m;
-			uintptr_t sa_base;
 			uint64_t iova = 0;
 			uint8_t loff = 0;
 			uint16_t d_off;
@@ -221,7 +222,7 @@ cn10k_sso_hws_post_process(struct cn10k_sso_hws *ws, uint64_t *u64,
 
 		u64[0] = CNXK_CLR_SUB_EVENT(u64[0]);
 		cn10k_wqe_to_mbuf(u64[1], mbuf, port, u64[0] & 0xFFFFF, flags,
-				  ws->lookup_mem, cpth);
+				  ws->lookup_mem, cpth, sa_base);
 		if (flags & NIX_RX_OFFLOAD_TSTAMP_F)
 			cn10k_sso_process_tstamp(u64[1], mbuf,
 						 ws->tstamp[port]);
diff --git a/drivers/net/cnxk/cn10k_rx.h b/drivers/net/cnxk/cn10k_rx.h
index fe521138e01d7..34fafe2998cf2 100644
--- a/drivers/net/cnxk/cn10k_rx.h
+++ b/drivers/net/cnxk/cn10k_rx.h
@@ -144,18 +144,126 @@ nix_sec_flush_meta(uintptr_t laddr, uint16_t lmt_id, uint8_t loff,
 	roc_lmt_submit_steorl(lmt_id, pa);
 }
 
+#if defined(RTE_ARCH_ARM64)
+static __rte_always_inline uint64_t
+nix_sec_reass_frags_get(const struct cpt_parse_hdr_s *hdr, struct rte_mbuf **next_mbufs)
+{
+	const struct cpt_frag_info_s *finfo;
+	uint32_t offset = hdr->w2.fi_offset;
+	const uint64_t *frag_ptr;
+	uint64x2_t frags23;
+	uint16x4_t fsz_w1;
+
+	/* offset of 0 implies 256B, otherwise it implies offset*8B */
+	offset = (((offset - 1) & 0x1f) + 1) * 8;
+	finfo = RTE_PTR_ADD(hdr, offset);
+	frag_ptr = (const uint64_t *)(finfo + 1);
+	frags23 = vrev64q_u8(vld1q_u64(frag_ptr));
+
+	next_mbufs[0] = ((struct rte_mbuf *)rte_be_to_cpu_64(hdr->frag1_wqe_ptr) - 1);
+	next_mbufs[1] = ((struct rte_mbuf *)vgetq_lane_u64(frags23, 0) - 1);
+	next_mbufs[2] = ((struct rte_mbuf *)vgetq_lane_u64(frags23, 1) - 1);
+
+	fsz_w1 = vdup_n_u64(finfo->w1.u64);
+	fsz_w1 = vrev16_u8(fsz_w1);
+	return vget_lane_u64(fsz_w1, 0);
+}
+
+static __rte_always_inline void
+nix_sec_reass_first_frag_update(struct rte_mbuf *head, const uint8_t *m_ipptr,
+				uint64_t fsz, uint64_t cq_w1, uint16_t *ihl)
+{
+	union nix_rx_parse_u *rx = (union nix_rx_parse_u *)((uintptr_t)(head + 1) + 8);
+	uint16_t fragx_sum = vaddv_u16(vdup_n_u64(fsz));
+	uint8_t lcptr = rx->lcptr;
+	uint16_t tot_len;
+	uint32_t cksum;
+	uint8_t *ipptr;
+
+	ipptr = (uint8_t *)head->buf_addr + head->data_off + lcptr;
+	/* Find the L3 header length and update inner pkt based on meta lc type */
+	if (((cq_w1 >> 40) & 0xF) == NPC_LT_LC_IP) {
+		const struct rte_ipv4_hdr *m_hdr = (const struct rte_ipv4_hdr *)m_ipptr;
+		struct rte_ipv4_hdr *hdr = (struct rte_ipv4_hdr *)ipptr;
+
+		*ihl = (m_hdr->version_ihl & 0xf) << 2;
+
+		hdr->fragment_offset = 0;
+		tot_len = rte_cpu_to_be_16(fragx_sum + *ihl);
+		hdr->total_length = tot_len;
+		/* Perform incremental checksum based on meta pkt ip hdr */
+		cksum = m_hdr->hdr_checksum;
+		cksum += m_hdr->fragment_offset;
+		cksum += 0xFFFF;
+		cksum += m_hdr->total_length;
+		cksum += (uint16_t)(~tot_len);
+		cksum = (cksum & 0xFFFF) + ((cksum & 0xFFFF0000) >> 16);
+		hdr->hdr_checksum = cksum;
+
+		head->pkt_len = lcptr + *ihl + fragx_sum;
+	} else {
+		struct rte_ipv6_hdr *hdr = (struct rte_ipv6_hdr *)ipptr;
+		size_t ext_len = sizeof(struct rte_ipv6_hdr);
+		uint8_t *nxt_hdr = (uint8_t *)hdr;
+		int nh = hdr->proto;
+
+		*ihl = 0;
+		while (nh != -EINVAL) {
+			nxt_hdr += ext_len;
+			*ihl += ext_len;
+			nh = rte_ipv6_get_next_ext(nxt_hdr, nh, &ext_len);
+		}
+
+		/* Remove the frag header by moving header 8 bytes forward */
+		hdr->payload_len = rte_cpu_to_be_16(fragx_sum + *ihl -
+					8 - sizeof(struct rte_ipv6_hdr));
+
+		rte_memcpy(rte_pktmbuf_mtod_offset(head, void *, 8),
+			   rte_pktmbuf_mtod(head, void *),
+			   lcptr + sizeof(struct rte_ipv6_hdr));
+
+		head->data_len -= 8;
+		head->data_off += 8;
+		head->pkt_len = lcptr + *ihl - 8 + fragx_sum;
+	}
+}
+
+#else
+static __rte_always_inline uint64_t
+nix_sec_reass_frags_get(const struct cpt_parse_hdr_s *hdr, struct rte_mbuf **next_mbufs)
+{
+	RTE_SET_USED(hdr);
+	next_mbufs[0] = NULL;
+	next_mbufs[1] = NULL;
+	next_mbufs[2] = NULL;
+	return 0;
+}
+
+static __rte_always_inline void
+nix_sec_reass_first_frag_update(struct rte_mbuf *head, const uint8_t *m_ipptr,
+				uint64_t fsz, uint64_t cq_w1, uint16_t *ihl)
+{
+	RTE_SET_USED(head);
+	RTE_SET_USED(m_ipptr);
+	RTE_SET_USED(fsz);
+	RTE_SET_USED(cq_w1);
+	*ihl = 0;
+}
+#endif
+
 static struct rte_mbuf *
 nix_sec_attach_frags(const struct cpt_parse_hdr_s *hdr,
+		     struct rte_mbuf *head,
 		     struct cn10k_inb_priv_data *inb_priv,
 		     const uint64_t mbuf_init)
 {
-	struct rte_mbuf *head, *mbuf, *mbuf_prev;
-	uint32_t offset = hdr->w2.fi_offset;
+	uint8_t num_frags = hdr->w0.num_frags;
+	struct rte_mbuf *next_mbufs[3];
 	union nix_rx_parse_u *frag_rx;
-	struct cpt_frag_info_s *finfo;
-	uint64_t *frag_ptr = NULL;
+	struct rte_mbuf *mbuf;
 	uint64_t ol_flags;
 	uint16_t frag_size;
+	uint8_t frag_i = 0;
 	uint16_t rlen;
 	uint64_t *wqe;
 	int off;
@@ -164,79 +272,37 @@ nix_sec_attach_frags(const struct cpt_parse_hdr_s *hdr,
 	ol_flags = BIT_ULL(inb_priv->reass_dynflag_bit);
 	ol_flags |= RTE_MBUF_F_RX_SEC_OFFLOAD;
 
-	/* offset of 0 implies 256B, otherwise it implies offset*8B */
-	offset = (((offset - 1) & 0x1f) + 1) * 8;
-	finfo = RTE_PTR_ADD(hdr, offset);
+	/* Get frags list */
+	nix_sec_reass_frags_get(hdr, next_mbufs);
 
 	/* Frag-0: */
-	wqe = (uint64_t *)(rte_be_to_cpu_64(hdr->wqe_ptr));
+	wqe = (uint64_t *)(head + 1);
 	rlen = ((*(wqe + 10)) >> 16) & 0xFFFF;
 
 	frag_rx = (union nix_rx_parse_u *)(wqe + 1);
-	frag_size = rlen + frag_rx->lcptr - frag_rx->laptr;
-	frag_rx->pkt_lenm1 = frag_size - 1;
 
-	mbuf = (struct rte_mbuf *)((uintptr_t)wqe - sizeof(struct rte_mbuf));
-	*(uint64_t *)(&mbuf->rearm_data) = mbuf_init;
-	mbuf->data_len = frag_size;
-	mbuf->pkt_len = frag_size;
-	mbuf->ol_flags = ol_flags;
-	mbuf->next = NULL;
-	head = mbuf;
-	mbuf_prev = mbuf;
+	head->ol_flags = ol_flags;
 	/* Update dynamic field with userdata */
-	*rte_security_dynfield(mbuf) = (uint64_t)inb_priv->userdata;
-
-	cnxk_ip_reassembly_dynfield(head, off)->nb_frags = hdr->w0.num_frags - 1;
-	cnxk_ip_reassembly_dynfield(head, off)->next_frag = NULL;
-
-	/* Frag-1: */
-	if (hdr->w0.num_frags > 1) {
-		wqe = (uint64_t *)(rte_be_to_cpu_64(hdr->frag1_wqe_ptr));
-		rlen = ((*(wqe + 10)) >> 16) & 0xFFFF;
-
-		frag_rx = (union nix_rx_parse_u *)(wqe + 1);
-		frag_size = rlen + frag_rx->lcptr - frag_rx->laptr;
-		frag_rx->pkt_lenm1 = frag_size - 1;
-
-		mbuf = (struct rte_mbuf *)((uintptr_t)wqe -
-				sizeof(struct rte_mbuf));
-		*(uint64_t *)(&mbuf->rearm_data) = mbuf_init;
-		mbuf->data_len = frag_size;
-		mbuf->pkt_len = frag_size;
-		mbuf->ol_flags = ol_flags;
-		mbuf->next = NULL;
-
-		/* Update dynamic field with userdata */
-		*rte_security_dynfield(mbuf) = (uint64_t)inb_priv->userdata;
-
-		/* Mark frag as get */
-		RTE_MEMPOOL_CHECK_COOKIES(mbuf->pool, (void **)&mbuf, 1, 1);
+	*rte_security_dynfield(head) = (uint64_t)inb_priv->userdata;
 
-		cnxk_ip_reassembly_dynfield(mbuf, off)->nb_frags =
-			hdr->w0.num_frags - 2;
-		cnxk_ip_reassembly_dynfield(mbuf, off)->next_frag = NULL;
-		cnxk_ip_reassembly_dynfield(mbuf_prev, off)->next_frag = mbuf;
-		mbuf_prev = mbuf;
-	}
+	num_frags--;
+	mbuf = head;
 
-	/* Frag-2: */
-	if (hdr->w0.num_frags > 2) {
-		frag_ptr = (uint64_t *)(finfo + 1);
-		wqe = (uint64_t *)(rte_be_to_cpu_64(*frag_ptr));
+	/* Frag-1+: */
+	while (num_frags) {
+		cnxk_ip_reassembly_dynfield(mbuf, off)->next_frag = next_mbufs[frag_i];
+		cnxk_ip_reassembly_dynfield(mbuf, off)->nb_frags = num_frags;
+		mbuf = next_mbufs[frag_i];
+		wqe = (uint64_t *)(mbuf + 1);
 		rlen = ((*(wqe + 10)) >> 16) & 0xFFFF;
 
 		frag_rx = (union nix_rx_parse_u *)(wqe + 1);
 		frag_size = rlen + frag_rx->lcptr - frag_rx->laptr;
-		frag_rx->pkt_lenm1 = frag_size - 1;
 
-		mbuf = (struct rte_mbuf *)((uintptr_t)wqe -
-				sizeof(struct rte_mbuf));
 		*(uint64_t *)(&mbuf->rearm_data) = mbuf_init;
 		mbuf->data_len = frag_size;
 		mbuf->pkt_len = frag_size;
 		mbuf->ol_flags = ol_flags;
-		mbuf->next = NULL;
 
 		/* Update dynamic field with userdata */
 		*rte_security_dynfield(mbuf) = (uint64_t)inb_priv->userdata;
@@ -244,187 +310,95 @@ nix_sec_attach_frags(const struct cpt_parse_hdr_s *hdr,
 		/* Mark frag as get */
 		RTE_MEMPOOL_CHECK_COOKIES(mbuf->pool, (void **)&mbuf, 1, 1);
 
-		cnxk_ip_reassembly_dynfield(mbuf, off)->nb_frags =
-			hdr->w0.num_frags - 3;
-		cnxk_ip_reassembly_dynfield(mbuf, off)->next_frag = NULL;
-		cnxk_ip_reassembly_dynfield(mbuf_prev, off)->next_frag = mbuf;
-		mbuf_prev = mbuf;
+		num_frags--;
+		frag_i++;
 	}
+	cnxk_ip_reassembly_dynfield(mbuf, off)->nb_frags = 0;
+	cnxk_ip_reassembly_dynfield(mbuf, off)->next_frag = NULL;
 
-	/* Frag-3: */
-	if (hdr->w0.num_frags > 3) {
-		wqe = (uint64_t *)(rte_be_to_cpu_64(*(frag_ptr + 1)));
-		rlen = ((*(wqe + 10)) >> 16) & 0xFFFF;
-
-		frag_rx = (union nix_rx_parse_u *)(wqe + 1);
-		frag_size = rlen + frag_rx->lcptr - frag_rx->laptr;
-		frag_rx->pkt_lenm1 = frag_size - 1;
-
-		mbuf = (struct rte_mbuf *)((uintptr_t)wqe -
-				sizeof(struct rte_mbuf));
-		*(uint64_t *)(&mbuf->rearm_data) = mbuf_init;
-		mbuf->data_len = frag_size;
-		mbuf->pkt_len = frag_size;
-		mbuf->ol_flags = ol_flags;
-		mbuf->next = NULL;
-
-		/* Mark frag as get */
-		RTE_MEMPOOL_CHECK_COOKIES(mbuf->pool, (void **)&mbuf, 1, 1);
-
-		/* Update dynamic field with userdata */
-		*rte_security_dynfield(mbuf) = (uint64_t)inb_priv->userdata;
-
-		cnxk_ip_reassembly_dynfield(mbuf, off)->nb_frags =
-			hdr->w0.num_frags - 4;
-		cnxk_ip_reassembly_dynfield(mbuf, off)->next_frag = NULL;
-		cnxk_ip_reassembly_dynfield(mbuf_prev, off)->next_frag = mbuf;
-	}
 	return head;
 }
 
-static struct rte_mbuf *
-nix_sec_reassemble_frags(const struct cpt_parse_hdr_s *hdr, uint64_t cq_w1,
-			uint64_t cq_w5, uint64_t mbuf_init)
+static __rte_always_inline struct rte_mbuf *
+nix_sec_reassemble_frags(const struct cpt_parse_hdr_s *hdr, struct rte_mbuf *head,
+			 uint64_t cq_w1, uint64_t cq_w5, uint64_t mbuf_init)
 {
-	uint32_t fragx_sum, pkt_hdr_len, l3_hdr_size;
-	uint32_t offset = hdr->w2.fi_offset;
-	union nix_rx_parse_u *inner_rx;
-	uint16_t rlen, data_off, b_off;
+	uint8_t num_frags = hdr->w0.num_frags;
 	union nix_rx_parse_u *frag_rx;
-	struct cpt_frag_info_s *finfo;
-	struct rte_mbuf *head, *mbuf;
-	uint64_t *frag_ptr = NULL;
-	rte_iova_t *inner_iova;
+	struct rte_mbuf *next_mbufs[3];
+	uint16_t data_off, b_off;
+	const uint8_t *m_ipptr;
+	uint16_t l3_hdr_size;
+	struct rte_mbuf *mbuf;
 	uint16_t frag_size;
+	uint64_t fsz_w1;
 	uint64_t *wqe;
 
 	/* Base data offset */
 	b_off = mbuf_init & 0xFFFFUL;
 	mbuf_init &= ~0xFFFFUL;
 
-	/* offset of 0 implies 256B, otherwise it implies offset*8B */
-	offset = (((offset - 1) & 0x1f) + 1) * 8;
-	finfo = RTE_PTR_ADD(hdr, offset);
+	/* Get list of all fragments and frag sizes */
+	fsz_w1 = nix_sec_reass_frags_get(hdr, next_mbufs);
 
 	/* Frag-0: */
-	wqe = (uint64_t *)rte_be_to_cpu_64(hdr->wqe_ptr);
-	inner_rx = (union nix_rx_parse_u *)(wqe + 1);
-	inner_iova = (rte_iova_t *)*(wqe + 9);
-
-	/* Update only the upper 28-bits from meta pkt parse info */
-	*((uint64_t *)inner_rx) = ((*((uint64_t *)inner_rx) & ((1ULL << 36) - 1)) |
-				(cq_w1 & ~((1ULL << 36) - 1)));
-
-	rlen = ((*(wqe + 10)) >> 16) & 0xFFFF;
-	frag_size = rlen + ((cq_w5 >> 16) & 0xFF) - (cq_w5 & 0xFF);
-	fragx_sum = rte_be_to_cpu_16(finfo->w1.frag_size0);
-	pkt_hdr_len = frag_size - fragx_sum;
-
-	mbuf = (struct rte_mbuf *)((uintptr_t)wqe - sizeof(struct rte_mbuf));
-	*(uint64_t *)(&mbuf->rearm_data) = mbuf_init | b_off;
-	mbuf->data_len = frag_size;
-	head = mbuf;
+	wqe = (uint64_t *)(head + 1);
 
-	if (inner_rx->lctype == NPC_LT_LC_IP) {
-		struct rte_ipv4_hdr *hdr = (struct rte_ipv4_hdr *)
-				RTE_PTR_ADD(inner_iova, inner_rx->lcptr);
-
-		l3_hdr_size = (hdr->version_ihl & 0xf) << 2;
-	} else {
-		struct rte_ipv6_hdr *hdr = (struct rte_ipv6_hdr *)
-				RTE_PTR_ADD(inner_iova, inner_rx->lcptr);
-		size_t ext_len = sizeof(struct rte_ipv6_hdr);
-		uint8_t *nxt_hdr = (uint8_t *)hdr;
-		int nh = hdr->proto;
-
-		l3_hdr_size = 0;
-		while (nh != -EINVAL) {
-			nxt_hdr += ext_len;
-			l3_hdr_size += ext_len;
-			nh = rte_ipv6_get_next_ext(nxt_hdr, nh, &ext_len);
-		}
-	}
+	/* First fragment data len is already update by caller */
+	m_ipptr = ((const uint8_t *)hdr + ((cq_w5 >> 16) & 0xFF));
+	nix_sec_reass_first_frag_update(head, m_ipptr, fsz_w1, cq_w1, &l3_hdr_size);
+	fsz_w1 >>= 16;
 
 	/* Frag-1: */
-	wqe = (uint64_t *)(rte_be_to_cpu_64(hdr->frag1_wqe_ptr));
-	frag_size = rte_be_to_cpu_16(finfo->w1.frag_size1);
+	head->next = next_mbufs[0];
+	mbuf = next_mbufs[0];
+	wqe = (uint64_t *)(mbuf + 1);
 	frag_rx = (union nix_rx_parse_u *)(wqe + 1);
+	frag_size = fsz_w1 & 0xFFFF;
+	fsz_w1 >>= 16;
 
-	mbuf->next = (struct rte_mbuf *)((uintptr_t)wqe - sizeof(struct rte_mbuf));
-	mbuf = mbuf->next;
 	data_off = b_off + frag_rx->lcptr + l3_hdr_size;
 	*(uint64_t *)(&mbuf->rearm_data) = mbuf_init | data_off;
 	mbuf->data_len = frag_size;
-	fragx_sum += frag_size;
 
 	/* Mark frag as get */
 	RTE_MEMPOOL_CHECK_COOKIES(mbuf->pool, (void **)&mbuf, 1, 1);
 
 	/* Frag-2: */
-	if (hdr->w0.num_frags > 2) {
-		frag_ptr = (uint64_t *)(finfo + 1);
-		wqe = (uint64_t *)(rte_be_to_cpu_64(*frag_ptr));
-		frag_size = rte_be_to_cpu_16(finfo->w1.frag_size2);
+	if (num_frags > 2) {
+		mbuf->next = next_mbufs[1];
+		mbuf = next_mbufs[1];
+		wqe = (uint64_t *)(mbuf + 1);
 		frag_rx = (union nix_rx_parse_u *)(wqe + 1);
+		frag_size = fsz_w1 & 0xFFFF;
+		fsz_w1 >>= 16;
 
-		mbuf->next = (struct rte_mbuf *)((uintptr_t)wqe - sizeof(struct rte_mbuf));
-		mbuf = mbuf->next;
 		data_off = b_off + frag_rx->lcptr + l3_hdr_size;
 		*(uint64_t *)(&mbuf->rearm_data) = mbuf_init | data_off;
 		mbuf->data_len = frag_size;
-		fragx_sum += frag_size;
 
 		/* Mark frag as get */
 		RTE_MEMPOOL_CHECK_COOKIES(mbuf->pool, (void **)&mbuf, 1, 1);
 	}
 
 	/* Frag-3: */
-	if (hdr->w0.num_frags > 3) {
-		wqe = (uint64_t *)(rte_be_to_cpu_64(*(frag_ptr + 1)));
-		frag_size = rte_be_to_cpu_16(finfo->w1.frag_size3);
+	if (num_frags > 3) {
+		mbuf->next = next_mbufs[2];
+		mbuf = next_mbufs[2];
+		wqe = (uint64_t *)(mbuf + 1);
 		frag_rx = (union nix_rx_parse_u *)(wqe + 1);
+		frag_size = fsz_w1 & 0xFFFF;
+		fsz_w1 >>= 16;
 
-		mbuf->next = (struct rte_mbuf *)((uintptr_t)wqe - sizeof(struct rte_mbuf));
-		mbuf = mbuf->next;
 		data_off = b_off + frag_rx->lcptr + l3_hdr_size;
 		*(uint64_t *)(&mbuf->rearm_data) = mbuf_init | data_off;
 		mbuf->data_len = frag_size;
-		fragx_sum += frag_size;
 
 		/* Mark frag as get */
 		RTE_MEMPOOL_CHECK_COOKIES(mbuf->pool, (void **)&mbuf, 1, 1);
 	}
 
-	if (inner_rx->lctype == NPC_LT_LC_IP) {
-		struct rte_ipv4_hdr *hdr = (struct rte_ipv4_hdr *)
-				RTE_PTR_ADD(inner_iova, inner_rx->lcptr);
-
-		hdr->fragment_offset = 0;
-		hdr->total_length = rte_cpu_to_be_16(fragx_sum + l3_hdr_size);
-		hdr->hdr_checksum = 0;
-		hdr->hdr_checksum = rte_ipv4_cksum(hdr);
-
-		inner_rx->pkt_lenm1 = pkt_hdr_len + fragx_sum - 1;
-	} else {
-		/* Remove the frag header by moving header 8 bytes forward */
-		struct rte_ipv6_hdr *hdr = (struct rte_ipv6_hdr *)
-				RTE_PTR_ADD(inner_iova, inner_rx->lcptr);
-
-		hdr->payload_len = rte_cpu_to_be_16(fragx_sum + l3_hdr_size -
-					8 - sizeof(struct rte_ipv6_hdr));
-
-		rte_memcpy(rte_pktmbuf_mtod_offset(head, void *, 8),
-			   rte_pktmbuf_mtod(head, void *),
-			   inner_rx->lcptr + sizeof(struct rte_ipv6_hdr));
-
-		inner_rx->pkt_lenm1 = pkt_hdr_len + fragx_sum - 8 - 1;
-		head->data_len -= 8;
-		head->data_off += 8;
-	}
-	mbuf->next = NULL;
-	head->pkt_len = inner_rx->pkt_lenm1 + 1;
-	head->nb_segs = hdr->w0.num_frags;
-
+	head->nb_segs = num_frags;
 	return head;
 }
 
@@ -480,153 +454,89 @@ nix_sec_meta_to_mbuf_sc(uint64_t cq_w1, uint64_t cq_w5, const uint64_t sa_base,
 	void *inb_sa;
 	uint64_t w0;
 
-	if ((flags & NIX_RX_REAS_F) && (cq_w1 & BIT(11))) {
-		/* Get SPI from CPT_PARSE_S's cookie(already swapped) */
-		w0 = hdr->w0.u64;
-		sa_idx = w0 >> 32;
-
-		inb_sa = roc_nix_inl_ot_ipsec_inb_sa(sa_base, sa_idx);
-		inb_priv = roc_nix_inl_ot_ipsec_inb_sa_sw_rsvd(inb_sa);
-
-		if (!hdr->w0.num_frags) {
-			/* No Reassembly or inbound error */
-			if (hdr->w0.pkt_fmt == ROC_IE_OT_SA_PKT_FMT_FULL) {
-				inner = nix_sec_oop_process(hdr, mbuf, &mbuf_init);
-			} else {
-				inner = (struct rte_mbuf *)
-					(rte_be_to_cpu_64(hdr->wqe_ptr) -
-					 sizeof(struct rte_mbuf));
-			}
-
-			/* Update dynamic field with userdata */
-			*rte_security_dynfield(inner) =
-				(uint64_t)inb_priv->userdata;
-
-			/* Get ucc from cpt parse header */
-			ucc = hdr->w3.hw_ccode;
-
-			/* Calculate inner packet length as
-			 * IP total len + l2 len
-			 */
-			ip = (uintptr_t)hdr + ((cq_w5 >> 16) & 0xFF);
-			ip += ((cq_w1 >> 40) & 0x6);
-			len = rte_be_to_cpu_16(*(uint16_t *)ip);
-			len += ((cq_w5 >> 16) & 0xFF) - (cq_w5 & 0xFF);
-			len += (cq_w1 & BIT(42)) ? 40 : 0;
-
-			inner->pkt_len = len;
-			inner->data_len = len;
-			*(uint64_t *)(&inner->rearm_data) = mbuf_init;
-
-			inner->ol_flags = ((CPT_COMP_HWGOOD_MASK & (1U << ucc)) ?
-					   RTE_MBUF_F_RX_SEC_OFFLOAD :
-					   (RTE_MBUF_F_RX_SEC_OFFLOAD |
-					    RTE_MBUF_F_RX_SEC_OFFLOAD_FAILED));
-
-			ucc = hdr->w3.uc_ccode;
-
-			if (ucc && ucc < 0xED) {
-				inner->ol_flags |= RTE_MBUF_F_RX_SEC_OFFLOAD_FAILED;
-			} else {
-				ucc += 3; /* To make codes in 0xFx series except 0 */
-				inner->ol_flags |= ((ucc & 0xF0) == 0xF0) ?
-						   ((NIX_RX_SEC_UCC_CONST >> ((ucc & 0xF) << 3))
-						    & 0xFF) << 1 : RTE_MBUF_F_RX_IP_CKSUM_GOOD;
-			}
-		} else if ((!(hdr->w0.err_sum) || roc_ie_ot_ucc_is_success(hdr->w3.uc_ccode)) &&
-			   !(hdr->w0.reas_sts)) {
-			/* Reassembly success */
-			inner = nix_sec_reassemble_frags(hdr, cq_w1, cq_w5,
-							 mbuf_init);
-
-			/* Update dynamic field with userdata */
-			*rte_security_dynfield(inner) =
-				(uint64_t)inb_priv->userdata;
+	if (!(cq_w1 & BIT(11)))
+		return mbuf;
 
-			/* Assume success */
-			inner->ol_flags = RTE_MBUF_F_RX_SEC_OFFLOAD;
-		} else {
-			/* Reassembly failure */
-			inner = nix_sec_attach_frags(hdr, inb_priv, mbuf_init);
-		}
+	if (flags & NIX_RX_REAS_F && hdr->w0.pkt_fmt == ROC_IE_OT_SA_PKT_FMT_FULL) {
+		inner = nix_sec_oop_process(hdr, mbuf, &mbuf_init);
+	} else {
+		inner = (struct rte_mbuf *)(rte_be_to_cpu_64(hdr->wqe_ptr) -
+					    sizeof(struct rte_mbuf));
 
 		/* Store meta in lmtline to free
 		 * Assume all meta's from same aura.
 		 */
-		if (hdr->w0.pkt_fmt != ROC_IE_OT_SA_PKT_FMT_FULL) {
-			*(uint64_t *)(laddr + (*loff << 3)) = (uint64_t)mbuf;
-			*loff = *loff + 1;
-
-			/* Mark meta mbuf as put */
-			RTE_MEMPOOL_CHECK_COOKIES(mbuf->pool, (void **)&mbuf,
-						  1, 0);
-
-			/* Mark inner mbuf as get */
-			RTE_MEMPOOL_CHECK_COOKIES(inner->pool, (void **)&inner,
-						  1, 1);
-		}
-
-		return inner;
-	} else if (cq_w1 & BIT(11)) {
-		inner = (struct rte_mbuf *)(rte_be_to_cpu_64(hdr->wqe_ptr) -
-					    sizeof(struct rte_mbuf));
-
-		/* Get SPI from CPT_PARSE_S's cookie(already swapped) */
-		w0 = hdr->w0.u64;
-		sa_idx = w0 >> 32;
+		*(uint64_t *)(laddr + (*loff << 3)) = (uint64_t)mbuf;
+		*loff = *loff + 1;
+	}
 
-		inb_sa = roc_nix_inl_ot_ipsec_inb_sa(sa_base, sa_idx);
-		inb_priv = roc_nix_inl_ot_ipsec_inb_sa_sw_rsvd(inb_sa);
+	/* Get SPI from CPT_PARSE_S's cookie(already swapped) */
+	w0 = hdr->w0.u64;
+	sa_idx = w0 >> 32;
 
-		/* Update dynamic field with userdata */
-		*rte_security_dynfield(inner) = (uint64_t)inb_priv->userdata;
+	inb_sa = roc_nix_inl_ot_ipsec_inb_sa(sa_base, sa_idx);
+	inb_priv = roc_nix_inl_ot_ipsec_inb_sa_sw_rsvd(inb_sa);
 
-		/* Get ucc from cpt parse header */
-		ucc = hdr->w3.hw_ccode;
+	/* Update dynamic field with userdata */
+	*rte_security_dynfield(inner) = (uint64_t)inb_priv->userdata;
 
-		/* Calculate inner packet length as IP total len + l2 len */
-		ip = (uintptr_t)hdr + ((cq_w5 >> 16) & 0xFF);
-		ip += ((cq_w1 >> 40) & 0x6);
-		len = rte_be_to_cpu_16(*(uint16_t *)ip);
-		len += ((cq_w5 >> 16) & 0xFF) - (cq_w5 & 0xFF);
-		len += (cq_w1 & BIT(42)) ? 40 : 0;
+	/* Get ucc from cpt parse header */
+	ucc = hdr->w3.hw_ccode;
 
-		inner->pkt_len = len;
-		inner->data_len = len;
-		*(uint64_t *)(&inner->rearm_data) = mbuf_init;
+	/* Calculate inner packet length as IP total len + l2 len */
+	ip = (uintptr_t)hdr + ((cq_w5 >> 16) & 0xFF);
+	ip += ((cq_w1 >> 40) & 0x6);
+	len = rte_be_to_cpu_16(*(uint16_t *)ip);
+	len += ((cq_w5 >> 16) & 0xFF) - (cq_w5 & 0xFF);
+	len += (cq_w1 & BIT(42)) ? 40 : 0;
 
-		inner->ol_flags = ((CPT_COMP_HWGOOD_MASK & (1U << ucc)) ?
-				   RTE_MBUF_F_RX_SEC_OFFLOAD :
-				   (RTE_MBUF_F_RX_SEC_OFFLOAD |
-				    RTE_MBUF_F_RX_SEC_OFFLOAD_FAILED));
+	inner->pkt_len = len;
+	inner->data_len = len;
+	*(uint64_t *)(&inner->rearm_data) = mbuf_init;
 
-		ucc = hdr->w3.uc_ccode;
+	inner->ol_flags = ((CPT_COMP_HWGOOD_MASK & (1U << ucc)) ?
+			   RTE_MBUF_F_RX_SEC_OFFLOAD :
+			   (RTE_MBUF_F_RX_SEC_OFFLOAD |
+			    RTE_MBUF_F_RX_SEC_OFFLOAD_FAILED));
 
-		if (ucc && ucc < 0xED) {
-			inner->ol_flags |= RTE_MBUF_F_RX_SEC_OFFLOAD_FAILED;
-		} else {
-			ucc += 3; /* To make codes in 0xFx series except 0 */
-			inner->ol_flags |= ((ucc & 0xF0) == 0xF0) ?
-					   ((NIX_RX_SEC_UCC_CONST >> ((ucc & 0xF) << 3))
-					    & 0xFF) << 1 : RTE_MBUF_F_RX_IP_CKSUM_GOOD;
-		}
+	ucc = hdr->w3.uc_ccode;
 
-		/* Store meta in lmtline to free
-		 * Assume all meta's from same aura.
-		 */
-		*(uint64_t *)(laddr + (*loff << 3)) = (uint64_t)mbuf;
-		*loff = *loff + 1;
+	if (ucc && ucc < 0xED) {
+		inner->ol_flags |= RTE_MBUF_F_RX_SEC_OFFLOAD_FAILED;
+	} else {
+		ucc += 3; /* To make codes in 0xFx series except 0 */
+		inner->ol_flags |= ((ucc & 0xF0) == 0xF0) ?
+			((NIX_RX_SEC_UCC_CONST >> ((ucc & 0xF) << 3))
+			 & 0xFF) << 1 : RTE_MBUF_F_RX_IP_CKSUM_GOOD;
+	}
 
+	if (!(flags & NIX_RX_REAS_F) || hdr->w0.pkt_fmt != ROC_IE_OT_SA_PKT_FMT_FULL) {
 		/* Mark meta mbuf as put */
 		RTE_MEMPOOL_CHECK_COOKIES(mbuf->pool, (void **)&mbuf, 1, 0);
 
 		/* Mark inner mbuf as get */
 		RTE_MEMPOOL_CHECK_COOKIES(inner->pool, (void **)&inner, 1, 1);
-
-		return inner;
 	}
 
-	return mbuf;
+	/* Skip reassembly processing when multi-seg is enabled */
+	if (!(flags & NIX_RX_MULTI_SEG_F) && (flags & NIX_RX_REAS_F) && hdr->w0.num_frags) {
+		if ((!(hdr->w0.err_sum) || roc_ie_ot_ucc_is_success(hdr->w3.uc_ccode)) &&
+		    !(hdr->w0.reas_sts)) {
+			/* Reassembly success */
+			nix_sec_reassemble_frags(hdr, inner, cq_w1, cq_w5, mbuf_init);
+
+			/* Update dynamic field with userdata */
+			*rte_security_dynfield(inner) =
+				(uint64_t)inb_priv->userdata;
+
+			/* Assume success */
+			inner->ol_flags = RTE_MBUF_F_RX_SEC_OFFLOAD;
+		} else {
+			/* Reassembly failure */
+			nix_sec_attach_frags(hdr, inner, inb_priv, mbuf_init);
+		}
+	}
+	return inner;
 }
 
 #if defined(RTE_ARCH_ARM64)
@@ -657,11 +567,16 @@ nix_sec_meta_to_mbuf(uint64_t cq_w1, uint64_t cq_w5, uintptr_t inb_sa,
 	    hdr->w0.pkt_fmt != ROC_IE_OT_SA_PKT_FMT_FULL)
 		RTE_MEMPOOL_CHECK_COOKIES(inner->pool, (void **)&inner, 1, 1);
 
-	if (flags & NIX_RX_REAS_F && hdr->w0.num_frags) {
+	if (!(flags & NIX_RX_MULTI_SEG_F) && flags & NIX_RX_REAS_F && hdr->w0.num_frags) {
 		if ((!(hdr->w0.err_sum) || roc_ie_ot_ucc_is_success(hdr->w3.uc_ccode)) &&
 		    !(hdr->w0.reas_sts)) {
+			/* First frag len */
+			inner->pkt_len = vgetq_lane_u16(*rx_desc_field1, 2);
+			inner->data_len = vgetq_lane_u16(*rx_desc_field1, 4);
+			*(uint64_t *)(&inner->rearm_data) = mbuf_init;
+
 			/* Reassembly success */
-			nix_sec_reassemble_frags(hdr, cq_w1, cq_w5, mbuf_init);
+			nix_sec_reassemble_frags(hdr, inner, cq_w1, cq_w5, mbuf_init);
 
 			/* Assume success */
 			*ol_flags |= RTE_MBUF_F_RX_SEC_OFFLOAD;
@@ -677,14 +592,8 @@ nix_sec_meta_to_mbuf(uint64_t cq_w1, uint64_t cq_w5, uintptr_t inb_sa,
 			*rearm = vsetq_lane_u64(mbuf_init, *rearm, 0);
 		} else {
 			/* Reassembly failure */
-			nix_sec_attach_frags(hdr, inb_priv, mbuf_init);
+			nix_sec_attach_frags(hdr, inner, inb_priv, mbuf_init);
 			*ol_flags |= inner->ol_flags;
-
-			/* Update pkt_len and data_len */
-			*rx_desc_field1 = vsetq_lane_u16(inner->pkt_len,
-							 *rx_desc_field1, 2);
-			*rx_desc_field1 = vsetq_lane_u16(inner->data_len,
-							 *rx_desc_field1, 4);
 		}
 	} else if (flags & NIX_RX_REAS_F) {
 		/* Without fragmentation but may have to handle OOP session */
@@ -755,64 +664,104 @@ nix_update_match_id(const uint16_t match_id, uint64_t ol_flags,
 
 static __rte_always_inline void
 nix_cqe_xtract_mseg(const union nix_rx_parse_u *rx, struct rte_mbuf *mbuf,
-		    uint64_t rearm, uintptr_t cpth, const uint16_t flags)
+		    uint64_t rearm, uintptr_t cpth, uintptr_t sa_base, const uint16_t flags)
 {
+	const struct cpt_parse_hdr_s *hdr = (const struct cpt_parse_hdr_s *)cpth;
+	struct cn10k_inb_priv_data *inb_priv = NULL;
+	uint8_t num_frags = 0, frag_i = 0;
+	struct rte_mbuf *next_mbufs[3];
 	const rte_iova_t *iova_list;
+	bool reas_success = false;
 	uint16_t later_skip = 0;
 	struct rte_mbuf *head;
 	const rte_iova_t *eol;
+	uint64_t cq_w5 = 0;
+	uint16_t ihl = 0;
+	uint64_t fsz = 0;
+	int dyn_off = 0;
 	uint8_t nb_segs;
+	uint16_t sg_len;
 	uint64_t cq_w1;
 	int64_t len;
 	uint64_t sg;
 
 	cq_w1 = *(const uint64_t *)rx;
+	if (flags & NIX_RX_REAS_F)
+		cq_w5 = *((const uint64_t *)rx + 4);
 	/* Use inner rx parse for meta pkts sg list */
 	if (cq_w1 & BIT(11) && flags & NIX_RX_OFFLOAD_SECURITY_F) {
-		const struct cpt_parse_hdr_s *hdr = (const struct cpt_parse_hdr_s *)cpth;
 		const uint64_t *wqe = (const uint64_t *)(mbuf + 1);
 
-		if (!(flags & NIX_RX_REAS_F) || hdr->w0.pkt_fmt != ROC_IE_OT_SA_PKT_FMT_FULL)
+		if (hdr->w0.pkt_fmt != ROC_IE_OT_SA_PKT_FMT_FULL)
 			rx = (const union nix_rx_parse_u *)(wqe + 1);
 	}
 
 	sg = *(const uint64_t *)(rx + 1);
 	nb_segs = (sg >> 48) & 0x3;
 
-	if (nb_segs == 1)
+	if (nb_segs == 1 && !(flags & NIX_RX_REAS_F))
 		return;
 
 	/* For security we have already updated right pkt_len */
-	if (cq_w1 & BIT(11) && flags & NIX_RX_OFFLOAD_SECURITY_F)
+	if (cq_w1 & BIT(11) && flags & NIX_RX_OFFLOAD_SECURITY_F) {
 		len = mbuf->pkt_len;
-	else
+
+		/* Handle reassembly with multi segs */
+		if (flags & NIX_RX_REAS_F && hdr->w0.num_frags) {
+			void *inb_sa;
+
+			num_frags = hdr->w0.num_frags;
+			inb_sa = roc_nix_inl_ot_ipsec_inb_sa(sa_base, hdr->w0.u64 >> 32);
+			inb_priv = roc_nix_inl_ot_ipsec_inb_sa_sw_rsvd(inb_sa);
+			ihl = 0;
+
+			dyn_off = inb_priv->reass_dynfield_off;
+			fsz = nix_sec_reass_frags_get(hdr, next_mbufs);
+			num_frags -= 1;
+
+			if (!(hdr->w0.reas_sts) &&
+			    (!(hdr->w0.err_sum) ||
+			     roc_ie_ot_ucc_is_success(hdr->w3.uc_ccode)))
+				reas_success = true;
+		}
+	} else {
 		len = rx->pkt_lenm1 + 1;
+	}
+
 	mbuf->pkt_len = len - (flags & NIX_RX_OFFLOAD_TSTAMP_F ? CNXK_NIX_TIMESYNC_RX_OFFSET : 0);
+	mbuf->nb_segs = nb_segs;
+	head = mbuf;
 	mbuf->data_len =
 		(sg & 0xFFFF) - (flags & NIX_RX_OFFLOAD_TSTAMP_F ? CNXK_NIX_TIMESYNC_RX_OFFSET : 0);
+	eol = ((const rte_iova_t *)(rx + 1) + ((rx->desc_sizem1 + 1) << 1));
+again:
 	len -= mbuf->data_len;
-	mbuf->nb_segs = nb_segs;
 	sg = sg >> 16;
-
-	eol = ((const rte_iova_t *)(rx + 1) + ((rx->desc_sizem1 + 1) << 1));
 	/* Skip SG_S and first IOVA*/
 	iova_list = ((const rte_iova_t *)(rx + 1)) + 2;
 	nb_segs--;
 
-	rearm = rearm & ~0xFFFF;
 	later_skip = (uintptr_t)mbuf->buf_addr - (uintptr_t)mbuf;
 
-	head = mbuf;
 	while (nb_segs) {
 		mbuf->next = (struct rte_mbuf *)(*iova_list - later_skip);
 		mbuf = mbuf->next;
 
 		RTE_MEMPOOL_CHECK_COOKIES(mbuf->pool, (void **)&mbuf, 1, 1);
 
-		mbuf->data_len = sg & 0xFFFF;
-		len -= sg & 0XFFFF;
+		sg_len = sg & 0XFFFF;
+		if (flags & NIX_RX_OFFLOAD_SECURITY_F) {
+			/* Adjust last mbuf data length with negative offset for
+			 * security pkts if needed.
+			 */
+			len -= sg_len;
+			sg_len = (len > 0) ? sg_len : (sg_len + len);
+			len = (len > 0) ? len : 0;
+		}
+
+		mbuf->data_len = sg_len;
 		sg = sg >> 16;
-		*(uint64_t *)(&mbuf->rearm_data) = rearm;
+		*(uint64_t *)(&mbuf->rearm_data) = rearm & ~0xFFFF;
 		nb_segs--;
 		iova_list++;
 
@@ -824,15 +773,90 @@ nix_cqe_xtract_mseg(const union nix_rx_parse_u *rx, struct rte_mbuf *mbuf,
 		}
 	}
 
-	/* Adjust last mbuf data length with negative offset for security pkts if needed */
-	if (cq_w1 & BIT(11) && flags & NIX_RX_OFFLOAD_SECURITY_F && len < 0)
-		mbuf->data_len += len;
+	if ((flags & NIX_RX_REAS_F) && (cq_w1 & BIT(11)) && num_frags) {
+		struct rte_mbuf *next_frag = next_mbufs[frag_i];
+		uint16_t lcptr, ldptr = 0;
+
+		rx = (const union nix_rx_parse_u *)((uintptr_t)(next_frag + 1) + 8);
+		lcptr = (*((const uint64_t *)rx + 4) >> 16) & 0xFF;
+		eol = ((const rte_iova_t *)(rx + 1) + ((rx->desc_sizem1 + 1) << 1));
+		sg = *(const uint64_t *)(rx + 1);
+		nb_segs = (sg >> 48) & 0x3;
+
+		if (reas_success) {
+			/* Update first fragment info */
+			if (!frag_i) {
+				const uint8_t *ipptr;
+
+				ipptr = ((const uint8_t *)hdr + ((cq_w5 >> 16) & 0xFF));
+				nix_sec_reass_first_frag_update(head, ipptr, fsz, cq_w1, &ihl);
+				fsz >>= 16;
+			}
+			mbuf->next = next_frag;
+			head->nb_segs += nb_segs;
+			len = fsz & 0xFFFF;
+			fsz >>= 16;
+			ldptr = ihl + lcptr;
+		} else {
+			len = ((eol[0] >> 16) & 0xFFFF) + lcptr;
+			head->ol_flags |= BIT_ULL(inb_priv->reass_dynflag_bit) |
+				RTE_MBUF_F_RX_SEC_OFFLOAD;
+			cnxk_ip_reassembly_dynfield(head, dyn_off)->next_frag = next_frag;
+			cnxk_ip_reassembly_dynfield(head, dyn_off)->nb_frags = num_frags;
+			/* Update dynamic field with userdata from prev head */
+			*rte_security_dynfield(next_frag) = *rte_security_dynfield(head);
+			head = next_frag;
+			head->pkt_len = len - (flags & NIX_RX_OFFLOAD_TSTAMP_F ?
+					       CNXK_NIX_TIMESYNC_RX_OFFSET : 0);
+			head->nb_segs = nb_segs;
+		}
+		mbuf = next_frag;
+		*(uint64_t *)(&mbuf->rearm_data) = rearm + ldptr;
+		mbuf->data_len = (sg & 0xFFFF) - ldptr -
+				 (flags & NIX_RX_OFFLOAD_TSTAMP_F ?
+				  CNXK_NIX_TIMESYNC_RX_OFFSET : 0);
+		RTE_MEMPOOL_CHECK_COOKIES(mbuf->pool, (void **)&mbuf, 1, 1);
+		num_frags--;
+		frag_i++;
+		goto again;
+	} else if ((flags & NIX_RX_REAS_F) && (cq_w1 & BIT(11)) && !reas_success &&
+		   hdr->w0.pkt_fmt == ROC_IE_OT_SA_PKT_FMT_FULL) {
+		uintptr_t wqe = rte_be_to_cpu_64(hdr->wqe_ptr);
+
+		/* Process OOP packet inner buffer mseg. reas_success flag is used here only
+		 * to avoid looping.
+		 */
+		mbuf = ((struct rte_mbuf *)wqe) - 1;
+		rx = (const union nix_rx_parse_u *)(wqe + 8);
+		eol = ((const rte_iova_t *)(rx + 1) + ((rx->desc_sizem1 + 1) << 1));
+		sg = *(const uint64_t *)(rx + 1);
+		nb_segs = (sg >> 48) & 0x3;
+
+
+		len = mbuf->pkt_len;
+		*(uint64_t *)(&mbuf->rearm_data) = rearm;
+		mbuf->data_len = (sg & 0xFFFF) -
+				 (flags & NIX_RX_OFFLOAD_TSTAMP_F ?
+				  CNXK_NIX_TIMESYNC_RX_OFFSET : 0);
+		head = mbuf;
+		head->nb_segs = nb_segs;
+		/* Using this flag to avoid looping in case of OOP */
+		reas_success = true;
+		goto again;
+	}
+
+	/* Update for last failure fragment */
+	if ((flags & NIX_RX_REAS_F) && frag_i && !reas_success) {
+		cnxk_ip_reassembly_dynfield(head, dyn_off)->next_frag = NULL;
+		cnxk_ip_reassembly_dynfield(head, dyn_off)->nb_frags = 0;
+	}
 }
 
 static __rte_always_inline void
 cn10k_nix_cqe_to_mbuf(const struct nix_cqe_hdr_s *cq, const uint32_t tag,
 		      struct rte_mbuf *mbuf, const void *lookup_mem,
-		      const uint64_t val, const uintptr_t cpth, const uint16_t flag)
+		      const uint64_t val, const uintptr_t cpth, const uintptr_t sa_base,
+		      const uint16_t flag)
 {
 	const union nix_rx_parse_u *rx =
 		(const union nix_rx_parse_u *)((const uint64_t *)cq + 1);
@@ -886,7 +910,7 @@ cn10k_nix_cqe_to_mbuf(const struct nix_cqe_hdr_s *cq, const uint32_t tag,
 		 * timestamp data process.
 		 * Hence, timestamp flag argument is not required.
 		 */
-		nix_cqe_xtract_mseg(rx, mbuf, val, cpth, flag & ~NIX_RX_OFFLOAD_TSTAMP_F);
+		nix_cqe_xtract_mseg(rx, mbuf, val, cpth, sa_base, flag & ~NIX_RX_OFFLOAD_TSTAMP_F);
 }
 
 static inline uint16_t
@@ -1015,7 +1039,7 @@ cn10k_nix_recv_pkts(void *rx_queue, struct rte_mbuf **rx_pkts, uint16_t pkts,
 		}
 
 		cn10k_nix_cqe_to_mbuf(cq, cq->tag, mbuf, lookup_mem, mbuf_init,
-				      cpth, flags);
+				      cpth, sa_base, flags);
 		cn10k_nix_mbuf_to_tstamp(mbuf, rxq->tstamp,
 					(flags & NIX_RX_OFFLOAD_TSTAMP_F),
 					(uint64_t *)((uint8_t *)mbuf
@@ -1842,16 +1866,16 @@ cn10k_nix_recv_pkts_vector(void *args, struct rte_mbuf **mbufs, uint16_t pkts,
 			 */
 			nix_cqe_xtract_mseg((union nix_rx_parse_u *)
 					    (CQE_PTR_OFF(cq0, 0, 8, flags)),
-					    mbuf0, mbuf_initializer, cpth0, flags);
+					    mbuf0, mbuf_initializer, cpth0, sa_base, flags);
 			nix_cqe_xtract_mseg((union nix_rx_parse_u *)
 					    (CQE_PTR_OFF(cq0, 1, 8, flags)),
-					    mbuf1, mbuf_initializer, cpth1, flags);
+					    mbuf1, mbuf_initializer, cpth1, sa_base, flags);
 			nix_cqe_xtract_mseg((union nix_rx_parse_u *)
 					    (CQE_PTR_OFF(cq0, 2, 8, flags)),
-					    mbuf2, mbuf_initializer, cpth2, flags);
+					    mbuf2, mbuf_initializer, cpth2, sa_base, flags);
 			nix_cqe_xtract_mseg((union nix_rx_parse_u *)
 					    (CQE_PTR_OFF(cq0, 3, 8, flags)),
-					    mbuf3, mbuf_initializer, cpth3, flags);
+					    mbuf3, mbuf_initializer, cpth3, sa_base, flags);
 		}
 
 		/* Store the mbufs to rx_pkts */
-- 
2.25.1

