From 71e57c75981c80f2f15008c37afcc9ab43fd502d Mon Sep 17 00:00:00 2001
From: Vamsi Attunuru <vattunuru@marvell.com>
Date: Sun, 30 Jul 2023 08:38:49 -0700
Subject: [PATCH 560/955] net/octeon_ep: sync with 23.03

sync with 23.03-devel driver

Signed-off-by: Vamsi Attunuru <vattunuru@marvell.com>
Change-Id: I758363c49276d786378548b4f660b7e4c1625a66
Reviewed-on: https://sj1git1.cavium.com/c/IP/SW/dataplane/dpdk/+/108483
Base-Builds: sa_ip-toolkits-Jenkins <sa_ip-toolkits-jenkins@marvell.com>
Tested-by: sa_ip-toolkits-Jenkins <sa_ip-toolkits-jenkins@marvell.com>
Reviewed-by: Jerin Jacob Kollanukkaran <jerinj@marvell.com>
---
 drivers/net/octeon_ep/cnxk_ep_vf.c    |  91 ++++------
 drivers/net/octeon_ep/cnxk_ep_vf.h    |  26 ++-
 drivers/net/octeon_ep/meson.build     |   2 -
 drivers/net/octeon_ep/otx2_ep_vf.c    | 247 +++++++++++++-------------
 drivers/net/octeon_ep/otx2_ep_vf.h    | 157 ++++++++++++----
 drivers/net/octeon_ep/otx_ep_common.h |  86 ++++-----
 drivers/net/octeon_ep/otx_ep_ethdev.c | 229 +++++++++++-------------
 drivers/net/octeon_ep/otx_ep_irq.c    | 183 -------------------
 drivers/net/octeon_ep/otx_ep_irq.h    |  12 --
 drivers/net/octeon_ep/otx_ep_mbox.c   |   8 +-
 drivers/net/octeon_ep/otx_ep_rxtx.c   |  45 +++--
 drivers/net/octeon_ep/otx_ep_rxtx.h   |   3 +-
 drivers/net/octeon_ep/otx_ep_vf.c     |  15 +-
 drivers/net/octeon_ep/otx_ep_vf.h     |  23 ---
 14 files changed, 460 insertions(+), 667 deletions(-)
 delete mode 100644 drivers/net/octeon_ep/otx_ep_irq.c
 delete mode 100644 drivers/net/octeon_ep/otx_ep_irq.h

diff --git a/drivers/net/octeon_ep/cnxk_ep_vf.c b/drivers/net/octeon_ep/cnxk_ep_vf.c
index 92e44f8a72fc7..92c2d2ca5c6e2 100644
--- a/drivers/net/octeon_ep/cnxk_ep_vf.c
+++ b/drivers/net/octeon_ep/cnxk_ep_vf.c
@@ -2,14 +2,12 @@
  * Copyright(C) 2022 Marvell.
  */
 
+#include <inttypes.h>
 #include <errno.h>
 
 #include <rte_common.h>
 #include <rte_cycles.h>
 #include <rte_memzone.h>
-#include <rte_spinlock.h>
-#include <rte_interrupts.h>
-
 #include "otx_ep_common.h"
 #include "cnxk_ep_vf.h"
 
@@ -55,35 +53,31 @@ static int
 cnxk_ep_vf_setup_global_input_regs(struct otx_ep_device *otx_ep)
 {
 	uint64_t q_no = 0ull;
-	int ret = 0;
 
 	for (q_no = 0; q_no < (otx_ep->sriov_info.rings_per_vf); q_no++)
 		cnxk_ep_vf_setup_global_iq_reg(otx_ep, q_no);
-
-	return ret;
+	return 0;
 }
 
 static int
 cnxk_ep_vf_setup_global_output_regs(struct otx_ep_device *otx_ep)
 {
 	uint32_t q_no;
-	int ret = 0;
 
 	for (q_no = 0; q_no < (otx_ep->sriov_info.rings_per_vf); q_no++)
 		cnxk_ep_vf_setup_global_oq_reg(otx_ep, q_no);
-
-	return ret;
+	return 0;
 }
 
 static int
 cnxk_ep_vf_setup_device_regs(struct otx_ep_device *otx_ep)
 {
 	int ret;
+
 	ret = cnxk_ep_vf_setup_global_input_regs(otx_ep);
 	if (ret)
 		return ret;
 	ret = cnxk_ep_vf_setup_global_output_regs(otx_ep);
-
 	return ret;
 }
 
@@ -91,7 +85,7 @@ static int
 cnxk_ep_vf_setup_iq_regs(struct otx_ep_device *otx_ep, uint32_t iq_no)
 {
 	struct otx_ep_instr_queue *iq = otx_ep->instr_queue[iq_no];
-	uint64_t loop = OTX_EP_BUSY_LOOP_COUNT;
+	int loop = OTX_EP_BUSY_LOOP_COUNT;
 	volatile uint64_t reg_val = 0ull;
 	uint64_t ism_addr;
 
@@ -107,7 +101,7 @@ cnxk_ep_vf_setup_iq_regs(struct otx_ep_device *otx_ep, uint32_t iq_no)
 		} while ((!(reg_val & CNXK_EP_R_IN_CTL_IDLE)) && loop--);
 	}
 
-	if (!loop) {
+	if (loop < 0) {
 		otx_ep_err("IDLE bit is not set\n");
 		return -EIO;
 	}
@@ -131,7 +125,7 @@ cnxk_ep_vf_setup_iq_regs(struct otx_ep_device *otx_ep, uint32_t iq_no)
 		rte_delay_ms(1);
 	} while (reg_val != 0 && loop--);
 
-	if (!loop) {
+	if (loop < 0) {
 		otx_ep_err("INST CNT REGISTER is not zero\n");
 		return -EIO;
 	}
@@ -150,11 +144,10 @@ cnxk_ep_vf_setup_iq_regs(struct otx_ep_device *otx_ep, uint32_t iq_no)
 	iq->inst_cnt_ism =
 		(uint32_t *)((uint8_t *)otx_ep->ism_buffer_mz->addr
 			     + CNXK_EP_IQ_ISM_OFFSET(iq_no));
-	otx_ep_err("SDP_R[%d] INST Q ISM virt: %p, dma: %p", iq_no,
-		   (void *)iq->inst_cnt_ism, (void *)ism_addr);
+	otx_ep_err("SDP_R[%d] INST Q ISM virt: %p, dma: 0x%" PRIX64, iq_no,
+		   (void *)iq->inst_cnt_ism, ism_addr);
 	*iq->inst_cnt_ism = 0;
 	iq->inst_cnt_ism_prev = 0;
-
 	return 0;
 }
 
@@ -163,7 +156,7 @@ cnxk_ep_vf_setup_oq_regs(struct otx_ep_device *otx_ep, uint32_t oq_no)
 {
 	volatile uint64_t reg_val = 0ull;
 	uint64_t oq_ctl = 0ull;
-	uint64_t loop = OTX_EP_BUSY_LOOP_COUNT;
+	int loop = OTX_EP_BUSY_LOOP_COUNT;
 	struct otx_ep_droq *droq = otx_ep->droq[oq_no];
 	uint64_t ism_addr;
 
@@ -173,22 +166,19 @@ cnxk_ep_vf_setup_oq_regs(struct otx_ep_device *otx_ep, uint32_t oq_no)
 	reg_val = oct_ep_read64(otx_ep->hw_addr + CNXK_EP_R_OUT_CONTROL(oq_no));
 
 	while ((!(reg_val & CNXK_EP_R_OUT_CTL_IDLE)) && loop--) {
-		reg_val = oct_ep_read64(otx_ep->hw_addr +
-				CNXK_EP_R_OUT_CONTROL(oq_no));
+		reg_val = oct_ep_read64(otx_ep->hw_addr + CNXK_EP_R_OUT_CONTROL(oq_no));
+		rte_delay_ms(1);
 	}
 
-	if (!loop) {
+	if (loop < 0) {
 		otx_ep_err("OUT CNT REGISTER value is zero\n");
 		return -EIO;
 	}
 
-	oct_ep_write64(droq->desc_ring_dma, otx_ep->hw_addr +
-			CNXK_EP_R_OUT_SLIST_BADDR(oq_no));
-	oct_ep_write64(droq->nb_desc, otx_ep->hw_addr +
-			CNXK_EP_R_OUT_SLIST_RSIZE(oq_no));
+	oct_ep_write64(droq->desc_ring_dma, otx_ep->hw_addr + CNXK_EP_R_OUT_SLIST_BADDR(oq_no));
+	oct_ep_write64(droq->nb_desc, otx_ep->hw_addr + CNXK_EP_R_OUT_SLIST_RSIZE(oq_no));
 
-	oq_ctl = oct_ep_read64(otx_ep->hw_addr +
-			CNXK_EP_R_OUT_CONTROL(oq_no));
+	oq_ctl = oct_ep_read64(otx_ep->hw_addr + CNXK_EP_R_OUT_CONTROL(oq_no));
 
 	/* Clear the ISIZE and BSIZE (22-0) */
 	oq_ctl &= ~(OTX_EP_CLEAR_ISIZE_BSIZE);
@@ -196,20 +186,17 @@ cnxk_ep_vf_setup_oq_regs(struct otx_ep_device *otx_ep, uint32_t oq_no)
 	/* Populate the BSIZE (15-0) */
 	oq_ctl |= (droq->buffer_size & OTX_EP_DROQ_BUFSZ_MASK);
 
-	oct_ep_write64(oq_ctl, otx_ep->hw_addr +
-			CNXK_EP_R_OUT_CONTROL(oq_no));
+	oct_ep_write64(oq_ctl, otx_ep->hw_addr + CNXK_EP_R_OUT_CONTROL(oq_no));
 
 	/* Mapped address of the pkt_sent and pkts_credit regs */
-	droq->pkts_sent_reg = (uint8_t *)otx_ep->hw_addr +
-				CNXK_EP_R_OUT_CNTS(oq_no);
+	droq->pkts_sent_reg = (uint8_t *)otx_ep->hw_addr + CNXK_EP_R_OUT_CNTS(oq_no);
 	droq->pkts_credit_reg = (uint8_t *)otx_ep->hw_addr + CNXK_EP_R_OUT_SLIST_DBELL(oq_no);
 
-	rte_write64(OTX_EP_CLEAR_OUT_INT_LVLS,
-			otx_ep->hw_addr + CNXK_EP_R_OUT_INT_LEVELS(oq_no));
+	rte_write64(OTX_EP_CLEAR_OUT_INT_LVLS, otx_ep->hw_addr + CNXK_EP_R_OUT_INT_LEVELS(oq_no));
 
 	/* Clear PKT_CNT register */
 	rte_write64(OTX_EP_CLEAR_SDP_OUT_PKT_CNT, (uint8_t *)otx_ep->hw_addr +
-			CNXK_EP_R_OUT_PKT_CNT(oq_no));
+		    CNXK_EP_R_OUT_PKT_CNT(oq_no));
 
 	/* Clear the OQ doorbell  */
 	rte_write32(OTX_EP_CLEAR_SLIST_DBELL, droq->pkts_credit_reg);
@@ -219,52 +206,49 @@ cnxk_ep_vf_setup_oq_regs(struct otx_ep_device *otx_ep, uint32_t oq_no)
 		rte_delay_ms(1);
 	}
 
-	if (!loop) {
+	if (loop < 0) {
 		otx_ep_err("Packets credit register value is not cleared\n");
 		return -EIO;
 	}
 
-	otx_ep_dbg("SDP_R[%d]_credit:%x", oq_no,
-		   rte_read32(droq->pkts_credit_reg));
+	otx_ep_dbg("SDP_R[%d]_credit:%x", oq_no, rte_read32(droq->pkts_credit_reg));
 
 	/* Clear the OQ_OUT_CNTS doorbell  */
 	reg_val = rte_read32(droq->pkts_sent_reg);
 	rte_write32((uint32_t)reg_val, droq->pkts_sent_reg);
 
-	otx_ep_dbg("SDP_R[%d]_sent: %x", oq_no,
-			rte_read32(droq->pkts_sent_reg));
+	otx_ep_dbg("SDP_R[%d]_sent: %x", oq_no, rte_read32(droq->pkts_sent_reg));
 	/* Set up ISM registers and structures */
 	ism_addr = (otx_ep->ism_buffer_mz->iova | CNXK_EP_ISM_EN
-			| CNXK_EP_ISM_MSIX_DIS)
-			+ CNXK_EP_OQ_ISM_OFFSET(oq_no);
+		    | CNXK_EP_ISM_MSIX_DIS)
+		    + CNXK_EP_OQ_ISM_OFFSET(oq_no);
 	rte_write64(ism_addr, (uint8_t *)otx_ep->hw_addr +
-			CNXK_EP_R_OUT_CNTS_ISM(oq_no));
+		    CNXK_EP_R_OUT_CNTS_ISM(oq_no));
 	droq->pkts_sent_ism =
-			(uint32_t *)((uint8_t *)otx_ep->ism_buffer_mz->addr
-			+ CNXK_EP_OQ_ISM_OFFSET(oq_no));
-	otx_ep_err("SDP_R[%d] OQ ISM virt: %p, dma: %p", oq_no,
-		(void *)droq->pkts_sent_ism, (void *)ism_addr);
+		(uint32_t *)((uint8_t *)otx_ep->ism_buffer_mz->addr
+			     + CNXK_EP_OQ_ISM_OFFSET(oq_no));
+	otx_ep_err("SDP_R[%d] OQ ISM virt: %p dma: 0x%" PRIX64,
+		    oq_no, (void *)droq->pkts_sent_ism, ism_addr);
 	*droq->pkts_sent_ism = 0;
 	droq->pkts_sent_ism_prev = 0;
 
 	loop = OTX_EP_BUSY_LOOP_COUNT;
-
-	while (((rte_read32(droq->pkts_sent_reg)) != 0ull)) {
+	while (((rte_read32(droq->pkts_sent_reg)) != 0ull) && loop--) {
 		reg_val = rte_read32(droq->pkts_sent_reg);
 		rte_write32((uint32_t)reg_val, droq->pkts_sent_reg);
 		rte_delay_ms(1);
 	}
 
-	if (!loop) {
+	if (loop < 0) {
 		otx_ep_err("Packets sent register value is not cleared\n");
 		return -EIO;
 	}
 
-	otx_ep_dbg("SDP_R[%d]_sent: %x", oq_no,
-			rte_read32(droq->pkts_sent_reg));
+	otx_ep_dbg("SDP_R[%d]_sent: %x", oq_no, rte_read32(droq->pkts_sent_reg));
 
 	/* Set Watermark for backpressure */
-	oct_ep_write64(OTX_EP_OQ_WMARK_MIN, otx_ep->hw_addr + CNXK_EP_R_OUT_WMARK(oq_no));
+	oct_ep_write64(OTX_EP_OQ_WMARK_MIN,
+		       otx_ep->hw_addr + CNXK_EP_R_OUT_WMARK(oq_no));
 
 	return 0;
 }
@@ -272,7 +256,7 @@ cnxk_ep_vf_setup_oq_regs(struct otx_ep_device *otx_ep, uint32_t oq_no)
 static int
 cnxk_ep_vf_enable_iq(struct otx_ep_device *otx_ep, uint32_t q_no)
 {
-	uint64_t loop = OTX_EP_BUSY_LOOP_COUNT;
+	int loop = OTX_EP_BUSY_LOOP_COUNT;
 	uint64_t reg_val = 0ull;
 
 	/* Resetting doorbells during IQ enabling also to handle abrupt
@@ -285,7 +269,7 @@ cnxk_ep_vf_enable_iq(struct otx_ep_device *otx_ep, uint32_t q_no)
 		rte_delay_ms(1);
 	}
 
-	if (!loop) {
+	if (loop < 0) {
 		otx_ep_err("INSTR DBELL not coming back to 0\n");
 		return -EIO;
 	}
@@ -433,5 +417,6 @@ cnxk_ep_vf_setup_device(struct otx_ep_device *otx_ep)
 
 	otx_ep->fn_list.enable_oq           = cnxk_ep_vf_enable_oq;
 	otx_ep->fn_list.disable_oq          = cnxk_ep_vf_disable_oq;
+
 	return 0;
 }
diff --git a/drivers/net/octeon_ep/cnxk_ep_vf.h b/drivers/net/octeon_ep/cnxk_ep_vf.h
index 1a74511f51e42..86277449eae8f 100644
--- a/drivers/net/octeon_ep/cnxk_ep_vf.h
+++ b/drivers/net/octeon_ep/cnxk_ep_vf.h
@@ -5,7 +5,7 @@
 #define _CNXK_EP_VF_H_
 
 #include <rte_io.h>
-#include "otx_ep_common.h"
+
 #define CNXK_CONFIG_XPANSION_BAR             0x38
 #define CNXK_CONFIG_PCIE_CAP                 0x70
 #define CNXK_CONFIG_PCIE_DEVCAP              0x74
@@ -56,10 +56,9 @@
 #define CNXK_EP_R_IN_BYTE_CNT(ring)            \
 	(CNXK_EP_R_IN_BYTE_CNT_START +  ((ring) * CNXK_EP_RING_OFFSET))
 
-#define CNXK_EP_R_IN_CNTS_ISM(ring)               \
+#define CNXK_EP_R_IN_CNTS_ISM(ring)            \
 	(CNXK_EP_R_IN_CNTS_ISM_START + ((ring) * CNXK_EP_RING_OFFSET))
 
-
 /** Rings per Virtual Function **/
 #define CNXK_EP_R_IN_CTL_RPVF_MASK	(0xF)
 #define	CNXK_EP_R_IN_CTL_RPVF_POS	(48)
@@ -93,6 +92,10 @@
 #define CNXK_EP_R_OUT_BYTE_CNT_START       0x10190
 #define CNXK_EP_R_OUT_CNTS_ISM_START       0x10510
 
+#define CNXK_EP_R_MBOX_PF_VF_DATA_START    0x10210
+#define CNXK_EP_R_MBOX_VF_PF_DATA_START    0x10230
+#define CNXK_EP_R_MBOX_PF_VF_INT_START     0x10220
+
 #define CNXK_EP_R_OUT_CNTS(ring)                \
 	(CNXK_EP_R_OUT_CNTS_START + ((ring) * CNXK_EP_RING_OFFSET))
 
@@ -123,15 +126,15 @@
 #define CNXK_EP_R_OUT_BYTE_CNT(ring)             \
 	(CNXK_EP_R_OUT_BYTE_CNT_START + ((ring) * CNXK_EP_RING_OFFSET))
 
-#define CNXK_EP_R_OUT_CNTS_ISM(ring)              \
+#define CNXK_EP_R_OUT_CNTS_ISM(ring)             \
 	(CNXK_EP_R_OUT_CNTS_ISM_START + ((ring) * CNXK_EP_RING_OFFSET))
 
-#define CNXK_EP_R_MBOX_PF_VF_DATA_START      0x10210
-#define CNXK_EP_R_MBOX_VF_PF_DATA_START      0x10230
-
-#define CNXK_EP_R_MBOX_VF_PF_DATA(ring)           \
+#define CNXK_EP_R_MBOX_VF_PF_DATA(ring)          \
 	(CNXK_EP_R_MBOX_VF_PF_DATA_START + ((ring) * CNXK_EP_RING_OFFSET))
 
+#define CNXK_EP_R_MBOX_PF_VF_INT(ring)           \
+	(CNXK_EP_R_MBOX_PF_VF_INT_START + ((ring) * CNXK_EP_RING_OFFSET))
+
 /*------------------ R_OUT Masks ----------------*/
 #define CNXK_EP_R_OUT_INT_LEVELS_BMODE       (1ULL << 63)
 #define CNXK_EP_R_OUT_INT_LEVELS_TIMET       (32)
@@ -147,7 +150,6 @@
 #define CNXK_EP_R_OUT_CTL_NSR_P              (1ULL << 25)
 #define CNXK_EP_R_OUT_CTL_ROR_P              (1ULL << 24)
 #define CNXK_EP_R_OUT_CTL_IMODE              (1ULL << 23)
-#define CNXK_EP_R_IN_CNTS_OUT_INT            (1ULL << 62)
 
 #define PCI_DEVID_CN10KA_EP_NET_VF		0xB903
 #define PCI_DEVID_CNF10KA_EP_NET_VF		0xBA03
@@ -175,14 +177,10 @@ struct cnxk_ep_instr_64B {
 	/* Additional headers available in a 64-byte instruction. */
 	uint64_t exhdr[4];
 };
+
 #define CNXK_EP_IQ_ISM_OFFSET(queue)    (RTE_CACHE_LINE_SIZE * (queue) + 4)
 #define CNXK_EP_OQ_ISM_OFFSET(queue)    (RTE_CACHE_LINE_SIZE * (queue))
 #define CNXK_EP_ISM_EN                  (0x1)
 #define CNXK_EP_ISM_MSIX_DIS            (0x2)
-#define CNXK_EP_MAX_RX_PKT_LEN          (16384)
-#define OTX_EP_R_MBOX_PF_VF_INT_START        (0x10220)
-#define OTX_EP_RING_OFFSET                   (0x1ull << 17)
-#define OTX_EP_R_MBOX_PF_VF_INT(ring) \
-	(OTX_EP_R_MBOX_PF_VF_INT_START + ((ring) * OTX_EP_RING_OFFSET))
 
 #endif /*_CNXK_EP_VF_H_ */
diff --git a/drivers/net/octeon_ep/meson.build b/drivers/net/octeon_ep/meson.build
index 23c95fd9ebb26..e698bf9792208 100644
--- a/drivers/net/octeon_ep/meson.build
+++ b/drivers/net/octeon_ep/meson.build
@@ -2,13 +2,11 @@
 # Copyright(C) 2021 Marvell.
 #
 
-
 sources = files(
         'otx_ep_ethdev.c',
         'otx_ep_rxtx.c',
         'otx_ep_vf.c',
         'otx2_ep_vf.c',
         'cnxk_ep_vf.c',
-        'otx_ep_irq.c',
         'otx_ep_mbox.c',
 )
diff --git a/drivers/net/octeon_ep/otx2_ep_vf.c b/drivers/net/octeon_ep/otx2_ep_vf.c
index 2b9790595dcc0..ced3a415a5bd3 100644
--- a/drivers/net/octeon_ep/otx2_ep_vf.c
+++ b/drivers/net/octeon_ep/otx2_ep_vf.c
@@ -6,96 +6,87 @@
 
 #include <rte_common.h>
 #include <rte_cycles.h>
-#include <rte_spinlock.h>
-#include <rte_interrupts.h>
-
 #include <rte_memzone.h>
 #include "otx_ep_common.h"
-#include "cnxk_ep_vf.h"
 #include "otx2_ep_vf.h"
 
-#define MAX_INTR_VEC_ID RTE_MAX_RXTX_INTR_VEC_ID
-#define MSIX_IRQ_SET_BUF_LEN (sizeof(struct vfio_irq_set) + \
-			      sizeof(int) * (MAX_INTR_VEC_ID))
-
 static int otx2_vf_enable_rxq_intr(struct otx_ep_device *otx_epvf,
 				   uint16_t q_no);
 
 static int
 otx2_vf_reset_iq(struct otx_ep_device *otx_ep, int q_no)
 {
-	int loop = OTX2_EP_BUSY_LOOP_COUNT;
+	int loop = SDP_VF_BUSY_LOOP_COUNT;
 	volatile uint64_t d64 = 0ull;
 
 	/* There is no RST for a ring.
 	 * Clear all registers one by one after disabling the ring
 	 */
 
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_IN_ENABLE(q_no));
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_IN_INSTR_BADDR(q_no));
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_IN_INSTR_RSIZE(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_IN_ENABLE(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_IN_INSTR_BADDR(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_IN_INSTR_RSIZE(q_no));
 
 	d64 = 0xFFFFFFFF; /* ~0ull */
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_IN_INSTR_DBELL(q_no));
-	d64 = otx2_read64(otx_ep->hw_addr + CNXK_EP_R_IN_INSTR_DBELL(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_IN_INSTR_DBELL(q_no));
+	d64 = otx2_read64(otx_ep->hw_addr + SDP_VF_R_IN_INSTR_DBELL(q_no));
 
 	while ((d64 != 0) && loop--) {
 		rte_delay_ms(1);
 		d64 = otx2_read64(otx_ep->hw_addr +
-				  CNXK_EP_R_IN_INSTR_DBELL(q_no));
+				  SDP_VF_R_IN_INSTR_DBELL(q_no));
 	}
 	if (loop < 0) {
 		otx_ep_err("%s: doorbell init retry limit exceeded.\n", __func__);
 		return -EIO;
 	}
 
-	loop = OTX2_EP_BUSY_LOOP_COUNT;
+	loop = SDP_VF_BUSY_LOOP_COUNT;
 	do {
-		d64 = otx2_read64(otx_ep->hw_addr + CNXK_EP_R_IN_CNTS(q_no));
-		otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_IN_CNTS(q_no));
+		d64 = otx2_read64(otx_ep->hw_addr + SDP_VF_R_IN_CNTS(q_no));
+		otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_IN_CNTS(q_no));
 		rte_delay_ms(1);
-	} while ((d64 & ~CNXK_EP_R_IN_CNTS_OUT_INT) != 0 && loop--);
+	} while ((d64 & ~SDP_VF_R_IN_CNTS_OUT_INT) != 0 && loop--);
 	if (loop < 0) {
 		otx_ep_err("%s: in_cnts init retry limit exceeded.\n", __func__);
 		return -EIO;
 	}
 
 	d64 = 0ull;
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_IN_INT_LEVELS(q_no));
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_IN_PKT_CNT(q_no));
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_IN_BYTE_CNT(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_IN_INT_LEVELS(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_IN_PKT_CNT(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_IN_BYTE_CNT(q_no));
 
 	return 0;
 }
 
-
 static int
 otx2_vf_reset_oq(struct otx_ep_device *otx_ep, int q_no)
 {
-	int loop = OTX2_EP_BUSY_LOOP_COUNT;
+	int loop = SDP_VF_BUSY_LOOP_COUNT;
 	volatile uint64_t d64 = 0ull;
 
-	otx2_write64(d64, otx_ep->hw_addr + OTX2_EP_R_OUT_ENABLE(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_OUT_ENABLE(q_no));
 
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_OUT_SLIST_BADDR(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_OUT_SLIST_BADDR(q_no));
 
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_OUT_SLIST_RSIZE(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_OUT_SLIST_RSIZE(q_no));
 
 	d64 = 0xFFFFFFFF;
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_OUT_SLIST_DBELL(q_no));
-	d64 = otx2_read64(otx_ep->hw_addr + CNXK_EP_R_OUT_SLIST_DBELL(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_OUT_SLIST_DBELL(q_no));
+	d64 = otx2_read64(otx_ep->hw_addr + SDP_VF_R_OUT_SLIST_DBELL(q_no));
 	while ((d64 != 0) && loop--) {
 		rte_delay_ms(1);
 		d64 = otx2_read64(otx_ep->hw_addr +
-				  CNXK_EP_R_OUT_SLIST_DBELL(q_no));
+				  SDP_VF_R_OUT_SLIST_DBELL(q_no));
 	}
 	if (loop < 0) {
 		otx_ep_err("%s: doorbell init retry limit exceeded.\n", __func__);
 		return -EIO;
 	}
 
-	if (otx2_read64(otx_ep->hw_addr + CNXK_EP_R_OUT_CNTS(q_no))
-	    & OTX2_EP_R_OUT_CNTS_OUT_INT) {
+	if (otx2_read64(otx_ep->hw_addr + SDP_VF_R_OUT_CNTS(q_no))
+	    & SDP_VF_R_OUT_CNTS_OUT_INT) {
 		/*
 		 * The OUT_INT bit is set.  This interrupt must be enabled in
 		 * order to clear the interrupt.  Interrupts are disabled
@@ -104,28 +95,28 @@ otx2_vf_reset_oq(struct otx_ep_device *otx_ep, int q_no)
 		union out_int_lvl_t out_int_lvl;
 
 		out_int_lvl.d64 = otx2_read64(otx_ep->hw_addr +
-					CNXK_EP_R_OUT_INT_LEVELS(q_no));
+					SDP_VF_R_OUT_INT_LEVELS(q_no));
 		out_int_lvl.s.time_cnt_en = 1;
 		out_int_lvl.s.cnt = 0;
 		otx2_write64(out_int_lvl.d64, otx_ep->hw_addr +
-				CNXK_EP_R_OUT_INT_LEVELS(q_no));
+				SDP_VF_R_OUT_INT_LEVELS(q_no));
 	}
 
-	loop = OTX2_EP_BUSY_LOOP_COUNT;
+	loop = SDP_VF_BUSY_LOOP_COUNT;
 	do {
-		d64 = otx2_read64(otx_ep->hw_addr + CNXK_EP_R_OUT_CNTS(q_no));
-		otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_OUT_CNTS(q_no));
+		d64 = otx2_read64(otx_ep->hw_addr + SDP_VF_R_OUT_CNTS(q_no));
+		otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_OUT_CNTS(q_no));
 		rte_delay_ms(1);
-	} while ((d64 & ~OTX2_EP_R_OUT_CNTS_IN_INT) != 0 && loop--);
+	} while ((d64 & ~SDP_VF_R_OUT_CNTS_IN_INT) != 0 && loop--);
 	if (loop < 0) {
 		otx_ep_err("%s: out_cnts init retry limit exceeded.\n", __func__);
 		return -EIO;
 	}
 
 	d64 = 0ull;
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_OUT_INT_LEVELS(q_no));
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_OUT_PKT_CNT(q_no));
-	otx2_write64(d64, otx_ep->hw_addr + CNXK_EP_R_OUT_BYTE_CNT(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_OUT_INT_LEVELS(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_OUT_PKT_CNT(q_no));
+	otx2_write64(d64, otx_ep->hw_addr + SDP_VF_R_OUT_BYTE_CNT(q_no));
 
 	return 0;
 }
@@ -138,13 +129,13 @@ otx2_vf_setup_global_iq_reg(struct otx_ep_device *otx_ep, int q_no)
 	/* Select ES, RO, NS, RDSIZE,DPTR Format#0 for IQs
 	 * IS_64B is by default enabled.
 	 */
-	reg_val = oct_ep_read64(otx_ep->hw_addr + CNXK_EP_R_IN_CONTROL(q_no));
+	reg_val = oct_ep_read64(otx_ep->hw_addr + SDP_VF_R_IN_CONTROL(q_no));
 
-	reg_val |= CNXK_EP_R_IN_CTL_RDSIZE;
-	reg_val |= CNXK_EP_R_IN_CTL_IS_64B;
-	reg_val |= CNXK_EP_R_IN_CTL_ESR;
+	reg_val |= SDP_VF_R_IN_CTL_RDSIZE;
+	reg_val |= SDP_VF_R_IN_CTL_IS_64B;
+	reg_val |= SDP_VF_R_IN_CTL_ESR;
 
-	oct_ep_write64(reg_val, otx_ep->hw_addr + CNXK_EP_R_IN_CONTROL(q_no));
+	oct_ep_write64(reg_val, otx_ep->hw_addr + SDP_VF_R_IN_CONTROL(q_no));
 }
 
 static void
@@ -152,22 +143,22 @@ otx2_vf_setup_global_oq_reg(struct otx_ep_device *otx_ep, int q_no)
 {
 	volatile uint64_t reg_val = 0ull;
 
-	reg_val = oct_ep_read64(otx_ep->hw_addr + CNXK_EP_R_OUT_CONTROL(q_no));
+	reg_val = oct_ep_read64(otx_ep->hw_addr + SDP_VF_R_OUT_CONTROL(q_no));
 
-	reg_val &= ~(CNXK_EP_R_OUT_CTL_IMODE);
-	reg_val &= ~(CNXK_EP_R_OUT_CTL_ROR_P);
-	reg_val &= ~(CNXK_EP_R_OUT_CTL_NSR_P);
-	reg_val &= ~(CNXK_EP_R_OUT_CTL_ROR_I);
-	reg_val &= ~(CNXK_EP_R_OUT_CTL_NSR_I);
-	reg_val &= ~(CNXK_EP_R_OUT_CTL_ES_I);
-	reg_val &= ~(CNXK_EP_R_OUT_CTL_ROR_D);
-	reg_val &= ~(CNXK_EP_R_OUT_CTL_NSR_D);
-	reg_val &= ~(CNXK_EP_R_OUT_CTL_ES_D);
+	reg_val &= ~(SDP_VF_R_OUT_CTL_IMODE);
+	reg_val &= ~(SDP_VF_R_OUT_CTL_ROR_P);
+	reg_val &= ~(SDP_VF_R_OUT_CTL_NSR_P);
+	reg_val &= ~(SDP_VF_R_OUT_CTL_ROR_I);
+	reg_val &= ~(SDP_VF_R_OUT_CTL_NSR_I);
+	reg_val &= ~(SDP_VF_R_OUT_CTL_ES_I);
+	reg_val &= ~(SDP_VF_R_OUT_CTL_ROR_D);
+	reg_val &= ~(SDP_VF_R_OUT_CTL_NSR_D);
+	reg_val &= ~(SDP_VF_R_OUT_CTL_ES_D);
 
 	/* INFO/DATA ptr swap is required  */
-	reg_val |= (CNXK_EP_R_OUT_CTL_ES_P);
+	reg_val |= (SDP_VF_R_OUT_CTL_ES_P);
 
-	oct_ep_write64(reg_val, otx_ep->hw_addr + CNXK_EP_R_OUT_CONTROL(q_no));
+	oct_ep_write64(reg_val, otx_ep->hw_addr + SDP_VF_R_OUT_CONTROL(q_no));
 }
 
 static int
@@ -209,9 +200,9 @@ otx2_vf_setup_global_input_regs(struct otx_ep_device *otx_ep)
 	ret = otx2_vf_reset_input_queues(otx_ep);
 	if (ret)
 		return ret;
+
 	for (q_no = 0; q_no < (otx_ep->sriov_info.rings_per_vf); q_no++)
 		otx2_vf_setup_global_iq_reg(otx_ep, q_no);
-
 	return ret;
 }
 
@@ -219,15 +210,13 @@ static int
 otx2_vf_setup_global_output_regs(struct otx_ep_device *otx_ep)
 {
 	uint32_t q_no;
-	int ret;
+	int ret = 0;
 
 	ret = otx2_vf_reset_output_queues(otx_ep);
 	if (ret)
 		return ret;
-
 	for (q_no = 0; q_no < (otx_ep->sriov_info.rings_per_vf); q_no++)
 		otx2_vf_setup_global_oq_reg(otx_ep, q_no);
-
 	return ret;
 }
 
@@ -240,7 +229,6 @@ otx2_vf_setup_device_regs(struct otx_ep_device *otx_ep)
 	if (ret)
 		return ret;
 	ret = otx2_vf_setup_global_output_regs(otx_ep);
-
 	return ret;
 }
 
@@ -250,56 +238,59 @@ otx2_vf_setup_iq_regs(struct otx_ep_device *otx_ep, uint32_t iq_no)
 	struct otx_ep_instr_queue *iq = otx_ep->instr_queue[iq_no];
 	volatile uint64_t reg_val = 0ull;
 	uint64_t ism_addr;
-	int loop = OTX2_EP_BUSY_LOOP_COUNT;
+	int loop = SDP_VF_BUSY_LOOP_COUNT;
 
-	reg_val = oct_ep_read64(otx_ep->hw_addr + CNXK_EP_R_IN_CONTROL(iq_no));
+	reg_val = oct_ep_read64(otx_ep->hw_addr + SDP_VF_R_IN_CONTROL(iq_no));
 
 	/* Wait till IDLE to set to 1, not supposed to configure BADDR
 	 * as long as IDLE is 0
 	 */
-	if (!(reg_val & CNXK_EP_R_IN_CTL_IDLE)) {
+	if (!(reg_val & SDP_VF_R_IN_CTL_IDLE)) {
 		do {
-			reg_val = oct_ep_read64(otx_ep->hw_addr + CNXK_EP_R_IN_CONTROL(iq_no));
-		} while ((!(reg_val & CNXK_EP_R_IN_CTL_IDLE)) && loop--);
-		if (loop < 0)
-			return -EIO;
+			reg_val = oct_ep_read64(otx_ep->hw_addr + SDP_VF_R_IN_CONTROL(iq_no));
+		} while ((!(reg_val & SDP_VF_R_IN_CTL_IDLE)) && loop--);
+	}
+
+	if (loop < 0) {
+		otx_ep_err("IDLE bit is not set\n");
+		return -EIO;
 	}
 
 	/* Write the start of the input queue's ring and its size  */
-	oct_ep_write64(iq->base_addr_dma, otx_ep->hw_addr +
-		       CNXK_EP_R_IN_INSTR_BADDR(iq_no));
-	oct_ep_write64(iq->nb_desc, otx_ep->hw_addr +
-		       CNXK_EP_R_IN_INSTR_RSIZE(iq_no));
+	oct_ep_write64(iq->base_addr_dma, otx_ep->hw_addr + SDP_VF_R_IN_INSTR_BADDR(iq_no));
+	oct_ep_write64(iq->nb_desc, otx_ep->hw_addr + SDP_VF_R_IN_INSTR_RSIZE(iq_no));
 
 	/* Remember the doorbell & instruction count register addr
 	 * for this queue
 	 */
-	iq->doorbell_reg = (uint8_t *)otx_ep->hw_addr + CNXK_EP_R_IN_INSTR_DBELL(iq_no);
-	iq->inst_cnt_reg = (uint8_t *)otx_ep->hw_addr + CNXK_EP_R_IN_CNTS(iq_no);
+	iq->doorbell_reg = (uint8_t *)otx_ep->hw_addr + SDP_VF_R_IN_INSTR_DBELL(iq_no);
+	iq->inst_cnt_reg = (uint8_t *)otx_ep->hw_addr + SDP_VF_R_IN_CNTS(iq_no);
 
 	otx_ep_dbg("InstQ[%d]:dbell reg @ 0x%p inst_cnt_reg @ 0x%p",
 		   iq_no, iq->doorbell_reg, iq->inst_cnt_reg);
-	loop = OTX2_EP_BUSY_LOOP_COUNT;
+	loop = SDP_VF_BUSY_LOOP_COUNT;
 	do {
 		reg_val = rte_read32(iq->inst_cnt_reg);
 		rte_write32(reg_val, iq->inst_cnt_reg);
 	} while (reg_val != 0 && loop--);
 
-	if (loop < 0)
+	if (loop < 0) {
+		otx_ep_err("INST CNT REGISTER is not zero\n");
 		return -EIO;
+	}
 
 	/* IN INTR_THRESHOLD is set to max(FFFFFFFF) which disable the IN INTR
 	 * to raise
 	 */
 	oct_ep_write64(OTX_EP_CLEAR_SDP_IN_INT_LVLS,
-		       otx_ep->hw_addr + CNXK_EP_R_IN_INT_LEVELS(iq_no));
+		       otx_ep->hw_addr + SDP_VF_R_IN_INT_LEVELS(iq_no));
 
 	/* Set up IQ ISM registers and structures */
 	ism_addr = (otx_ep->ism_buffer_mz->iova | OTX2_EP_ISM_EN
 		    | OTX2_EP_ISM_MSIX_DIS)
 		    + OTX2_EP_IQ_ISM_OFFSET(iq_no);
 	oct_ep_write64(ism_addr, (uint8_t *)otx_ep->hw_addr +
-		       CNXK_EP_R_IN_CNTS_ISM(iq_no));
+		    SDP_VF_R_IN_CNTS_ISM(iq_no));
 	iq->inst_cnt_ism =
 		(uint32_t *)((uint8_t *)otx_ep->ism_buffer_mz->addr
 			     + OTX2_EP_IQ_ISM_OFFSET(iq_no));
@@ -317,27 +308,29 @@ otx2_vf_setup_oq_regs(struct otx_ep_device *otx_ep, uint32_t oq_no)
 {
 	volatile uint64_t reg_val = 0ull;
 	uint64_t oq_ctl = 0ull;
-	struct otx_ep_droq *droq = otx_ep->droq[oq_no];
 	uint64_t ism_addr;
-	int loop = OTX2_EP_BUSY_LOOP_COUNT;
+	int loop = OTX_EP_BUSY_LOOP_COUNT;
+	struct otx_ep_droq *droq = otx_ep->droq[oq_no];
 
 	/* Wait on IDLE to set to 1, supposed to configure BADDR
 	 * as long as IDLE is 0
 	 */
-	reg_val = oct_ep_read64(otx_ep->hw_addr + CNXK_EP_R_OUT_CONTROL(oq_no));
+	reg_val = oct_ep_read64(otx_ep->hw_addr + SDP_VF_R_OUT_CONTROL(oq_no));
 
-	while ((!(reg_val & CNXK_EP_R_OUT_CTL_IDLE)) && loop--) {
-		reg_val = oct_ep_read64(otx_ep->hw_addr +
-				      CNXK_EP_R_OUT_CONTROL(oq_no));
+	while ((!(reg_val & SDP_VF_R_OUT_CTL_IDLE)) && loop--) {
+		reg_val = oct_ep_read64(otx_ep->hw_addr + SDP_VF_R_OUT_CONTROL(oq_no));
+		rte_delay_ms(1);
 	}
-	if (loop < 0)
+
+	if (loop < 0) {
+		otx_ep_err("OUT CNT REGISTER value is zero\n");
 		return -EIO;
+	}
 
-	oct_ep_write64(droq->desc_ring_dma, otx_ep->hw_addr +
-		     CNXK_EP_R_OUT_SLIST_BADDR(oq_no));
-	oct_ep_write64(droq->nb_desc, otx_ep->hw_addr + CNXK_EP_R_OUT_SLIST_RSIZE(oq_no));
+	oct_ep_write64(droq->desc_ring_dma, otx_ep->hw_addr + SDP_VF_R_OUT_SLIST_BADDR(oq_no));
+	oct_ep_write64(droq->nb_desc, otx_ep->hw_addr + SDP_VF_R_OUT_SLIST_RSIZE(oq_no));
 
-	oq_ctl = oct_ep_read64(otx_ep->hw_addr + CNXK_EP_R_OUT_CONTROL(oq_no));
+	oq_ctl = oct_ep_read64(otx_ep->hw_addr + SDP_VF_R_OUT_CONTROL(oq_no));
 
 	/* Clear the ISIZE and BSIZE (22-0) */
 	oq_ctl &= ~(OTX_EP_CLEAR_ISIZE_BSIZE);
@@ -345,45 +338,44 @@ otx2_vf_setup_oq_regs(struct otx_ep_device *otx_ep, uint32_t oq_no)
 	/* Populate the BSIZE (15-0) */
 	oq_ctl |= (droq->buffer_size & OTX_EP_DROQ_BUFSZ_MASK);
 
-	otx2_write64(oq_ctl, otx_ep->hw_addr + CNXK_EP_R_OUT_CONTROL(oq_no));
+	oct_ep_write64(oq_ctl, otx_ep->hw_addr + SDP_VF_R_OUT_CONTROL(oq_no));
 
 	/* Mapped address of the pkt_sent and pkts_credit regs */
-	droq->pkts_sent_reg = (uint8_t *)otx_ep->hw_addr + CNXK_EP_R_OUT_CNTS(oq_no);
-	droq->pkts_credit_reg = (uint8_t *)otx_ep->hw_addr + CNXK_EP_R_OUT_SLIST_DBELL(oq_no);
+	droq->pkts_sent_reg = (uint8_t *)otx_ep->hw_addr + SDP_VF_R_OUT_CNTS(oq_no);
+	droq->pkts_credit_reg = (uint8_t *)otx_ep->hw_addr + SDP_VF_R_OUT_SLIST_DBELL(oq_no);
 
-	rte_write64(OTX_EP_CLEAR_OUT_INT_LVLS, otx_ep->hw_addr + CNXK_EP_R_OUT_INT_LEVELS(oq_no));
+	rte_write64(OTX_EP_CLEAR_OUT_INT_LVLS, otx_ep->hw_addr + SDP_VF_R_OUT_INT_LEVELS(oq_no));
 
 	/* Clear PKT_CNT register */
 	rte_write64(OTX_EP_CLEAR_SDP_OUT_PKT_CNT, (uint8_t *)otx_ep->hw_addr +
-		    CNXK_EP_R_OUT_PKT_CNT(oq_no));
+		    SDP_VF_R_OUT_PKT_CNT(oq_no));
 
-	loop = OTX_EP_BUSY_LOOP_COUNT;
 	/* Clear the OQ doorbell  */
-	loop = OTX2_EP_BUSY_LOOP_COUNT;
+	loop = OTX_EP_BUSY_LOOP_COUNT;
 	rte_write32(OTX_EP_CLEAR_SLIST_DBELL, droq->pkts_credit_reg);
 	while ((rte_read32(droq->pkts_credit_reg) != 0ull) && loop--) {
 		rte_write32(OTX_EP_CLEAR_SLIST_DBELL, droq->pkts_credit_reg);
 		rte_delay_ms(1);
 	}
 
-	if (loop < 0)
+	if (loop < 0) {
+		otx_ep_err("Packets credit register value is not cleared\n");
 		return -EIO;
-	otx_ep_dbg("SDP_R[%d]_credit:%x", oq_no,
-		   rte_read32(droq->pkts_credit_reg));
+	}
+	otx_ep_dbg("SDP_R[%d]_credit:%x", oq_no, rte_read32(droq->pkts_credit_reg));
 
 	/* Clear the OQ_OUT_CNTS doorbell  */
 	reg_val = rte_read32(droq->pkts_sent_reg);
 	rte_write32((uint32_t)reg_val, droq->pkts_sent_reg);
 
-	otx_ep_dbg("SDP_R[%d]_sent: %x", oq_no,
-		   rte_read32(droq->pkts_sent_reg));
+	otx_ep_dbg("SDP_R[%d]_sent: %x", oq_no, rte_read32(droq->pkts_sent_reg));
 
 	/* Set up ISM registers and structures */
 	ism_addr = (otx_ep->ism_buffer_mz->iova | OTX2_EP_ISM_EN
 		    | OTX2_EP_ISM_MSIX_DIS)
 		    + OTX2_EP_OQ_ISM_OFFSET(oq_no);
 	oct_ep_write64(ism_addr, (uint8_t *)otx_ep->hw_addr +
-		    CNXK_EP_R_OUT_CNTS_ISM(oq_no));
+		    SDP_VF_R_OUT_CNTS_ISM(oq_no));
 	droq->pkts_sent_ism =
 		(uint32_t *)((uint8_t *)otx_ep->ism_buffer_mz->addr
 			     + OTX2_EP_OQ_ISM_OFFSET(oq_no));
@@ -393,17 +385,16 @@ otx2_vf_setup_oq_regs(struct otx_ep_device *otx_ep, uint32_t oq_no)
 	*droq->pkts_sent_ism = 0;
 	droq->pkts_sent_ism_prev = 0;
 
-	loop = OTX_EP_BUSY_LOOP_COUNT;
+	loop = SDP_VF_BUSY_LOOP_COUNT;
 	while (((rte_read32(droq->pkts_sent_reg)) != 0ull) && loop--) {
 		reg_val = rte_read32(droq->pkts_sent_reg);
 		rte_write32((uint32_t)reg_val, droq->pkts_sent_reg);
 		rte_delay_ms(1);
 	}
-
 	if (loop < 0)
 		return -EIO;
 	otx_ep_dbg("SDP_R[%d]_sent: %x", oq_no,
-		   rte_read32(droq->pkts_sent_reg));
+		    rte_read32(droq->pkts_sent_reg));
 
 	return 0;
 }
@@ -411,16 +402,16 @@ otx2_vf_setup_oq_regs(struct otx_ep_device *otx_ep, uint32_t oq_no)
 static int
 otx2_vf_enable_iq(struct otx_ep_device *otx_ep, uint32_t q_no)
 {
-	volatile uint64_t reg_val = 0ull;
-	int loop = OTX2_EP_BUSY_LOOP_COUNT;
+	int loop = SDP_VF_BUSY_LOOP_COUNT;
+	uint64_t reg_val = 0ull;
 
 	/* Resetting doorbells during IQ enabling also to handle abrupt
 	 * guest reboot. IQ reset does not clear the doorbells.
 	 */
-	oct_ep_write64(0xFFFFFFFF, otx_ep->hw_addr + CNXK_EP_R_IN_INSTR_DBELL(q_no));
+	oct_ep_write64(0xFFFFFFFF, otx_ep->hw_addr + SDP_VF_R_IN_INSTR_DBELL(q_no));
 
 	while (((oct_ep_read64(otx_ep->hw_addr +
-		 CNXK_EP_R_IN_INSTR_DBELL(q_no))) != 0ull) && loop--) {
+		 SDP_VF_R_IN_INSTR_DBELL(q_no))) != 0ull) && loop--) {
 		rte_delay_ms(1);
 	}
 
@@ -429,10 +420,10 @@ otx2_vf_enable_iq(struct otx_ep_device *otx_ep, uint32_t q_no)
 		return -EIO;
 	}
 
-	reg_val = oct_ep_read64(otx_ep->hw_addr + CNXK_EP_R_IN_ENABLE(q_no));
+	reg_val = oct_ep_read64(otx_ep->hw_addr + SDP_VF_R_IN_ENABLE(q_no));
 	reg_val |= 0x1ull;
 
-	oct_ep_write64(reg_val, otx_ep->hw_addr + CNXK_EP_R_IN_ENABLE(q_no));
+	oct_ep_write64(reg_val, otx_ep->hw_addr + SDP_VF_R_IN_ENABLE(q_no));
 
 	otx_ep_info("IQ[%d] enable done", q_no);
 
@@ -444,9 +435,9 @@ otx2_vf_enable_oq(struct otx_ep_device *otx_ep, uint32_t q_no)
 {
 	uint64_t reg_val = 0ull;
 
-	reg_val = oct_ep_read64(otx_ep->hw_addr + OTX2_EP_R_OUT_ENABLE(q_no));
+	reg_val = oct_ep_read64(otx_ep->hw_addr + SDP_VF_R_OUT_ENABLE(q_no));
 	reg_val |= 0x1ull;
-	oct_ep_write64(reg_val, otx_ep->hw_addr + OTX2_EP_R_OUT_ENABLE(q_no));
+	oct_ep_write64(reg_val, otx_ep->hw_addr + SDP_VF_R_OUT_ENABLE(q_no));
 
 	otx_ep_info("OQ[%d] enable done", q_no);
 
@@ -477,10 +468,10 @@ otx2_vf_disable_iq(struct otx_ep_device *otx_ep, uint32_t q_no)
 	uint64_t reg_val = 0ull;
 
 	/* Reset the doorbell register for this Input Queue. */
-	reg_val = oct_ep_read64(otx_ep->hw_addr + CNXK_EP_R_IN_ENABLE(q_no));
+	reg_val = oct_ep_read64(otx_ep->hw_addr + SDP_VF_R_IN_ENABLE(q_no));
 	reg_val &= ~0x1ull;
 
-	oct_ep_write64(reg_val, otx_ep->hw_addr + CNXK_EP_R_IN_ENABLE(q_no));
+	oct_ep_write64(reg_val, otx_ep->hw_addr + SDP_VF_R_IN_ENABLE(q_no));
 }
 
 static void
@@ -488,10 +479,10 @@ otx2_vf_disable_oq(struct otx_ep_device *otx_ep, uint32_t q_no)
 {
 	volatile uint64_t reg_val = 0ull;
 
-	reg_val = oct_ep_read64(otx_ep->hw_addr + OTX2_EP_R_OUT_ENABLE(q_no));
+	reg_val = oct_ep_read64(otx_ep->hw_addr + SDP_VF_R_OUT_ENABLE(q_no));
 	reg_val &= ~0x1ull;
 
-	oct_ep_write64(reg_val, otx_ep->hw_addr + OTX2_EP_R_OUT_ENABLE(q_no));
+	oct_ep_write64(reg_val, otx_ep->hw_addr + SDP_VF_R_OUT_ENABLE(q_no));
 }
 
 static void
@@ -543,14 +534,14 @@ static int otx2_vf_enable_rxq_intr(struct otx_ep_device *otx_epvf,
 	union out_cnts_t out_cnts;
 
 	out_int_lvl.d64 = otx2_read64(otx_epvf->hw_addr +
-				CNXK_EP_R_OUT_INT_LEVELS(q_no));
+				SDP_VF_R_OUT_INT_LEVELS(q_no));
 	out_int_lvl.s.time_cnt_en = 1;
 	out_int_lvl.s.cnt = 0;
 	otx2_write64(out_int_lvl.d64, otx_epvf->hw_addr +
-			CNXK_EP_R_OUT_INT_LEVELS(q_no));
+			SDP_VF_R_OUT_INT_LEVELS(q_no));
 	out_cnts.d64 = 0;
 	out_cnts.s.resend = 1;
-	otx2_write64(out_cnts.d64, otx_epvf->hw_addr + CNXK_EP_R_OUT_CNTS(q_no));
+	otx2_write64(out_cnts.d64, otx_epvf->hw_addr + SDP_VF_R_OUT_CNTS(q_no));
 	return 0;
 }
 
@@ -561,11 +552,11 @@ static int otx2_vf_disable_rxq_intr(struct otx_ep_device *otx_epvf,
 
 	/* Disable the interrupt for this queue */
 	out_int_lvl.d64 = otx2_read64(otx_epvf->hw_addr +
-				CNXK_EP_R_OUT_INT_LEVELS(q_no));
+				SDP_VF_R_OUT_INT_LEVELS(q_no));
 	out_int_lvl.s.time_cnt_en = 0;
 	out_int_lvl.s.cnt = 0;
 	otx2_write64(out_int_lvl.d64, otx_epvf->hw_addr +
-			CNXK_EP_R_OUT_INT_LEVELS(q_no));
+			SDP_VF_R_OUT_INT_LEVELS(q_no));
 
 	return 0;
 }
@@ -586,10 +577,10 @@ otx2_ep_vf_setup_device(struct otx_ep_device *otx_ep)
 	}
 
 	/* Get IOQs (RPVF] count */
-	reg_val = oct_ep_read64(otx_ep->hw_addr + CNXK_EP_R_IN_CONTROL(0));
+	reg_val = oct_ep_read64(otx_ep->hw_addr + SDP_VF_R_IN_CONTROL(0));
 
-	otx_ep->sriov_info.rings_per_vf = ((reg_val >> CNXK_EP_R_IN_CTL_RPVF_POS)
-					  & CNXK_EP_R_IN_CTL_RPVF_MASK);
+	otx_ep->sriov_info.rings_per_vf = ((reg_val >> SDP_VF_R_IN_CTL_RPVF_POS)
+					  & SDP_VF_R_IN_CTL_RPVF_MASK);
 
 	otx_ep_info("SDP RPVF: %d", otx_ep->sriov_info.rings_per_vf);
 
@@ -606,7 +597,9 @@ otx2_ep_vf_setup_device(struct otx_ep_device *otx_ep)
 
 	otx_ep->fn_list.enable_oq           = otx2_vf_enable_oq;
 	otx_ep->fn_list.disable_oq          = otx2_vf_disable_oq;
+
 	otx_ep->fn_list.enable_rxq_intr     = otx2_vf_enable_rxq_intr;
 	otx_ep->fn_list.disable_rxq_intr    = otx2_vf_disable_rxq_intr;
+
 	return 0;
 }
diff --git a/drivers/net/octeon_ep/otx2_ep_vf.h b/drivers/net/octeon_ep/otx2_ep_vf.h
index 8c47c88b99235..34662fec6d636 100644
--- a/drivers/net/octeon_ep/otx2_ep_vf.h
+++ b/drivers/net/octeon_ep/otx2_ep_vf.h
@@ -6,29 +6,130 @@
 
 #include <rte_io.h>
 
+#define SDP_VF_R_IN_CTL_IDLE            (0x1ull << 28)
+#define SDP_VF_R_IN_CTL_RDSIZE          (0x3ull << 25) /* Setting to max(4) */
+#define SDP_VF_R_IN_CTL_IS_64B          (0x1ull << 24)
+#define SDP_VF_R_IN_CTL_ESR             (0x1ull << 1)
+
+#define SDP_VF_BUSY_LOOP_COUNT      (10000)
+
+/* SDP VF OQ Masks */
+#define SDP_VF_R_OUT_CTL_IDLE         (0x1ull << 40)
+#define SDP_VF_R_OUT_CTL_ES_I         (0x1ull << 34)
+#define SDP_VF_R_OUT_CTL_NSR_I        (0x1ull << 33)
+#define SDP_VF_R_OUT_CTL_ROR_I        (0x1ull << 32)
+#define SDP_VF_R_OUT_CTL_ES_D         (0x1ull << 30)
+#define SDP_VF_R_OUT_CTL_NSR_D        (0x1ull << 29)
+#define SDP_VF_R_OUT_CTL_ROR_D        (0x1ull << 28)
+#define SDP_VF_R_OUT_CTL_ES_P         (0x1ull << 26)
+#define SDP_VF_R_OUT_CTL_NSR_P        (0x1ull << 25)
+#define SDP_VF_R_OUT_CTL_ROR_P        (0x1ull << 24)
+#define SDP_VF_R_OUT_CTL_IMODE        (0x1ull << 23)
+#define SDP_VF_R_OUT_CNTS_OUT_INT     (0x1ull << 62)
+#define SDP_VF_R_OUT_CNTS_IN_INT      (0x1ull << 61)
+#define SDP_VF_R_IN_CNTS_OUT_INT      (0x1ull << 62)
+
+/* SDP VF Register definitions */
+#define SDP_VF_RING_OFFSET                (0x1ull << 17)
+
+/* SDP VF IQ Registers */
+#define SDP_VF_R_IN_CONTROL_START         (0x10000)
+#define SDP_VF_R_IN_ENABLE_START          (0x10010)
+#define SDP_VF_R_IN_INSTR_BADDR_START     (0x10020)
+#define SDP_VF_R_IN_INSTR_RSIZE_START     (0x10030)
+#define SDP_VF_R_IN_INSTR_DBELL_START     (0x10040)
+#define SDP_VF_R_IN_CNTS_START            (0x10050)
+#define SDP_VF_R_IN_INT_LEVELS_START      (0x10060)
+#define SDP_VF_R_IN_PKT_CNT_START         (0x10080)
+#define SDP_VF_R_IN_BYTE_CNT_START        (0x10090)
+#define SDP_VF_R_IN_CNTS_ISM_START        (0x10520)
+
+#define SDP_VF_R_IN_CONTROL(ring)  \
+	(SDP_VF_R_IN_CONTROL_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_IN_ENABLE(ring)   \
+	(SDP_VF_R_IN_ENABLE_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_IN_INSTR_BADDR(ring)   \
+	(SDP_VF_R_IN_INSTR_BADDR_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_IN_INSTR_RSIZE(ring)   \
+	(SDP_VF_R_IN_INSTR_RSIZE_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_IN_INSTR_DBELL(ring)   \
+	(SDP_VF_R_IN_INSTR_DBELL_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_IN_CNTS(ring)          \
+	(SDP_VF_R_IN_CNTS_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_IN_INT_LEVELS(ring)    \
+	(SDP_VF_R_IN_INT_LEVELS_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_IN_PKT_CNT(ring)       \
+	(SDP_VF_R_IN_PKT_CNT_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_IN_BYTE_CNT(ring)          \
+	(SDP_VF_R_IN_BYTE_CNT_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_IN_CNTS_ISM(ring)          \
+	(SDP_VF_R_IN_CNTS_ISM_START + (SDP_VF_RING_OFFSET * (ring)))
+
+/* SDP VF OQ Registers */
+#define SDP_VF_R_OUT_CNTS_START              (0x10100)
+#define SDP_VF_R_OUT_INT_LEVELS_START        (0x10110)
+#define SDP_VF_R_OUT_SLIST_BADDR_START       (0x10120)
+#define SDP_VF_R_OUT_SLIST_RSIZE_START       (0x10130)
+#define SDP_VF_R_OUT_SLIST_DBELL_START       (0x10140)
+#define SDP_VF_R_OUT_CONTROL_START           (0x10150)
+#define SDP_VF_R_OUT_ENABLE_START            (0x10160)
+#define SDP_VF_R_OUT_PKT_CNT_START           (0x10180)
+#define SDP_VF_R_OUT_BYTE_CNT_START          (0x10190)
+#define SDP_VF_R_OUT_CNTS_ISM_START          (0x10510)
+
+#define SDP_VF_R_OUT_CONTROL(ring)    \
+	(SDP_VF_R_OUT_CONTROL_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_OUT_ENABLE(ring)     \
+	(SDP_VF_R_OUT_ENABLE_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_OUT_SLIST_BADDR(ring)  \
+	(SDP_VF_R_OUT_SLIST_BADDR_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_OUT_SLIST_RSIZE(ring)  \
+	(SDP_VF_R_OUT_SLIST_RSIZE_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_OUT_SLIST_DBELL(ring)  \
+	(SDP_VF_R_OUT_SLIST_DBELL_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_OUT_CNTS(ring)   \
+	(SDP_VF_R_OUT_CNTS_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_OUT_INT_LEVELS(ring)   \
+	(SDP_VF_R_OUT_INT_LEVELS_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_OUT_PKT_CNT(ring)   \
+	(SDP_VF_R_OUT_PKT_CNT_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_OUT_BYTE_CNT(ring)   \
+	(SDP_VF_R_OUT_BYTE_CNT_START + ((ring) * SDP_VF_RING_OFFSET))
+
+#define SDP_VF_R_OUT_CNTS_ISM(ring)   \
+	(SDP_VF_R_OUT_CNTS_ISM_START + (SDP_VF_RING_OFFSET * (ring)))
+
+/* SDP VF IQ Masks */
+#define SDP_VF_R_IN_CTL_RPVF_MASK       (0xF)
+#define	SDP_VF_R_IN_CTL_RPVF_POS        (48)
+
 /* IO Access */
 #define otx2_read64(addr) rte_read64_relaxed((void *)(addr))
 #define otx2_write64(val, addr) rte_write64_relaxed((val), (void *)(addr))
 
-#define PCI_DEVID_OCTEONTX2_EP_NET_VF		0xB203 /* OCTEON 9 EP mode */
+#define PCI_DEVID_CN9K_EP_NET_VF		0xB203 /* OCTEON 9 EP mode */
 #define PCI_DEVID_CN98XX_EP_NET_VF		0xB103
 #define PCI_DEVID_CNF95N_EP_NET_VF		0xB403
 #define PCI_DEVID_CNF95O_EP_NET_VF		0xB603
 #define PCI_DEVID_LIO3_EP_NET_VF		0x3383
-#define PCI_DEVID_CNF95XXN_EP_NET_VF		0xB403
-#define PCI_DEVID_CNF95XXO_EP_NET_VF		0xB603
-
-#define OTX2_EP_MAX_RX_PKT_LEN			(16384)
-
-#define OTX2_EP_BUSY_LOOP_COUNT                 (10000)
-#define OTX2_EP_RING_OFFSET                     (1ULL << 17)
-#define OTX2_EP_R_OUT_CNTS_IN_INT               (1ULL << 61)
-#define OTX2_EP_R_OUT_CNTS_OUT_INT               (1ULL << 62)
 
-#define OTX2_EP_R_OUT_ENABLE_START               (0x10160)
-
-#define OTX2_EP_R_OUT_ENABLE(ring) \
-	(OTX2_EP_R_OUT_ENABLE_START + (OTX2_EP_RING_OFFSET * (ring)))
 int
 otx2_ep_vf_setup_device(struct otx_ep_device *sdpvf);
 
@@ -51,20 +152,11 @@ struct otx2_ep_instr_64B {
 	uint64_t exhdr[4];
 };
 
-#define OTX2_EP_IQ_ISM_OFFSET(queue)	(RTE_CACHE_LINE_SIZE * (queue) + 4)
-#define OTX2_EP_OQ_ISM_OFFSET(queue)	(RTE_CACHE_LINE_SIZE * (queue))
-#define OTX2_EP_ISM_EN			(0x1)
-#define OTX2_EP_ISM_MSIX_DIS		(0x2)
-#define OTX2_EP_MAX_RX_PKT_LEN		(16384)
-
-static inline int is_otx2_ep_vf(uint16_t chip_id)
-{
-	return (chip_id == PCI_DEVID_OCTEONTX2_EP_NET_VF ||
-		chip_id == PCI_DEVID_LIO3_EP_NET_VF ||
-		chip_id == PCI_DEVID_CNF95N_EP_NET_VF ||
-		chip_id == PCI_DEVID_CNF95O_EP_NET_VF ||
-		chip_id == PCI_DEVID_CN98XX_EP_NET_VF);
-}
+#define OTX2_EP_IQ_ISM_OFFSET(queue)   (RTE_CACHE_LINE_SIZE * (queue) + 4)
+#define OTX2_EP_OQ_ISM_OFFSET(queue)   (RTE_CACHE_LINE_SIZE * (queue))
+#define OTX2_EP_ISM_EN                 (0x1)
+#define OTX2_EP_ISM_MSIX_DIS           (0x2)
+#define OTX2_EP_MAX_RX_PKT_LEN         (16384)
 
 union out_int_lvl_t {
 	uint64_t d64;
@@ -102,13 +194,4 @@ union out_cnts_t {
 
 #define CN93XX_INTR_R_OUT_INT        (1ULL << 62)
 #define CN93XX_INTR_R_IN_INT         (1ULL << 61)
-#define OTX_EP_R_MBOX_PF_VF_INT_START        (0x10220)
-#define OTX_EP_RING_OFFSET                   (0x1ull << 17)
-#define OTX_EP_R_MBOX_PF_VF_INT(ring) \
-	(OTX_EP_R_MBOX_PF_VF_INT_START + ((ring) * OTX_EP_RING_OFFSET))
-
-#define OTX_EP_R_MBOX_PF_VF_DATA_START        (0x10210)
-#define OTX_EP_R_MBOX_PF_VF_DATA(ring)           \
-	(OTX_EP_R_MBOX_PF_VF_DATA_START + ((ring) * OTX_EP_RING_OFFSET))
-
 #endif /*_OTX2_EP_VF_H_ */
diff --git a/drivers/net/octeon_ep/otx_ep_common.h b/drivers/net/octeon_ep/otx_ep_common.h
index 44a01368f7803..e7fee83dff60e 100644
--- a/drivers/net/octeon_ep/otx_ep_common.h
+++ b/drivers/net/octeon_ep/otx_ep_common.h
@@ -4,6 +4,7 @@
 #ifndef _OTX_EP_COMMON_H_
 #define _OTX_EP_COMMON_H_
 
+#include <rte_spinlock.h>
 
 #define OTX_EP_NW_PKT_OP               0x1220
 #define OTX_EP_NW_CMD_OP               0x1221
@@ -37,21 +38,10 @@
 #define OTX_EP_NORESP_LAST          (4)
 #define OTX_EP_PCI_RING_ALIGN   65536
 #define OTX_EP_MAX_SG_LISTS 4
+#define OTX_EP_NUM_SG_PTRS 4
 #define SDP_PKIND 40
-#define SDP_OTX2_PKIND_FS24 57	/* Front size 24, NIC mode */
-/* Use LBK PKIND */
-#define SDP_OTX2_PKIND_FS0  0	/* Front size 0, LOOP packet mode */
-
-/*
- * Values for SDP packet mode
- * NIC: Has 24 byte header Host-> Octeon, 8 byte header Octeon->Host,
- *      application must handle these
- * LOOP: No headers, standard DPDK apps work on both ends.
- * The mode is selected by a parameter provided to the HOST DPDK driver
- */
-#define SDP_PACKET_MODE_PARAM	"sdp_packet_mode"
-#define SDP_PACKET_MODE_NIC	0x0
-#define SDP_PACKET_MODE_LOOP	0x1
+#define SDP_OTX2_PKIND 57
+#define SDP_OTX2_PKIND_FS0 0
 
 #define      ORDERED_TAG 0
 #define      ATOMIC_TAG  1
@@ -81,6 +71,9 @@
 #define oct_ep_read64(addr) rte_read64_relaxed((void *)(addr))
 #define oct_ep_write64(val, addr) rte_write64_relaxed((val), (void *)(addr))
 
+/* Mailbox maximum data size */
+#define MBOX_MAX_DATA_BUF_SIZE 320
+
 /* Input Request Header format */
 union otx_ep_instr_irh {
 	uint64_t u64;
@@ -147,12 +140,12 @@ typedef union otx_ep_instr_ih {
 struct otx_ep_sg_entry {
 	/** The first 64 bit gives the size of data in each dptr. */
 	union {
-		uint16_t size[4];
+		uint16_t size[OTX_EP_NUM_SG_PTRS];
 		uint64_t size64;
 	} u;
 
 	/** The 4 dptr pointers for this entry. */
-	uint64_t ptr[4];
+	uint64_t ptr[OTX_EP_NUM_SG_PTRS];
 };
 
 #define OTX_EP_SG_ENTRY_SIZE	(sizeof(struct otx_ep_sg_entry))
@@ -234,6 +227,7 @@ struct otx_ep_instr_queue {
 	 *  has read the commands.
 	 */
 	uint32_t flush_index;
+
 	/* Free-running/wrapping instruction counter for IQ. */
 	uint32_t inst_cnt;
 
@@ -266,6 +260,7 @@ struct otx_ep_instr_queue {
 
 	/* Location in memory updated by SDP ISM */
 	uint32_t *inst_cnt_ism;
+
 	/* track inst count locally to consolidate HW counter updates */
 	uint32_t inst_cnt_ism_prev;
 };
@@ -286,18 +281,11 @@ struct otx_ep_droq_desc {
 };
 #define OTX_EP_DROQ_DESC_SIZE	(sizeof(struct otx_ep_droq_desc))
 
-/* Receive Header, only present in NIC mode. */
-struct otx_ep_rh {
-	/* Reserved. */
-	uint64_t rsvd:48;
-
-	/* rx offload flags */
-	uint64_t rx_ol_flags:16;
+/* Receive Header */
+union otx_ep_rh {
+	uint64_t rh64;
 };
-
-#define OTX_EP_RH_SIZE_NIC (sizeof(struct otx_ep_rh))
-#define OTX_EP_RH_EXT_SIZE (sizeof(struct otx_ep_rh))
-#define OTX_EP_RH_SIZE_LOOP 0  /* Nothing in LOOP mode */
+#define OTX_EP_RH_SIZE (sizeof(union otx_ep_rh))
 
 /** Information about packet DMA'ed by OCTEON 9.
  *  The format of the information available at Info Pointer after OCTEON 9
@@ -309,10 +297,10 @@ struct otx_ep_droq_info {
 	/* The Length of the packet. */
 	uint64_t length;
 
-	/* The Output Receive Header, only present in NIC mode */
-	struct otx_ep_rh rh;
+	/* The Output Receive Header. */
+	union otx_ep_rh rh;
 };
-#define OTX_EP_DROQ_INFO_SIZE_NIC	(sizeof(struct otx_ep_droq_info))
+#define OTX_EP_DROQ_INFO_SIZE	(sizeof(struct otx_ep_droq_info))
 
 /* DROQ statistics. Each output queue has four stats fields. */
 struct otx_ep_droq_stats {
@@ -469,7 +457,6 @@ struct otx_ep_config {
 	/* OQ buffer size */
 	uint32_t oqdef_buf_size;
 };
-#define MBOX_MAX_DATA_BUF_SIZE 320
 
 /* SRIOV information */
 struct otx_ep_sriov_info {
@@ -496,6 +483,7 @@ struct otx_ep_fn_list {
 
 	int (*enable_oq)(struct otx_ep_device *otx_ep, uint32_t q_no);
 	void (*disable_oq)(struct otx_ep_device *otx_ep, uint32_t q_no);
+
 	int (*enable_rxq_intr)(struct otx_ep_device *otx_epvf, uint16_t q_no);
 	int (*disable_rxq_intr)(struct otx_ep_device *otx_epvf, uint16_t q_no);
 };
@@ -506,8 +494,8 @@ struct otx_ep_device {
 	struct rte_pci_device *pdev;
 
 	uint16_t chip_id;
-	uint16_t pf_num;
-	uint16_t vf_num;
+
+	uint32_t pkind;
 
 	struct rte_eth_dev *eth_dev;
 
@@ -543,36 +531,30 @@ struct otx_ep_device {
 	/* Device configuration */
 	const struct otx_ep_config *conf;
 
-	rte_spinlock_t mbox_lock;
+	uint64_t rx_offloads;
+
+	uint64_t tx_offloads;
+
+	/* DMA buffer for SDP ISM messages */
+	const struct rte_memzone *ism_buffer_mz;
 
-	int mbox_cmd_id;
+	/* Mailbox lock */
+	rte_spinlock_t mbox_lock;
 
+	/* Mailbox data */
 	uint8_t mbox_data_buf[MBOX_MAX_DATA_BUF_SIZE];
 
+	/* Mailbox data index */
 	int32_t mbox_data_index;
 
+	/* Mailbox receive message length */
 	int32_t mbox_rcv_message_len;
 
-	uint64_t rx_offloads;
-
-	uint64_t tx_offloads;
-
-	/* Packet mode (LOOP vs NIC), set by parameter */
-	uint8_t sdp_packet_mode;
-
-	/* DMA buffer for SDP ISM messages */
-	const struct rte_memzone *ism_buffer_mz;
-
 	/* Negotiated Mbox version */
 	uint32_t mbox_neg_ver;
 
 	/* firmware info */
 	struct otx_ep_fw_info fw_info;
-
-	/* Extended Response Header in packet data received from Hardware.
-	 * Includes metadata like checksum status.
-	 */
-	uint32_t rh_ext_size;
 };
 
 int otx_ep_setup_iqs(struct otx_ep_device *otx_ep, uint32_t iq_no,
@@ -599,11 +581,11 @@ int otx_ep_delete_oqs(struct otx_ep_device *otx_ep, uint32_t oq_no);
  * - Ethernet hdr
  * - CRC
  * - nested VLANs
- * - octeon rx info for NIC mode
+ * - octeon rx info
  */
 #define OTX_EP_ETH_OVERHEAD \
 	(RTE_ETHER_HDR_LEN + RTE_ETHER_CRC_LEN + \
-	 (2 * RTE_VLAN_HLEN) + OTX_EP_DROQ_INFO_SIZE_NIC)
+	 (2 * RTE_VLAN_HLEN) + OTX_EP_DROQ_INFO_SIZE)
 
 /* PCI IDs */
 #define PCI_VENDOR_ID_CAVIUM			0x177D
diff --git a/drivers/net/octeon_ep/otx_ep_ethdev.c b/drivers/net/octeon_ep/otx_ep_ethdev.c
index 91c66324c601c..129564b3e5713 100644
--- a/drivers/net/octeon_ep/otx_ep_ethdev.c
+++ b/drivers/net/octeon_ep/otx_ep_ethdev.c
@@ -2,11 +2,8 @@
  * Copyright(C) 2021 Marvell.
  */
 
+#include <inttypes.h>
 #include <ethdev_pci.h>
-#include <rte_ether.h>
-#include <rte_kvargs.h>
-#include <rte_spinlock.h>
-#include <eal_interrupts.h>
 
 #include "otx_ep_common.h"
 #include "otx_ep_vf.h"
@@ -14,7 +11,6 @@
 #include "cnxk_ep_vf.h"
 #include "otx_ep_rxtx.h"
 #include "otx_ep_mbox.h"
-#include "otx_ep_irq.h"
 
 #define OTX_EP_DEV(_eth_dev) \
 	((struct otx_ep_device *)(_eth_dev)->data->dev_private)
@@ -31,36 +27,6 @@ static const struct rte_eth_desc_lim otx_ep_tx_desc_lim = {
 	.nb_align	= OTX_EP_TXD_ALIGN,
 };
 
-static void
-otx_ep_interrupt_handler(void *param)
-{
-	struct otx_ep_device *otx_epvf = (struct otx_ep_device *)param;
-	union otx_ep_mbox_word *notif;
-	uint64_t reg_val;
-
-	if (otx_epvf) {
-		/* Clear Mbox interrupts */
-		reg_val = rte_read64((uint8_t *)otx_epvf->hw_addr + OTX_EP_R_MBOX_PF_VF_INT(0));
-		rte_write64(reg_val, (uint8_t *)otx_epvf->hw_addr + OTX_EP_R_MBOX_PF_VF_INT(0));
-		reg_val = otx2_read64((uint8_t *)otx_epvf->hw_addr + OTX_EP_R_MBOX_PF_VF_DATA(0));
-
-		notif = (union otx_ep_mbox_word *)&reg_val;
-		switch (notif->s_link_status.opcode) {
-		case OTX_EP_MBOX_NOTIF_LINK_STATUS:
-			if (notif->s_link_status.status)
-				otx_ep_dbg("LINK UP\n");
-			else
-				otx_ep_dbg("LINK DOWN\n");
-			break;
-		default:
-			otx_ep_err("Received unsupported notif %d\n", notif->s_link_status.opcode);
-			break;
-		}
-	} else {
-		otx_ep_err("otx_epdev_interrupt_handler is called with dev NULL\n");
-	}
-}
-
 static int
 otx_ep_dev_info_get(struct rte_eth_dev *eth_dev,
 		    struct rte_eth_dev_info *devinfo)
@@ -84,8 +50,8 @@ otx_ep_dev_info_get(struct rte_eth_dev *eth_dev,
 	devinfo->max_rx_pktlen = max_rx_pktlen;
 	devinfo->max_mtu = devinfo->max_rx_pktlen - OTX_EP_ETH_OVERHEAD;
 	devinfo->min_mtu = RTE_ETHER_MIN_LEN;
-	devinfo->rx_offload_capa = DEV_RX_OFFLOAD_SCATTER;
-	devinfo->tx_offload_capa = DEV_TX_OFFLOAD_MULTI_SEGS;
+	devinfo->rx_offload_capa = RTE_ETH_RX_OFFLOAD_SCATTER;
+	devinfo->tx_offload_capa = RTE_ETH_TX_OFFLOAD_MULTI_SEGS;
 
 	devinfo->max_mac_addrs = OTX_EP_MAX_MAC_ADDRS;
 
@@ -99,19 +65,21 @@ otx_ep_dev_info_get(struct rte_eth_dev *eth_dev,
 }
 
 static int
-otx_ep_dev_link_update(struct rte_eth_dev *eth_dev,
-		    int wait_to_complete __rte_unused)
+otx_ep_dev_link_update(struct rte_eth_dev *eth_dev, int wait_to_complete)
 {
-	int32_t ret = 0;
+	RTE_SET_USED(wait_to_complete);
+
+	if (!eth_dev->data->dev_started)
+		return 0;
 	struct rte_eth_link link;
+	int ret = 0;
 
 	memset(&link, 0, sizeof(link));
 	ret = otx_ep_mbox_get_link_info(eth_dev, &link);
 	if (ret)
 		return -EINVAL;
-
 	otx_ep_dbg("link status resp link %d duplex %d autoneg %d link_speed %d\n",
-		   link.link_status, link.link_duplex, link.link_autoneg, link.link_speed);
+		    link.link_status, link.link_duplex, link.link_autoneg, link.link_speed);
 	return rte_eth_linkstatus_set(eth_dev, &link);
 }
 
@@ -161,20 +129,6 @@ otx_ep_dev_set_default_mac_addr(struct rte_eth_dev *eth_dev,
 	return 0;
 }
 
-static int
-otx_ep_dev_get_mac_addr(struct rte_eth_dev *eth_dev,
-			struct rte_ether_addr *mac_addr)
-{
-	int ret;
-
-	ret = otx_ep_mbox_get_mac_addr(eth_dev, mac_addr);
-	if (ret)
-		return -EINVAL;
-	otx_ep_dbg("Get MAC address " RTE_ETHER_ADDR_PRT_FMT "\n",
-		    RTE_ETHER_ADDR_BYTES(mac_addr));
-	return 0;
-}
-
 static int
 otx_ep_dev_start(struct rte_eth_dev *eth_dev)
 {
@@ -216,53 +170,11 @@ otx_ep_dev_stop(struct rte_eth_dev *eth_dev)
 	return 0;
 }
 
-/* Close device */
-static int
-otx_ep_dev_close(struct rte_eth_dev *eth_dev)
-{
-	struct otx_ep_device *otx_epvf;
-	uint32_t num_queues, q;
-
-	if (rte_eal_process_type() != RTE_PROC_PRIMARY) {
-		eth_dev->dev_ops = NULL;
-		eth_dev->rx_pkt_burst = NULL;
-		eth_dev->tx_pkt_burst = NULL;
-		return 0;
-	}
-
-	otx_epvf = OTX_EP_DEV(eth_dev);
-	otx_ep_mbox_send_dev_exit(eth_dev);
-	otx_ep_mbox_disable_interrupt(otx_epvf);
-	otx_epvf->fn_list.disable_io_queues(otx_epvf);
-	num_queues = otx_epvf->nb_rx_queues;
-	for (q = 0; q < num_queues; q++) {
-		if (otx_ep_delete_oqs(otx_epvf, q)) {
-			otx_ep_err("Failed to delete OQ:%d\n", q);
-			return -EINVAL;
-		}
-	}
-	otx_ep_info("Num OQs:%d freed\n", otx_epvf->nb_rx_queues);
-	num_queues = otx_epvf->nb_tx_queues;
-	for (q = 0; q < num_queues; q++) {
-		if (otx_ep_delete_iqs(otx_epvf, q)) {
-			otx_ep_err("Failed to delete IQ:%d\n", q);
-			return -EINVAL;
-		}
-	}
-	otx_ep_dbg("Num IQs:%d freed\n", otx_epvf->nb_tx_queues);
-
-	if (rte_eth_dma_zone_free(eth_dev, "ism", 0)) {
-		otx_ep_err("Failed to delete ISM buffer\n");
-		return -EINVAL;
-	}
-	return 0;
-}
-
 /*
  * We only need 2 uint32_t locations per IOQ, but separate these so
  * each IOQ has the variables on its own cache line.
  */
-#define OTX_EP_ISM_BUFFER_SIZE	(OTX_EP_MAX_IOQS_PER_VF * RTE_CACHE_LINE_SIZE)
+#define OTX_EP_ISM_BUFFER_SIZE (OTX_EP_MAX_IOQS_PER_VF * RTE_CACHE_LINE_SIZE)
 static int
 otx_ep_ism_setup(struct otx_ep_device *otx_epvf)
 {
@@ -277,12 +189,13 @@ otx_ep_ism_setup(struct otx_ep_device *otx_epvf)
 		otx_ep_err("Failed to allocate ISM buffer\n");
 		return(-1);
 	}
-	otx_ep_dbg("ISM: virt: 0x%p, dma: %p\n",
+	otx_ep_dbg("ISM: virt: 0x%p, dma: 0x%" PRIX64,
 		    (void *)otx_epvf->ism_buffer_mz->addr,
-		   (void *)otx_epvf->ism_buffer_mz->iova);
+		    otx_epvf->ism_buffer_mz->iova);
 
 	return 0;
 }
+
 static int
 otx_ep_chip_specific_setup(struct otx_ep_device *otx_epvf)
 {
@@ -296,11 +209,11 @@ otx_ep_chip_specific_setup(struct otx_ep_device *otx_epvf)
 		ret = otx_ep_vf_setup_device(otx_epvf);
 		otx_epvf->fn_list.disable_io_queues(otx_epvf);
 		break;
-	case PCI_DEVID_OCTEONTX2_EP_NET_VF:
-	case PCI_DEVID_CNF95XXN_EP_NET_VF:
-	case PCI_DEVID_CNF95XXO_EP_NET_VF:
+	case PCI_DEVID_CN9K_EP_NET_VF:
 	case PCI_DEVID_LIO3_EP_NET_VF:
 	case PCI_DEVID_CN98XX_EP_NET_VF:
+	case PCI_DEVID_CNF95N_EP_NET_VF:
+	case PCI_DEVID_CNF95O_EP_NET_VF:
 		otx_epvf->chip_id = dev_id;
 		ret = otx2_ep_vf_setup_device(otx_epvf);
 		otx_epvf->fn_list.disable_io_queues(otx_epvf);
@@ -334,7 +247,6 @@ otx_epdev_init(struct otx_ep_device *otx_epvf)
 {
 	uint32_t ethdev_queues;
 	int ret = 0;
-	uint32_t vec = 0;
 
 	ret = otx_ep_chip_specific_setup(otx_epvf);
 	if (ret) {
@@ -347,7 +259,7 @@ otx_epdev_init(struct otx_ep_device *otx_epvf)
 	otx_epvf->eth_dev->rx_pkt_burst = &otx_ep_recv_pkts;
 	if (otx_epvf->chip_id == PCI_DEVID_OCTEONTX_EP_VF)
 		otx_epvf->eth_dev->tx_pkt_burst = &otx_ep_xmit_pkts;
-	else if (otx_epvf->chip_id == PCI_DEVID_OCTEONTX2_EP_NET_VF ||
+	else if (otx_epvf->chip_id == PCI_DEVID_CN9K_EP_NET_VF ||
 		 otx_epvf->chip_id == PCI_DEVID_CN98XX_EP_NET_VF ||
 		 otx_epvf->chip_id == PCI_DEVID_CNF95N_EP_NET_VF ||
 		 otx_epvf->chip_id == PCI_DEVID_CNF95O_EP_NET_VF ||
@@ -364,10 +276,9 @@ otx_epdev_init(struct otx_ep_device *otx_epvf)
 	ethdev_queues = (uint32_t)(otx_epvf->sriov_info.rings_per_vf);
 	otx_epvf->max_rx_queues = ethdev_queues;
 	otx_epvf->max_tx_queues = ethdev_queues;
-	otx_ep_register_irq(otx_epvf, otx_ep_interrupt_handler,
-						(void *)otx_epvf, vec);
-	otx_ep_mbox_enable_interrupt(otx_epvf);
+
 	otx_ep_info("OTX_EP Device is Ready\n");
+
 setup_fail:
 	return ret;
 }
@@ -438,12 +349,12 @@ otx_ep_rx_queue_setup(struct rte_eth_dev *eth_dev, uint16_t q_no,
 	}
 
 	if (num_rx_descs & (num_rx_descs - 1)) {
-		otx_ep_err("Invalid rx desc number(%u) This must be a power of 2\n",
+		otx_ep_err("Invalid rx desc number should be pow 2  %u\n",
 			   num_rx_descs);
 		return -EINVAL;
 	}
 	if (num_rx_descs < (SDP_GBL_WMARK * 8)) {
-		otx_ep_err("Invalid rx desc number(%u) should at least be greater than 8*wmark(%u)\n",
+		otx_ep_err("Invalid rx desc number(%u) should at least be greater than 8xwmark  %u\n",
 			   num_rx_descs, (SDP_GBL_WMARK * 8));
 		return -EINVAL;
 	}
@@ -522,7 +433,7 @@ otx_ep_tx_queue_setup(struct rte_eth_dev *eth_dev, uint16_t q_no,
 		return -EINVAL;
 	}
 	if (num_tx_descs & (num_tx_descs - 1)) {
-		otx_ep_err("Invalid tx desc number(%u) This must be a power of 2\n",
+		otx_ep_err("Invalid tx desc number should be pow 2  %u\n",
 			   num_tx_descs);
 		return -EINVAL;
 	}
@@ -614,12 +525,67 @@ otx_ep_dev_stats_get(struct rte_eth_dev *eth_dev,
 	return 0;
 }
 
+static int
+otx_ep_dev_close(struct rte_eth_dev *eth_dev)
+{
+	struct otx_ep_device *otx_epvf;
+	uint32_t num_queues, q_no;
+
+	if (rte_eal_process_type() != RTE_PROC_PRIMARY) {
+		eth_dev->dev_ops = NULL;
+		eth_dev->rx_pkt_burst = NULL;
+		eth_dev->tx_pkt_burst = NULL;
+		return 0;
+	}
+
+	otx_epvf = OTX_EP_DEV(eth_dev);
+	otx_ep_mbox_send_dev_exit(eth_dev);
+	otx_epvf->fn_list.disable_io_queues(otx_epvf);
+	num_queues = otx_epvf->nb_rx_queues;
+	for (q_no = 0; q_no < num_queues; q_no++) {
+		if (otx_ep_delete_oqs(otx_epvf, q_no)) {
+			otx_ep_err("Failed to delete OQ:%d\n", q_no);
+			return -EINVAL;
+		}
+	}
+	otx_ep_dbg("Num OQs:%d freed\n", otx_epvf->nb_rx_queues);
+
+	num_queues = otx_epvf->nb_tx_queues;
+	for (q_no = 0; q_no < num_queues; q_no++) {
+		if (otx_ep_delete_iqs(otx_epvf, q_no)) {
+			otx_ep_err("Failed to delete IQ:%d\n", q_no);
+			return -EINVAL;
+		}
+	}
+	otx_ep_dbg("Num IQs:%d freed\n", otx_epvf->nb_tx_queues);
+
+	if (rte_eth_dma_zone_free(eth_dev, "ism", 0)) {
+		otx_ep_err("Failed to delete ISM buffer\n");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int
+otx_ep_dev_get_mac_addr(struct rte_eth_dev *eth_dev,
+			struct rte_ether_addr *mac_addr)
+{
+	int ret;
+
+	ret = otx_ep_mbox_get_mac_addr(eth_dev, mac_addr);
+	if (ret)
+		return -EINVAL;
+	otx_ep_dbg("Get MAC address " RTE_ETHER_ADDR_PRT_FMT "\n",
+		    RTE_ETHER_ADDR_BYTES(mac_addr));
+	return 0;
+}
+
 /* Define our ethernet definitions */
 static const struct eth_dev_ops otx_ep_eth_dev_ops = {
 	.dev_configure		= otx_ep_dev_configure,
 	.dev_start		= otx_ep_dev_start,
 	.dev_stop		= otx_ep_dev_stop,
-	.dev_close		= otx_ep_dev_close,
 	.rx_queue_setup	        = otx_ep_rx_queue_setup,
 	.rx_queue_release	= otx_ep_rx_queue_release,
 	.tx_queue_setup	        = otx_ep_tx_queue_setup,
@@ -628,7 +594,8 @@ static const struct eth_dev_ops otx_ep_eth_dev_ops = {
 	.stats_get		= otx_ep_dev_stats_get,
 	.stats_reset		= otx_ep_dev_stats_reset,
 	.link_update		= otx_ep_dev_link_update,
-	.mtu_set                = otx_ep_dev_mtu_set,
+	.dev_close		= otx_ep_dev_close,
+	.mtu_set		= otx_ep_dev_mtu_set,
 	.mac_addr_set           = otx_ep_dev_set_default_mac_addr,
 };
 
@@ -649,7 +616,6 @@ otx_ep_eth_dev_uninit(struct rte_eth_dev *eth_dev)
 	return 0;
 }
 
-
 static int otx_ep_eth_dev_query_set_vf_mac(struct rte_eth_dev *eth_dev,
 					   struct rte_ether_addr *mac_addr)
 {
@@ -696,9 +662,7 @@ otx_ep_eth_dev_init(struct rte_eth_dev *eth_dev)
 		return 0;
 	}
 
-	otx_epvf->sdp_packet_mode = SDP_PACKET_MODE_LOOP;
 	rte_eth_copy_pci_info(eth_dev, pdev);
-
 	otx_epvf->eth_dev = eth_dev;
 	otx_epvf->port_id = eth_dev->data->port_id;
 	eth_dev->dev_ops = &otx_ep_eth_dev_ops;
@@ -715,19 +679,33 @@ otx_ep_eth_dev_init(struct rte_eth_dev *eth_dev)
 		eth_dev->dev_ops = NULL;
 		return -ENOMEM;
 	}
+	rte_eth_random_addr(vf_mac_addr.addr_bytes);
+	rte_ether_addr_copy(&vf_mac_addr, eth_dev->data->mac_addrs);
 	otx_epvf->hw_addr = pdev->mem_resource[0].addr;
 	otx_epvf->pdev = pdev;
 
 	if (otx_epdev_init(otx_epvf))
 		return -ENOMEM;
-
-	if (otx_ep_mbox_version_check(eth_dev))
+	if (otx_epvf->chip_id == PCI_DEVID_CN9K_EP_NET_VF ||
+	    otx_epvf->chip_id == PCI_DEVID_CN98XX_EP_NET_VF ||
+	    otx_epvf->chip_id == PCI_DEVID_CNF95N_EP_NET_VF ||
+	    otx_epvf->chip_id == PCI_DEVID_CNF95O_EP_NET_VF ||
+	    otx_epvf->chip_id == PCI_DEVID_CN10KA_EP_NET_VF ||
+	    otx_epvf->chip_id == PCI_DEVID_CN10KB_EP_NET_VF ||
+	    otx_epvf->chip_id == PCI_DEVID_CNF10KA_EP_NET_VF ||
+	    otx_epvf->chip_id == PCI_DEVID_CNF10KB_EP_NET_VF) {
+		otx_epvf->pkind = SDP_OTX2_PKIND_FS0;
+		otx_ep_info("using pkind %d\n", otx_epvf->pkind);
+	} else if (otx_epvf->chip_id == PCI_DEVID_OCTEONTX_EP_VF) {
+		otx_epvf->pkind = SDP_PKIND;
+		otx_ep_info("Using pkind %d.\n", otx_epvf->pkind);
+	} else {
+		otx_ep_err("Invalid chip id\n");
 		return -EINVAL;
+	}
 
-	if (otx_ep_mbox_get_fw_info(eth_dev))
+	if (otx_ep_mbox_version_check(eth_dev))
 		return -EINVAL;
-	if (otx_epvf->fw_info.rx_ol_flags)
-		otx_epvf->rh_ext_size = OTX_EP_RH_EXT_SIZE;
 
 	if (otx_ep_eth_dev_query_set_vf_mac(eth_dev,
 				(struct rte_ether_addr *)&vf_mac_addr)) {
@@ -735,6 +713,7 @@ otx_ep_eth_dev_init(struct rte_eth_dev *eth_dev)
 		return -ENODEV;
 	}
 	rte_ether_addr_copy(&vf_mac_addr, eth_dev->data->mac_addrs);
+
 	return 0;
 }
 
@@ -757,13 +736,11 @@ otx_ep_eth_dev_pci_remove(struct rte_pci_device *pci_dev)
 /* Set of PCI devices this driver supports */
 static const struct rte_pci_id pci_id_otx_ep_map[] = {
 	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_OCTEONTX_EP_VF) },
-	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_OCTEONTX2_EP_NET_VF) },
-	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_CNF95XXN_EP_NET_VF) },
-	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_CNF95XXO_EP_NET_VF) },
-	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_LIO3_EP_NET_VF) },
+	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_CN9K_EP_NET_VF) },
 	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_CN98XX_EP_NET_VF) },
 	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_CNF95N_EP_NET_VF) },
 	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_CNF95O_EP_NET_VF) },
+	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_LIO3_EP_NET_VF) },
 	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_CN10KA_EP_NET_VF) },
 	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_CN10KB_EP_NET_VF) },
 	{ RTE_PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, PCI_DEVID_CNF10KA_EP_NET_VF) },
diff --git a/drivers/net/octeon_ep/otx_ep_irq.c b/drivers/net/octeon_ep/otx_ep_irq.c
deleted file mode 100644
index 1e912d95319bf..0000000000000
--- a/drivers/net/octeon_ep/otx_ep_irq.c
+++ /dev/null
@@ -1,183 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(C) 2021 Marvell.
- */
-
-#include <rte_interrupts.h>
-#include <eal_interrupts.h>
-#include <ethdev_pci.h>
-#include <rte_ether.h>
-#include <linux/vfio.h>
-#include <sys/eventfd.h>
-#include <sys/ioctl.h>
-#include "otx_ep_common.h"
-#include "otx_ep_irq.h"
-
-
-#define MAX_INTR_VEC_ID RTE_MAX_RXTX_INTR_VEC_ID
-#define MSIX_IRQ_SET_BUF_LEN (sizeof(struct vfio_irq_set) + \
-			      sizeof(int) * (MAX_INTR_VEC_ID))
-static int
-otx_ep_irq_get_info(struct rte_intr_handle *intr_handle)
-{
-	struct vfio_irq_info irq = { .argsz = sizeof(irq) };
-	int rc;
-
-	irq.index = VFIO_PCI_MSIX_IRQ_INDEX;
-
-	rc = ioctl(intr_handle->dev_fd, VFIO_DEVICE_GET_IRQ_INFO, &irq);
-	if (rc < 0) {
-		otx_ep_err("Failed to get IRQ info rc=%d errno=%d", rc, errno);
-		return rc;
-	}
-
-	otx_ep_dbg("Flags=0x%x index=0x%x count=0x%x max_intr_vec_id=0x%x",
-			irq.flags, irq.index, irq.count, MAX_INTR_VEC_ID);
-
-	if (irq.count > MAX_INTR_VEC_ID) {
-		otx_ep_err("HW max=%d > MAX_INTR_VEC_ID: %d",
-				intr_handle->max_intr, MAX_INTR_VEC_ID);
-		intr_handle->max_intr = MAX_INTR_VEC_ID;
-	} else {
-		intr_handle->max_intr = irq.count;
-	}
-	otx_ep_info("Flags=0x%x index=0x%x count=0x%x max_intr_vec_id=0x%x intr_handle->max_intr+0x%x",
-			irq.flags, irq.index, irq.count, MAX_INTR_VEC_ID, intr_handle->max_intr);
-
-	return 0;
-}
-
-static int
-otx_ep_irq_init(struct rte_intr_handle *intr_handle)
-{
-	char irq_set_buf[MSIX_IRQ_SET_BUF_LEN];
-	struct vfio_irq_set *irq_set;
-	int32_t *fd_ptr;
-	int len, rc;
-	uint32_t i;
-
-	if (intr_handle->max_intr > MAX_INTR_VEC_ID) {
-		otx_ep_err("Max_intr=%d greater than MAX_INTR_VEC_ID=%d",
-				intr_handle->max_intr, MAX_INTR_VEC_ID);
-		return -ERANGE;
-	}
-
-	len = sizeof(struct vfio_irq_set) +
-		sizeof(int32_t) * intr_handle->max_intr;
-
-	irq_set = (struct vfio_irq_set *)irq_set_buf;
-	irq_set->argsz = len;
-	irq_set->start = 0;
-	irq_set->count = intr_handle->max_intr;
-	irq_set->flags = VFIO_IRQ_SET_DATA_EVENTFD |
-			VFIO_IRQ_SET_ACTION_TRIGGER;
-	irq_set->index = VFIO_PCI_MSIX_IRQ_INDEX;
-
-	fd_ptr = (int32_t *)&irq_set->data[0];
-	for (i = 0; i < irq_set->count; i++)
-		fd_ptr[i] = -1;
-
-	rc = ioctl(intr_handle->dev_fd, VFIO_DEVICE_SET_IRQS, irq_set);
-	if (rc)
-		otx_ep_err("Failed to set irqs vector rc=%d", rc);
-
-	return rc;
-}
-
-static int
-otx_ep_irq_config(struct rte_intr_handle *intr_handle, unsigned int vec)
-{
-	char irq_set_buf[MSIX_IRQ_SET_BUF_LEN];
-	struct vfio_irq_set *irq_set;
-	int32_t *fd_ptr;
-	int len, rc;
-
-	if (vec > intr_handle->max_intr) {
-		otx_ep_err("vector=%d greater than max_intr=%d", vec,
-				intr_handle->max_intr);
-		return -EINVAL;
-	}
-
-	len = sizeof(struct vfio_irq_set) + sizeof(int32_t);
-
-	irq_set = (struct vfio_irq_set *)irq_set_buf;
-	irq_set->argsz = len;
-
-	irq_set->start = vec;
-	irq_set->count = 1;
-	irq_set->flags = VFIO_IRQ_SET_DATA_EVENTFD |
-			VFIO_IRQ_SET_ACTION_TRIGGER;
-	irq_set->index = VFIO_PCI_MSIX_IRQ_INDEX;
-
-	/* Use vec fd to set interrupt vectors */
-	fd_ptr = (int32_t *)&irq_set->data[0];
-	fd_ptr[0] = intr_handle->efds[vec];
-
-	rc = ioctl(intr_handle->dev_fd, VFIO_DEVICE_SET_IRQS, irq_set);
-	if (rc)
-		otx_ep_err("Failed to set_irqs vector=0x%x rc=%d", vec, rc);
-
-	return rc;
-}
-
-int
-otx_ep_register_irq(struct otx_ep_device *otx_ep,
-			rte_intr_callback_fn cb, void *data, unsigned int vec)
-{
-	struct rte_pci_device *pci_dev      = otx_ep->pdev;
-	struct rte_intr_handle *intr_handle = pci_dev->intr_handle;
-	struct rte_intr_handle tmp_handle;
-	int rc = -1;
-
-	/* If no max_intr read from VFIO */
-	if (intr_handle->max_intr == 0) {
-		otx_ep_irq_get_info(intr_handle);
-		otx_ep_irq_init(intr_handle);
-	}
-
-	if (vec > intr_handle->max_intr) {
-		otx_ep_err("Vector=%d greater than max_intr=%d", vec,
-				intr_handle->max_intr);
-		return -EINVAL;
-	}
-
-	tmp_handle = *intr_handle;
-	/* Create new eventfd for interrupt vector */
-	tmp_handle.fd = eventfd(0, EFD_NONBLOCK | EFD_CLOEXEC);
-	if (tmp_handle.fd == -1)
-		return -ENODEV;
-
-	/* Register vector interrupt callback */
-	rc = rte_intr_callback_register(&tmp_handle, cb, data);
-	if (rc) {
-		otx_ep_err("Failed to register vector:0x%x irq callback.", vec);
-		return rc;
-	}
-
-	intr_handle->efds[vec] = tmp_handle.fd;
-	intr_handle->nb_efd = (vec > intr_handle->nb_efd) ?
-			vec : intr_handle->nb_efd;
-	if ((intr_handle->nb_efd + 1) > intr_handle->max_intr)
-		intr_handle->max_intr = intr_handle->nb_efd + 1;
-	otx_ep_info("Enable vector:0x%x for vfio (efds: %d, max:%d) type: %x dev_fd: %x",
-			vec, intr_handle->nb_efd, intr_handle->max_intr, intr_handle->type,
-			intr_handle->dev_fd);
-
-	/* Enable MSIX vectors to VFIO */
-	return otx_ep_irq_config(intr_handle, vec);
-}
-
-int
-otx_ep_unregister_irq(struct otx_ep_device *otx_ep,
-			rte_intr_callback_fn cb, void *data)
-{
-	struct rte_pci_device *pci_dev = otx_ep->pdev;
-	struct rte_intr_handle *intr_handle = pci_dev->intr_handle;
-	int rc = -1;
-
-	rc = rte_intr_callback_unregister(intr_handle, cb, data);
-	if (rc) {
-		otx_ep_err("Failed to unregister irq callback.\n");
-		return rc;
-	}
-	return 0;
-}
diff --git a/drivers/net/octeon_ep/otx_ep_irq.h b/drivers/net/octeon_ep/otx_ep_irq.h
deleted file mode 100644
index d490e484ad5d3..0000000000000
--- a/drivers/net/octeon_ep/otx_ep_irq.h
+++ /dev/null
@@ -1,12 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause
- * Copyright(C) 2021 Marvell.
- */
-
-#ifndef _OTX_EP_IRQ_H_
-#define _OTX_EP_IRQ_H_
-
-int otx_ep_register_irq(struct otx_ep_device *otx_ep,
-			rte_intr_callback_fn cb, void *data, unsigned int vec);
-int otx_ep_unregister_irq(struct otx_ep_device *otx_ep,
-			  rte_intr_callback_fn cb, void *data);
-#endif
diff --git a/drivers/net/octeon_ep/otx_ep_mbox.c b/drivers/net/octeon_ep/otx_ep_mbox.c
index 9665ec0fe9324..3c5739c7e1407 100644
--- a/drivers/net/octeon_ep/otx_ep_mbox.c
+++ b/drivers/net/octeon_ep/otx_ep_mbox.c
@@ -5,7 +5,6 @@
 #include <ethdev_pci.h>
 #include <rte_ether.h>
 #include <rte_kvargs.h>
-#include <rte_spinlock.h>
 
 #include "otx_ep_common.h"
 #include "otx_ep_vf.h"
@@ -102,7 +101,7 @@ otx_ep_mbox_bulk_read(struct otx_ep_device *otx_ep,
 	/*  PF sends the data length of requested CMD
 	 *  in  ACK
 	 */
-	data_len = *((int32_t *)rsp.s_data.data);
+	memcpy(&data_len, rsp.s_data.data, sizeof(data_len));
 	tmp_len = data_len;
 	cmd.u64 = 0;
 	rsp.u64 = 0;
@@ -262,14 +261,14 @@ void
 otx_ep_mbox_enable_interrupt(struct otx_ep_device *otx_ep)
 {
 	rte_write64(0x2, (uint8_t *)otx_ep->hw_addr +
-		   OTX_EP_R_MBOX_PF_VF_INT(0));
+		   CNXK_EP_R_MBOX_PF_VF_INT(0));
 }
 
 void
 otx_ep_mbox_disable_interrupt(struct otx_ep_device *otx_ep)
 {
 	rte_write64(0x00, (uint8_t *)otx_ep->hw_addr +
-		   OTX_EP_R_MBOX_PF_VF_INT(0));
+		   CNXK_EP_R_MBOX_PF_VF_INT(0));
 }
 
 int
@@ -303,6 +302,7 @@ int otx_ep_mbox_version_check(struct rte_eth_dev *eth_dev)
 	cmd.s_version.opcode = OTX_EP_MBOX_CMD_VERSION;
 	cmd.s_version.version = OTX_EP_MBOX_VERSION_CURRENT;
 	ret = otx_ep_send_mbox_cmd(otx_ep, cmd, &rsp);
+
 	/*
 	 * VF receives NACK or version info as zero
 	 * only if PF driver running old version of Mailbox
diff --git a/drivers/net/octeon_ep/otx_ep_rxtx.c b/drivers/net/octeon_ep/otx_ep_rxtx.c
index af524779dcce1..b37fc8109f297 100644
--- a/drivers/net/octeon_ep/otx_ep_rxtx.c
+++ b/drivers/net/octeon_ep/otx_ep_rxtx.c
@@ -9,7 +9,6 @@
 #include <rte_mbuf.h>
 #include <rte_io.h>
 #include <rte_net.h>
-#include <rte_cycles.h>
 #include <ethdev_pci.h>
 
 #include "otx_ep_common.h"
@@ -18,9 +17,10 @@
 #include "otx_ep_rxtx.h"
 
 /* SDP_LENGTH_S specifies packet length and is of 8-byte size */
-#define INFO_SIZE 8
+#define OTX_EP_INFO_SIZE 8
+#define OTX_EP_FSZ_FS0 0
 #define DROQ_REFILL_THRESHOLD 16
-#define OTX2_SDP_REQUEST_ISM	(0x1ULL << 63)
+#define OTX2_SDP_REQUEST_ISM   (0x1ULL << 63)
 
 static void
 otx_ep_dmazone_free(const struct rte_memzone *mz)
@@ -543,7 +543,7 @@ set_sg_size(struct otx_ep_sg_entry *sg_entry, uint16_t size, uint32_t pos)
 #if RTE_BYTE_ORDER == RTE_BIG_ENDIAN
 	sg_entry->u.size[pos] = size;
 #elif RTE_BYTE_ORDER == RTE_LITTLE_ENDIAN
-	sg_entry->u.size[3 - pos] = size;
+	sg_entry->u.size[(OTX_EP_NUM_SG_PTRS - 1) - pos] = size;
 #endif
 }
 
@@ -551,14 +551,14 @@ static inline int
 prepare_xmit_gather_list(struct otx_ep_instr_queue *iq, struct rte_mbuf *m, uint64_t *dptr,
 			 union otx_ep_instr_ih *ih)
 {
+	uint16_t j = 0, frags, num_sg, mask = OTX_EP_NUM_SG_PTRS - 1;
 	struct otx_ep_buf_free_info *finfo;
-	uint16_t j = 0, frags, num_sg;
 	uint32_t pkt_len;
 	int rc = -1;
 
 	pkt_len = rte_pktmbuf_pkt_len(m);
 	frags = m->nb_segs;
-	num_sg = (frags + 3) / 4;
+	num_sg = (frags + mask) / OTX_EP_NUM_SG_PTRS;
 
 	if (unlikely(pkt_len > OTX_EP_MAX_PKT_SZ && num_sg > OTX_EP_MAX_SG_LISTS)) {
 		otx_ep_err("Failed to xmit the pkt, pkt_len is higher or pkt has more segments\n");
@@ -572,8 +572,8 @@ prepare_xmit_gather_list(struct otx_ep_instr_queue *iq, struct rte_mbuf *m, uint
 	ih->s.gather = 1;
 
 	while (frags--) {
-		finfo->g.sg[(j >> 2)].ptr[(j & 3)] = rte_mbuf_data_iova(m);
-		set_sg_size(&finfo->g.sg[(j >> 2)], m->data_len, (j & 3));
+		finfo->g.sg[(j >> 2)].ptr[(j & mask)] = rte_mbuf_data_iova(m);
+		set_sg_size(&finfo->g.sg[(j >> 2)], m->data_len, (j & mask));
 		j++;
 		m = m->next;
 	}
@@ -604,7 +604,7 @@ otx_ep_xmit_pkts(void *tx_queue, struct rte_mbuf **pkts, uint16_t nb_pkts)
 
 	/* ih invars */
 	iqcmd.ih.s.fsz = OTX_EP_FSZ;
-	iqcmd.ih.s.pkind = otx_ep->fw_info.pkind;
+	iqcmd.ih.s.pkind = otx_ep->pkind; /* The SDK decided PKIND value */
 
 	/* pki ih3 invars */
 	iqcmd.pki_ih3.s.w = 1;
@@ -691,9 +691,9 @@ otx2_ep_xmit_pkts(void *tx_queue, struct rte_mbuf **pkts, uint16_t nb_pkts)
 	iqcmd2.irh.u64 = 0;
 
 	/* ih invars */
-	iqcmd2.ih.s.fsz = otx_ep->fw_info.fsz;
-	iqcmd2.ih.s.pkind = otx_ep->fw_info.pkind;
-	/* irh invars, ignored in LOOP mode */
+	iqcmd2.ih.s.fsz = OTX_EP_FSZ_FS0;
+	iqcmd2.ih.s.pkind = otx_ep->pkind; /* The SDK decided PKIND value */
+	/* irh invars */
 	iqcmd2.irh.s.opcode = OTX_EP_NW_PKT_OP;
 
 	for (i = 0; i < nb_pkts; i++) {
@@ -804,9 +804,7 @@ otx_ep_droq_read_packet(struct otx_ep_device *otx_ep,
 	uint64_t total_pkt_len;
 	uint32_t pkt_len = 0;
 	int next_idx;
-	int info_size;
 
-	info_size = INFO_SIZE + otx_ep->rh_ext_size;
 	droq_pkt  = droq->recv_buf_list[droq->read_idx];
 	droq_pkt2  = droq->recv_buf_list[droq->read_idx];
 	info = rte_pktmbuf_mtod(droq_pkt, struct otx_ep_droq_info *);
@@ -826,6 +824,7 @@ otx_ep_droq_read_packet(struct otx_ep_device *otx_ep,
 		if (!retry && !info->length) {
 			otx_ep_err("OCTEON DROQ[%d]: read_idx: %d; Retry failed !!\n",
 				   droq->q_no, droq->read_idx);
+			/* May be zero length packet; drop it */
 			assert(0);
 		}
 	}
@@ -838,12 +837,11 @@ otx_ep_droq_read_packet(struct otx_ep_device *otx_ep,
 
 	info->length = rte_bswap64(info->length);
 	/* Deduce the actual data size */
-	total_pkt_len = info->length + INFO_SIZE;
+	total_pkt_len = info->length + OTX_EP_INFO_SIZE;
 	if (total_pkt_len <= droq->buffer_size) {
-		info->length -=  otx_ep->rh_ext_size;
 		droq_pkt  = droq->recv_buf_list[droq->read_idx];
 		if (likely(droq_pkt != NULL)) {
-			droq_pkt->data_off += info_size;
+			droq_pkt->data_off += OTX_EP_INFO_SIZE;
 			/* otx_ep_dbg("OQ: pkt_len[%ld], buffer_size %d\n",
 			 * (long)info->length, droq->buffer_size);
 			 */
@@ -860,9 +858,10 @@ otx_ep_droq_read_packet(struct otx_ep_device *otx_ep,
 		struct rte_mbuf *first_buf = NULL;
 		struct rte_mbuf *last_buf = NULL;
 
-		/* initiating a csr read helps to flush pending dma */
+		/* csr read helps to flush pending dma */
 		droq->sent_reg_val = rte_read32(droq->pkts_sent_reg);
 		rte_rmb();
+
 		while (pkt_len < total_pkt_len) {
 			int cpy_len = 0;
 
@@ -883,11 +882,11 @@ otx_ep_droq_read_packet(struct otx_ep_device *otx_ep,
 				droq_pkt->port = otx_ep->port_id;
 				if (!pkt_len) {
 					droq_pkt->data_off +=
-						info_size;
+						OTX_EP_INFO_SIZE;
 					droq_pkt->pkt_len =
-						cpy_len - info_size;
+						cpy_len - OTX_EP_INFO_SIZE;
 					droq_pkt->data_len =
-						cpy_len - info_size;
+						cpy_len - OTX_EP_INFO_SIZE;
 				} else {
 					droq_pkt->pkt_len = cpy_len;
 					droq_pkt->data_len = cpy_len;
@@ -903,7 +902,7 @@ otx_ep_droq_read_packet(struct otx_ep_device *otx_ep,
 
 				last_buf = droq_pkt;
 			} else {
-				otx_ep_err("no recvbuf in jumbo processing\n");
+				otx_ep_err("no buf\n");
 				assert(0);
 			}
 
@@ -948,8 +947,8 @@ otx_ep_check_droq_pkts(struct otx_ep_droq *droq)
 		droq->pkts_sent_ism_prev = 0;
 	}
 	rte_write64(OTX2_SDP_REQUEST_ISM, droq->pkts_sent_reg);
-
 	droq->pkts_pending += new_pkts;
+
 	return new_pkts;
 }
 
diff --git a/drivers/net/octeon_ep/otx_ep_rxtx.h b/drivers/net/octeon_ep/otx_ep_rxtx.h
index 85dd1f8e05fb1..3f125270046ee 100644
--- a/drivers/net/octeon_ep/otx_ep_rxtx.h
+++ b/drivers/net/octeon_ep/otx_ep_rxtx.h
@@ -16,8 +16,7 @@
 #define OTX_EP_MAX_DELAYED_PKT_RETRIES 10000
 
 #define OTX_EP_FSZ 28
-#define OTX2_EP_FSZ_LOOP 0
-#define OTX2_EP_FSZ_NIC 24
+#define OTX2_EP_FSZ 24
 #define OTX_EP_MAX_INSTR 16
 
 static inline uint32_t
diff --git a/drivers/net/octeon_ep/otx_ep_vf.c b/drivers/net/octeon_ep/otx_ep_vf.c
index 3922b2ff415dc..4f3538146b57b 100644
--- a/drivers/net/octeon_ep/otx_ep_vf.c
+++ b/drivers/net/octeon_ep/otx_ep_vf.c
@@ -2,17 +2,16 @@
  * Copyright(C) 2021 Marvell.
  */
 
-#include <errno.h>
-
 #include <rte_common.h>
 #include <rte_cycles.h>
 #include <rte_io.h>
-#include <rte_spinlock.h>
-#include <rte_interrupts.h>
+#include <ethdev_driver.h>
+#include <ethdev_pci.h>
 
 #include "otx_ep_common.h"
 #include "otx_ep_vf.h"
 
+
 static int
 otx_ep_setup_global_iq_reg(struct otx_ep_device *otx_ep, int q_no)
 {
@@ -76,7 +75,6 @@ otx_ep_setup_global_input_regs(struct otx_ep_device *otx_ep)
 		if (ret)
 			return ret;
 	}
-
 	return 0;
 }
 
@@ -93,11 +91,11 @@ static int
 otx_ep_setup_device_regs(struct otx_ep_device *otx_ep)
 {
 	int ret;
+
 	ret = otx_ep_setup_global_input_regs(otx_ep);
 	if (ret)
 		return ret;
 	otx_ep_setup_global_output_regs(otx_ep);
-
 	return 0;
 }
 
@@ -155,7 +153,6 @@ otx_ep_setup_iq_regs(struct otx_ep_device *otx_ep, uint32_t iq_no)
 	 */
 	otx_ep_write64(OTX_EP_CLEAR_IN_INT_LVLS, otx_ep->hw_addr,
 		       OTX_EP_R_IN_INT_LEVELS(iq_no));
-
 	return 0;
 }
 
@@ -233,7 +230,6 @@ otx_ep_setup_oq_regs(struct otx_ep_device *otx_ep, uint32_t oq_no)
 	}
 	if (loop < 0)
 		return -EIO;
-
 	return 0;
 }
 
@@ -285,7 +281,6 @@ otx_ep_enable_oq(struct otx_ep_device *otx_ep, uint32_t q_no)
 		 OTX_EP_R_OUT_SLIST_DBELL(q_no))) != 0ull) && loop--) {
 		rte_delay_ms(1);
 	}
-
 	if (loop < 0) {
 		otx_ep_err("dbell reset failed\n");
 		return -EIO;
@@ -426,5 +421,7 @@ otx_ep_vf_setup_device(struct otx_ep_device *otx_ep)
 
 	otx_ep->fn_list.enable_oq           = otx_ep_enable_oq;
 	otx_ep->fn_list.disable_oq          = otx_ep_disable_oq;
+
+
 	return 0;
 }
diff --git a/drivers/net/octeon_ep/otx_ep_vf.h b/drivers/net/octeon_ep/otx_ep_vf.h
index 75f1b24fa1b53..1c98e626056ce 100644
--- a/drivers/net/octeon_ep/otx_ep_vf.h
+++ b/drivers/net/octeon_ep/otx_ep_vf.h
@@ -53,10 +53,6 @@
 #define OTX_EP_R_OUT_CONTROL_START           (0x10150)
 #define OTX_EP_R_OUT_ENABLE_START            (0x10160)
 
-#define OTX_EP_R_MBOX_PF_VF_DATA_START	     (0x10210)
-#define OTX_EP_R_MBOX_VF_PF_DATA_START	     (0x10230)
-#define OTX_EP_R_MBOX_PF_VF_INT_START	     (0x10220)
-
 #define OTX_EP_R_OUT_CONTROL(ring)    \
 	(OTX_EP_R_OUT_CONTROL_START + ((ring) * OTX_EP_RING_OFFSET))
 
@@ -78,21 +74,6 @@
 #define OTX_EP_R_OUT_INT_LEVELS(ring)   \
 	(OTX_EP_R_OUT_INT_LEVELS_START + ((ring) * OTX_EP_RING_OFFSET))
 
-#define OTX_EP_R_OUT_PKT_CNT(ring)   \
-	(OTX_EP_R_OUT_PKT_CNT_START + ((ring) * OTX_EP_RING_OFFSET))
-
-#define OTX_EP_R_OUT_BYTE_CNT(ring)   \
-	(OTX_EP_R_OUT_BYTE_CNT_START + ((ring) * OTX_EP_RING_OFFSET))
-
-#define OTX_EP_R_MBOX_PF_VF_DATA(ring) \
-	(OTX_EP_R_MBOX_PF_VF_DATA_START + ((ring) * OTX_EP_RING_OFFSET))
-
-#define OTX_EP_R_MBOX_VF_PF_DATA(ring) \
-	(OTX_EP_R_MBOX_VF_PF_DATA_START + ((ring) * OTX_EP_RING_OFFSET))
-#define OTX_EP_R_MBOX_PF_VF_INT(ring) \
-	(OTX_EP_R_MBOX_PF_VF_INT_START + ((ring) * OTX_EP_RING_OFFSET))
-
-
 /* OTX_EP VF OQ Masks */
 
 #define OTX_EP_R_OUT_CTL_IDLE         (1ull << 36)
@@ -108,10 +89,6 @@
 #define OTX_EP_R_OUT_CTL_IMODE        (1ull << 23)
 
 #define PCI_DEVID_OCTEONTX_EP_VF 0xa303
-static inline int is_otx_ep_vf(uint16_t chip_id)
-{
-	return (chip_id == PCI_DEVID_OCTEONTX_EP_VF);
-}
 
 /* this is a static value set by SLI PF driver in octeon
  * No handshake is available
-- 
2.25.1

